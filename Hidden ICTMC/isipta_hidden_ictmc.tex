%\documentclass[10pt,a4paper]{paper}
%\documentclass[3p]{elsarticle}
%\documentclass[a4paper,reqno]{amsart}
\documentclass[twoside,11pt]{article}
\usepackage{isipta}


\usepackage[british]{babel}
%\usepackage[garamond]{mathdesign}

\usepackage{authblk}

\usepackage{hyperref,url}

\usepackage{mathptmx}
\usepackage{amsmath}
\usepackage{courier}
\usepackage{amssymb}
%\usepackage{mathtools}
%\usepackage{amsthm}

\usepackage{enumerate}
\usepackage{enumitem,multicol}
\usepackage{tikz}
\usepackage{nicefrac}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{graphicx}

%\usepackage{eufrak}

%\usepackage{hyperref}
%\usepackage{pdfsync}
%\usepackage{authblk}

\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}

%\theoremstyle{definition}
%\newtheorem{exmp}{Example}%[section]
 
\renewcommand{\ttdefault}{cmtt}
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{definition}{Definition}
%\newtheorem{remark}{Remark}
%\newtheorem*{remark*}{Remark}

%\newtheorem{claim}{Claim}[theorem]
%\newtheorem*{claim*}{Claim}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}

% - macros

\newcommand{\nats}{\mathbb{N}}
\newcommand{\natswith}{\nats_{0}}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\realspos}{\reals_{>0}}
\newcommand{\realsnonneg}{\reals_{\geq 0}}

\newcommand{\states}{\mathcal{X}}
\newcommand{\observs}{\mathcal{Y}}

\newcommand{\paths}{\Omega}
%\newcommand{\path}{\omega}

\newcommand{\power}{\mathcal{P}(\paths)}
\newcommand{\nonemptypower}{\power_{\emptyset}}
\newcommand{\events}{\mathcal{E}}
%\newcommand{\nonemptyevents}{\events^{\emptyset}}
\newcommand{\filter}[1][t]{\mathcal{F}_{#1}}
\newcommand{\eventst}[1][t]{\events_{#1}}

\newcommand{\processes}{\mathbb{P}}
\newcommand{\mprocesses}{\processes^{\mathrm{M}}}

\newcommand{\hmprocesses}{\processes^{\mathrm{HM}}}

\newcommand{\wprocesses}{\processes^{\mathrm{W}}}
\newcommand{\wmprocesses}{\processes^{\mathrm{WM}}}

\newcommand{\whmprocesses}{\processes^{\mathrm{WHM}}}

\newcommand{\lexp}{\underline{\mathbb{E}}_{\rateset,\mathcal{M}}}
\newcommand{\uexp}{\overline{\mathbb{E}}_{\rateset,\mathcal{M}}}

\newcommand{\lt}{\underline{T}}
\newcommand{\lbound}{L}

\newcommand{\gambles}{\mathcal{L}}
\newcommand{\gamblesX}{\gambles(\states)} 

\newcommand{\ind}[1]{\mathbb{I}_{#1}}

\newcommand{\rateset}{\mathcal{Q}}
\newcommand{\lrate}{\underline{Q}}

\newcommand{\asa}{\Leftrightarrow}
\newcommand{\then}{\Rightarrow}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\abs}[1]{\left\vert #1 \right\vert}

\newcommand{\coloneqq}{:\!=}

\newcommand{\opinset}{\,\,\widetilde{\in}\,\,}

\newcommand{\argmin}{\arg\min}

\newcommand{\exampleend}{\hfill$\Diamond$}

\newcommand{\ictmc}{{ICTMC}}

\def\presuper#1#2%
  {\mathop{}%
   \mathopen{\vphantom{#2}}^{#1}%
   \kern-\scriptspace%
   #2}

\makeatletter
\newcommand{\customlabel}[2]{%
   \protected@write \@auxout {}{\string \newlabel {#1}{{#2}{\thepage}{#2}{#1}{}} }%
   \hypertarget{#1}{\emph{#2}\!}
}
\makeatother

\title{Efficient Computation of Updated Lower Expectations for\\ Imprecise Continuous-Time Hidden Markov Chains}

% \author[1]{Thomas E. Krak\thanks{t.e.krak@uu.nl}}
% \author[2]{Jasper de Bock\thanks{jasper.debock@ugent.be}}
% \affil[1]{Universiteit Utrecht}
% \affil[2]{Ghent University}

%\renewcommand\Authfont{\flushleft\textsc}
%\renewcommand\Affilfont{\normalfont\normalsize}
%\setlength{\affilsep}{1em}

\author{Thomas Krak \and Jasper De Bock \and Arno Siebes}

%\author[*]{Thomas Krak}
%\author[$\dagger$]{Jasper De Bock}
%
%\affil[ ]{${}^*$\texttt{t.e.krak@uu.nl}}
%\affil[ ]{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof\\
%3584 CC Utrecht\\
%The Netherlands}
%
%\affil[ ]{}
%
%\affil[$\dagger$]{\texttt{jasper.debock@ugent.be}}
%\affil[ ]{Ghent University\\
%Department of Electronics and Information Systems\\
%Technologiepark -- Zwijnaarde 914 \\
%9052 Zwijnaarde \\ 
%Belgium}

%\author{\normalfont Thomas Krak
%\large\hfill\texttt{t.e.krak@uu.nl}}
%\affil{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof \\
%3584 CC Utrecht \\
%The Netherlands}
%\author{\normalfont Jasper De Bock\large\hfill\texttt{jasper.debock@ugent.be}}
%\affil{Ghent University\\
% Department of Electronics and Information Systems\\
%Technologiepark -- Zwijnaarde 914 \\
%9052 Zwijnaarde \\ 
%Belgium
%}
%\author{\normalfont Arno Siebes
%\large\hfill\texttt{a.p.j.m.siebes@uu.nl}}
%\affil{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof \\
%3584 CC Utrecht \\
%The Netherlands
%\vspace{-0.4cm}}
%\author{Thomas Krak and Jasper de Bock}


\begin{document}

% \author{{\bf Thomas E. Krak} \\ Utrecht}
% \address{Utrecht University}
% \curraddr{}
% \email{t.e.krak@uu.nl}
% \thanks{}

%\author{Jasper de Bock \\ Ghent}
%\address{Ghent University}

%\author{
	%{\bf Thomas E. Krak} \quad\quad {\bf Jasper de Bock} \\
%	Utrecht University \quad Ghent University \\
	%Department of Information and Computing Sciences \\
	%Princetonplein 5, De Uithof \\
	%3584 CC Utrecht \\
	%The Netherlands \\
%	\texttt{\quad\quad t.e.krak@uu.nl} \quad\quad \texttt{jasper.debock@ugent.be}
%\and
	%{\bf Jasper de Bock} \\
%	Ghent University \\
	%SYSTeMS Research Group \\
	%Technologiepark -- Zwijnaarde 914 \\
	%9052 Zwijnaarde \\ 
	%Belgium \\
%	\texttt{jasper.debock@ugent.be}
%}
\date{}
\maketitle

% \noindent
% {\it Ghent University, Data Science Lab, Technologiepark -- Zwijnaarde 914, 9052 Zwijnaarde, Belgium}


\begin{abstract}
Lorem ipsum.
\end{abstract}

\section{Introduction}\label{sec:introduction}

A continuous-time Markov chain (CTMC) is a stochastic model that describes the evolution of a dynamical system under uncertainty. Specifically, it provides a measure of the uncertainty of how such a system might move through a discrete state-space, as time elapses in a continuous fashion.

A continuous-time \emph{hidden} Markov chain (CTHMC), then, is a stochastic model that contains a continuous-time Markov chain as a latent variable---that is, the actual realised behaviour of the system cannot be directly observed. Such a model furthermore incorporates random \emph{output} variables, which in some sense depend on the current state that the system is in, and it is rather realisations of these variables that one observes. Through this stochastic dependency between the output variables and the states in which the system might be, one can perform inferences about quantities of interest that depend on these states---even though they have not been, or cannot be, observed directly.

It should be clear from the above that CTHMC's are essentially the continuous-time analogue of the well-known (discrete-time) \emph{hidden Markov models} (HMM's). This HMM model class has many successful applications in modelling systems where the ``time'' dimension is discrete, for instance in predicting sequences of characters in optical character recognition. In contrast, CTHMC's may be used to model systems where the time dimension is more naturally described as continuous, for instance in modelling the behaviour of biological systems over time. It was only relatively recently that an expectation-maximisation algorithm for parameter estimation in CTHMC's was first described in the literature REF. This same paper showed that CTHMC's outperformed the previous state-of-the-art in certain disease-progress prediction tasks, specifically in modelling the development of glaucoma and Alzheimer's disease.

As should be clear from the terminology, the models described above all satisfy the eponymous Markov property. Loosely speaking, this property states that if we know the current state of the system, then any future behaviour will be independent of the entire history up to the current state. This simplifying assumption is typically rather critical to ensure that these models are computationally tractable to work with. Nevertheless, we would argue that it is also often an unrealistic assumption to impose on the model, and so it would seem to be of interest to robustify such models against cases where this assumption might not hold.

Recent work showed that---for ``non-hidden'' models---it is possible to robustify against this and other simplifying assumptions using \emph{imprecise continuous-time Markov chains} (ICTMC's) REF REF. Briefly, an ICTMC is a \emph{set} of continuous-time (and discrete-state) stochastic processes. Some of these processes are ``traditional'' time-homogeneous CTMC's. However, this set also contains much more complicated processes, which are non-homogeneous and do not satisfy the Markov property.

In this current work, then, we consider \emph{imprecise continuous-time hidden Markov chains}---a stochastic model analogous to a CTHMC, but where the latent CTMC is replaced by an ICTMC. A fully rigorous definition of such models is, due to length considerations, unfortunately outside the scope of this present paper. Instead, we introduce the model in a somewhat simplified fashion, and will focus in particular on practical aspects of the corresponding inference problem. That is, we provide results on how to efficiently compute lower expectations of functions on the state-space, given observed realisations of the output variables.

The paper is organised as follows. We introduce some notation in Section~\ref{sec:prelim}, and there also briefly recall the definitions and most important properties of ICTMC's. In particular, we there also summarise previous results on how to efficiently compute lower expectations for ICTMC's. In Section~\ref{sec:icthmc}, we introduce the hidden model on which we focus in this work. Next, in Section~\ref{sec:updating_model}, we discuss the problem of making inferences about the latent process, given some observations. Subsequently, in Section~\ref{sec:inference_algos}, we discuss how to efficiently solve this inference problem. We then compare and relate these results to other work in the literature, in Section~\ref{sec:related}, and finally close with conclusions and some pointers to future work, in Section~\ref{sec:conclusions}.

\section{Preliminaries}\label{sec:prelim}

We denote the reals as $\reals$, the non-negative reals as $\realsnonneg$, and the positive reals as $\realspos$. The natural numbers are denoted $\nats$, and we define $\natswith\coloneqq\nats\cup\{0\}$.

Since we are working in a continuous-time setting, a \emph{time-point} is an element of $\realsnonneg$, and these are typically denoted $t$ or $s$. We also make extensive use of finite sequences of time points $u\subset\realsnonneg$. These are taken to be ordered, so that they may be written $u=t_0,\ldots,t_n$, for some $n\in\natswith$, and such that then $t_i<t_j$ for all $i,j\in\{0,\ldots,n\}$ for which $i< j$. Such sequences are usually denoted $u$ or $v$, and we denote the entire set of them by $\mathcal{U}$. We write $u<t$ when all time points in $u$ are less than $t$, and similarly for other inequalities. Similarly, we write $u<v$ when $u$ properly comes before $v$. The sets of sequences that satisfy such inequalities are denoted $\mathcal{U}_{<t}$ or $\mathcal{U}_{<v}$, again extending intuitively to other inequalities. We finally define $\mathcal{U}_\emptyset\coloneqq \mathcal{U}\setminus\{\emptyset\}$. We use set-theoretic notation to operate on such sequences, while preserving the ordering; i.e., we write $u\cup v$ for the ordered union of $u$ and $v$.

Throughout, we consider some fixed, finite state space $\states$. A generic element of $\states$ will be denoted $x$. When considering the state-space at a specific time $t$, we write $\states_t\coloneqq\states$, and $x_t$ denotes a generic state-assignment at this time. When considering multiple time-points $u$ simultaneously, we denote the joint state-space as $\states_u\coloneqq\prod_{t_i\in u}\states_{t_i}$, a generic element of which is then denoted $x_u=(x_{t_0},\ldots,x_{t_n})$.

For any $u\in\mathcal{U}_\emptyset$, we denote with $\gambles(\states_u)$ the set of all real-valued functions on $\states_u$. We endow these function spaces with the $L^\infty$-norm, i.e. the norm $\norm{f}$ of any $f\in\gambles(\states_u)$ is defined to be $\norm{f}\coloneqq\norm{f}_\infty=\max\{\abs{f(x_u)}\,:\,x_u\in\states_u\}$.

\subsection{Imprecise Continuous-Time Markov Chains}

We here briefly recall the most important properties of imprecise continuous-time Markov chains (ICTMC's), following the definitions and results of Reference BIG PAPER. For reasons of brevity, we provide these definitions in a largely intuitive, non-rigorous manner, and refer the interested reader to this earlier work for an in-depth treatise on the subject.

An ICTMC will be defined below as a specific set of \emph{continuous-time stochastic processes}. Simply put, a continuous-time stochastic process is a joint probability distribution over random variables $X_t$, for each time $t\in\realsnonneg$, where each random variable $X_t$ takes values in $\states$. If such a stochastic process $P$ satisfies the \emph{Markov property}---see Equation~\eqref{eq:Markov_property} below---then $P$ is called a \emph{continuous-time Markov chain} (CTMC). The Markov property states that, for time points $t,s\in\realsnonneg$ such that $t\leq s$, and for any sequence of time points $u\in\mathcal{U}_{<t}$, it holds that
\begin{equation}\label{eq:Markov_property}
P(X_s\,\vert\,X_t=x_t,X_u=x_u) = P(X_s\,\vert\,X_t=x_t)\,.
\end{equation}
Intuitively, this means that once we know the state $x_t$ obtained at time $t$, the probability distribution over any state $X_s$ in the future---with respect to $t$---is independent of the history $x_u$ at time points $u$ that precede $t$.

Since we want to ultimately describe \emph{sets} of stochastic processes, it will be convenient to have a way to numerically parameterise such a CTMC---or more generally, such a continuous-time stochastic process. To this end, we require two different kinds of parameters. First of all, we need the specification of the initial distribution $P(X_0)$ over the state at time zero; this simply requires the specification of some probability mass function on $\states_0$.

The second type of parameter that we need requires the concept of a \emph{rate matrix}. Such a rate matrix $Q$ is a real-valued $\lvert\states\rvert\times\lvert\states\rvert$ matrix, whose off-diagonal elements are non-negative, and whose every row sums to zero---thus, the diagonal elements are non-positive. Such a rate matrix may be interpreted as describing the ``rate of change'' of the conditional probability $P(X_s\,\vert\,X_t)$, when $s$ is close to $t$. Specifically, for small enough $\Delta\in\realspos$, we may write that
\begin{equation*}
P(X_{t+\Delta}\,\vert\,X_t) \approx \bigl[I + \Delta Q\bigr](X_t, X_{t+\Delta})\,,
\end{equation*}
for some rate matrix $Q$, where $I$ denotes the $\lvert\states\rvert\times\lvert\states\rvert$ identity matrix, and where $[I + \Delta Q](X_t,X_{t+\Delta})$ denotes the element at the $X_t$-th row and $X_{t+\Delta}$-th column of the matrix $I + \Delta Q$. In general, this rate matrix $Q$ may depend on the specific time $t$ at which this relationship is stated. This rate matrix---or, when appropriate, time-dependent family of rate matrices---parameterises the dynamic behaviour of an CTMC. When considering more general stochastic processes that do not satisfy the Markov property, this family of rate matrices may furthermore be \emph{history}-dependent.

Using this method of parameterisation, an \emph{imprecise continuous-time Markov chain} (ICTMC) is similarly parameterised using a \emph{set} of rate matrices $\rateset$, and a \emph{set} of initial distributions $\mathcal{M}$. Intuitively, the corresponding ICTMC, denoted $\mathbb{P}_{\rateset,\mathcal{M}}$, can be characterised as the set of all stochastic processes $P$ that satisfy $P(X_0)\in\mathcal{M}$ and, for every time $t\in\realsnonneg$ and for every history $x_u\in\states_u$, with $u\in\mathcal{U}_{<t}$, there is some $Q\in\rateset$ and some $\Delta\in\realspos$, such that
\begin{equation*}
P(X_{t+\Delta}\,\vert\,X_t,X_u=x_u) \approx \bigl[I + \Delta Q\bigr](X_t, X_{t+\Delta})\,.
\end{equation*}
So, intuitively, we take $\mathbb{P}_{\rateset,\mathcal{M}}$ as the set of all continuous-time stochastic processes whose dynamics can be described using the elements of $\rateset$, and whose initial distributions are consistent with $\mathcal{M}$. For a more rigorous definition of such ICTMC's, we refer the reader to REF BIG PAPER.

The lower expectation with respect to this set $\mathbb{P}_{\rateset,\mathcal{M}}$ is then defined as
\begin{equation*}
\underline{\mathbb{E}}_{\rateset,\mathcal{M}}[\cdot\,\vert\,\cdot] \coloneqq \inf\left\{ \mathbb{E}_P[\cdot\,\vert\,\cdot]\,:\, P\in\mathbb{P}_{\rateset,\mathcal{M}} \right\}\,,
\end{equation*}
where $\mathbb{E}_P[\cdot\,\vert\,\cdot]$ denotes the expectation with respect to the (precise) stochastic process $P$.

\subsubsection{Computing Lower Expectations for ICTMC's}\label{subsec:ICTMC_computations}

Because we want to focus in this paper on providing efficient methods of computation, we here briefly recall some previous results from Reference REF about how to compute lower expectations for ICTMC's. We focus in particular on how to do this for functions on a single time-point $t$. Note that for such functions, the set $\gamblesX=\gambles(\states_t)$ can be interpreted as the vector space $\reals^{\lvert\states\rvert}$, since $\states$ is finite. This allows us to treat these functions $f\in\gamblesX$ as $\lvert\states\rvert$-dimensional vectors, which in particular allows us to represent linear maps from $\gamblesX$ to $\gamblesX$ using matrices.

Now, from a computational viewpoint, it is useful to introduce the \emph{lower transition rate operator} $\lrate$ that corresponds to $\rateset$. This operator is a (non-linear) map from $\gamblesX$ to $\gamblesX$, which is defined for every function $f\in\gamblesX$ as
\begin{equation}\label{eq:lower_rate_is_inf}
\lrate f \coloneqq \inf\{ Qf\,:\, Q\in\rateset \}\,.
\end{equation}
Observe that, due to the definition of the infimum, we therefore have for every $x\in\states$ that
\begin{equation*}
[\lrate f](x) = \inf\{[Qf](x)\,:\,Q\in\rateset\} = \inf\left\{ \sum_{x'\in\states}Q(x,x')f(x')\,:\,Q\in\rateset \right\}\,.
\end{equation*}
Numerically, this makes the optimisation problem in Equation~\ref{eq:lower_rate_is_inf} somewhat easier to solve, since it allows us to perform this optimisation element-wise.

This lower transition rate operator $\lrate$ can be used to compute the lower expectation of any function $f\in\gamblesX$, in the following way. For any $t,s\in\realsnonneg$ such that $t\leq s$, it can be shown that REF, for large enough\footnote{We refer the reader to this earlier work for a theoretical bound on the minimum such $n$ that is required to ensure a given maximum error on the approximation in Equation~\eqref{eq:lower_exp_in_steps}. We here briefly note that this bound scales polynomially in every relevant parameter, and is in particular inversely proportional to this maximum error. This means that $\lexp[f(X_s)\,\vert\,X_t]$ is numerically computable in polynomial time, provided that $\rateset$ is such that Equation~\eqref{eq:lower_rate_is_inf} can also be solved in the same time-complexity order.} $n\in\nats$, and writing $\Delta\coloneqq \nicefrac{(s-t)}{n}$,
\begin{equation}\label{eq:lower_exp_in_steps}
\lexp[f(X_s)\,\vert\,X_t] \approx \bigl[I + \Delta\lrate\,\bigr]^nf\,.
\end{equation}
Concretely, this means that if one is able to solve the minimisation problem in Equation~\eqref{eq:lower_rate_is_inf}---which is relatively straightforward for ``nice enough'' $\rateset$---then one can also compute the (conditional) lower expectation using the expression in Equation~\ref{eq:lower_exp_in_steps}. For illustration, we do this by first computing $f_1'\coloneqq \lrate f$ using Equation~\eqref{eq:lower_rate_is_inf}, and then computing $f_1\coloneqq f + \Delta f_1'$. Next, we compute $f_2'\coloneqq \lrate f_1$, from which we obtain $f_2\coloneqq f_1 + \Delta f_2'$. Proceeding in this fashion, after $n$ steps we obtain
\begin{equation*}
f_n = [I+\Delta\lrate]f_{n-1} = \bigl[I+\Delta\lrate\bigr]^nf \approx \underline{\mathbb{E}}_{\rateset,\mathcal{M}}[f(X_s)\,\vert\,X_t]\,,
\end{equation*}
which is the quantity of interest.

Furthermore, the \emph{unconditional} lower expectation of any function $f\in\gamblesX$, at time $t\in\realsnonneg$, can be computed as
\begin{equation}\label{eq:unconditional_lower_exp}
\underline{\mathbb{E}}_{\rateset,\mathcal{M}}[f(X_t)] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}\bigl[\underline{\mathbb{E}}_{\rateset,\mathcal{M}}[f(X_t)\,\vert\,X_0]\bigr] = \inf\left\{ \sum_{x\in\states} p(x)\cdot\underline{\mathbb{E}}_{\rateset,\mathcal{M}}[f(X_t)\,\vert\,X_0=x]\,:\,p\in\mathcal{M}  \right\}\,,
\end{equation}
again using the results from Reference BIG PAPER. Thus, from a practical point of view, it suffices to first compute the conditional lower expectation $\underline{\mathbb{E}}_{\rateset,\mathcal{M}}[f(X_t)\,\vert\,X_0]$, using Equation~\eqref{eq:lower_exp_in_steps}. Once this quantity is obtained, it remains to compute the right-hand side of Equation~\eqref{eq:unconditional_lower_exp}, which again is relatively straightforward when $\mathcal{M}$ is ``nice enough''.

\section{Imprecise Continuous-Time Hidden Markov Chains}\label{sec:icthmc}

In this section, we construct the \emph{hidden} model that is the subject of this paper. Simply put, our aim is to augment the stochastic processes that were introduced in the previous section, by adding random \emph{output} variables $Y_t$ whose distribution depends on the state $X_t$ obtained at the same time point $t$.

As was mentioned in Section~\ref{sec:introduction}, the rigorous construction of such augmented processes is omitted from the present paper due to length considerations. The difficulty is essentially in the fact that continuous-time stochastic processes specify random variables $X_t$ for \emph{every} time point $t\in\realsnonneg$. A consequence of this is that one has to be somewhat careful to ensure that the complete construction remains ``well-behaved'' when adding random variables $Y_t$ at each of these time points.

However, we want to focus in this paper on the more practical aspect of solving the inference problem of interest, i.e., computing lower expectations on the state-space \emph{given some observations}. Therefore, it suffices for our present purposes to only augment the model at the time points at which these observations were made. In other words, we assume that we are given some finite sequence of time points, and we now only need to consider these time points in augmenting the model.

We introduce the notion of an \emph{observable model}, i.e., the distribution of the $Y_t$, in Section~\ref{sec:observs}. In Section~\ref{sec:aug_stochastic_processes} we then augment stochastic processes, as discussed in the previous section, with such observable models. In order to disambiguate the notation, we will henceforth denote stochastic processes as $P_\states$, to emphasise the fact that they are only concerned with the state-space. Using these augmented stochastic processes, we finally define the imprecise hidden model that is the subject of this paper, in Section~\ref{subsec:ICTHMC}.

\subsection{Observables}\label{sec:observs}

As mentioned above, we want to augment stochastic processes with ``observable random variables'' $Y_t$, whose distribution depends on the state $X_t$. We here consider the definition of the corresponding (conditional) distribution.

We want this definition to be fairly general, and in particular do not want to stipulate that $Y$ should be either a discrete or a continuous random variable. To this end, we simply consider some set $\observs$ to be the outcome space of the random variable. We then let $\Sigma$ be some ($\sigma$-)algebra on $\observs$. Finally, for each $x\in\states$, we consider some probability measure $P_{\observs\vert\states}(\cdot\vert x)$ on $(\observs,\Sigma)$, with respect to which the random variable $Y$ can be defined.

\begin{definition}[Observable Model]
An \emph{observable model} is a tuple $(\observs,\Sigma,P_{\observs\vert \states})$, where $\observs$ is an outcome space, $\Sigma$ is a ($\sigma$-)algebra on $\observs$, and, for every $x\in\states$, $P_{\observs\vert\states}(\cdot\vert x)$ is a (finitely additive) probability measure on $(\observs,\Sigma)$.
\end{definition}

When considering (multiple) explicit time points, we use notation analogous to that used for states; so, $\observs_t\coloneqq\observs$ for any time $t\in\realsnonneg$, and for any $u\in\mathcal{U}$, we write $\observs_u\coloneqq \observs_{t_0}\times\cdots\observs_{t_n}$. 

When considering the algebra $\Sigma$ at multiple time points, we let $\Sigma_u$ denote the set of events $O_u=O_{t_0}\times\cdots\times O_{t_n}$, constructed for all $O_{t_i}\in\Sigma$. The complete product ($\sigma$-)algebra is then denoted $\sigma(\Sigma_u)$, i.e., this is the ($\sigma$-)algebra that is generated by $\Sigma_u$. Intuitively, separately defining $\Sigma_u$ will be useful because it only contains conjunctive statements between time-points, whereas $\sigma(\Sigma_u)$ also contains statements with much more intricate dependencies between time points.

We then let $(\observs_u,\sigma(\Sigma_u),P_{\observs_u\vert\states_u})$ be the product probability space, where, for every $x_u\in\states_u$, $P_{\observs_u\vert\states_u}(\cdot\vert x_u)$ is the product measure over the $P_{\observs_{t_i}\vert\states_{t_i}}(\cdot\vert x_{t_i})=P_{\observs\vert\states}(\cdot\vert x_{t_i})$.

\subsection{Augmented Stochastic Processes}\label{sec:aug_stochastic_processes}
We will now use this notion of observable models to define augmented stochastic processes, which will be the stochastic model underlying---precise---continuous time \emph{hidden} stochastic processes. 

To this end, we will for the remainder of this section consider some fixed observable model $(\observs,\Sigma,P_{\observs\vert\states})$, some fixed continuous-time stochastic process $P_\states$, and some fixed, non-empty and finite sequence of time-points $u\in\mathcal{U}_{\emptyset}$ on which observations may take place. Our aim will be to construct a joint model $P$ which extends $P_\states$ by introducing observable random variables $Y_t$ for each $t\in u$, where each $Y_t$ is distributed according to $P_{\observs\vert\states}$ depending on the state $X_t$. Such a $P$ will be called an \emph{augmented stochastic process}.

In particular, we assume that $Y_t$ is conditionally independent of \emph{every} other variable in the model, given the state $X_t$. This means that the construction of the augmented process $P$ is relatively straightforward; we can simply multiply $P_{\observs\vert\states}(Y_t\,\vert\,X_t)$ with any distribution $P_\states(X_t,X_{s_0},\ldots,X_{s_m})$ to obtain the joint distribution including $Y_t$. That is,
\begin{equation*}
P(Y_t,X_t,X_{s_0},\ldots,X_{s_m}) = P_{\observs\vert\states}(Y_t\,\vert\,X_t)P_\states(X_t,X_{s_0},\ldots,X_{s_m})\,.
\end{equation*}
Similarly, when considering multiple observations at once---say the entire sequence $u=t_0,\ldots,t_n$---then we have
\begin{equation*}
P(Y_{t_0},\ldots,Y_{t_n},X_{t_0},\ldots,X_{t_n}) = P_\states(X_{t_0},\ldots,X_{t_n})\prod_{i=0}^n P_{\observs\vert\states}(Y_{t_i}\,\vert\,X_{t_i})\,.
\end{equation*}
Other distributions can be derived similarly, or through appropriate marginalisation from such joint distributions.

The augmented stochastic process $P$ that is obtained by this construction will be denoted
\begin{equation*}
P=P_{\observs\vert\states}\otimes P_\states\,,
\end{equation*}
for the specific observable model $P_{\observs\vert\states}$ and stochastic process $P_\states$ that were taken to be fixed in this section. The sequence of time points $u$ on which the observations take place is left implicit for notational brevity. This method of notation now allows us to introduce the imprecise hidden model that is the subject of this paper, as follows.

\subsection{Imprecise Continuous-Time Hidden Markov Chains}\label{subsec:ICTHMC}

An \emph{imprecise continuous-time hidden Markov chain} (ICTHMC) is a set of augmented stochastic processes, obtained by augmenting all processes in an ICTMC with some given observable model.
\begin{definition}[ICTHMC]\label{def:hidden_ictmc}
Consider any ICTMC $\mathbb{P}_{\rateset,\mathcal{M}}$, and any observable model $(\observs,\Sigma,P_{\observs\vert\states})$. Then, the corresponding \emph{imprecise continuous-time hidden Markov chain} $\mathcal{Z}$ is the set of augmented stochastic processes that is defined by
$\mathcal{Z} \coloneqq \left\{ P_{\observs\vert\states}\otimes P_{\states} \,:\, P_{\states}\in\mathbb{P}_{\rateset,\mathcal{M}}\right\}$.

The lower expectation of $\mathcal{Z}$ will be denoted $\underline{\mathbb{E}}_\mathcal{Z}$.
\end{definition}
Note that we leave the parameters $\mathcal{M}$, $\rateset$ and $P_{\observs\vert\states}$ implicit in the notation of the ICTHMC $\mathcal{Z}$---we will henceforth take these parameters to be fixed.

Furthermore, note that $\mathcal{Z}$ contains an augmented stochastic process $P_{\observs\vert\states}\otimes P_{\states}$ for every $P_{\states}\in\mathbb{P}_{\rateset,\states}$. Hence, it follows immediately that for any function $f\in\gambles(\states_v)$ that only depends on the state space $\states_v$, and for any $u\in\mathcal{U}$, we have that $\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\,\vert\,X_u]=\lexp[f(X_v)\,\vert\,X_u]$. 

Similarly, since the observable model $(\observs,\Sigma,P_{\observs\vert\states})$ is shared by all augmented processes in $\mathcal{Z}$, the (lower) expectation of functions that only depend on observations $Y_u$, given the states $X_u$ at these same time points, can be derived directly from the observable model itself. That is, for any\footnote{This is actually false, but we feel that the intuition behind the statement is worthwhile. In particular, this clearly does hold for indicator functions $\ind{O_u}(Y_u)$ on events $O_u\in\Sigma_u$, whence $\underline{P}_\mathcal{Z}(O_u\vert X_u)=P_{\observs\vert\states}(O_u\vert X_u)$.

The more general statement holds for functions for which the expectation can be defined, and for which the dependencies between the time-points $u$ are not ``too strong''---it might not hold for indicators on events $O_u\in\sigma(\Sigma_u)$ for example. Both notions are somewhat cumbersome to make precise given the level of generality at which we defined observable models, and the present lack of rigour in defining the augmented stochastic processes.} function $f:\observs_u\to\reals$, we have $\underline{\mathbb{E}}_\mathcal{Z}[f(Y_u)\,\vert\,X_u]=\mathbb{E}_{P_{\observs\vert\states}}[f(Y_u)\,\vert\,X_u]$.

\section{Updating the Model}\label{sec:updating_model}

In the context of \emph{hidden} (continuous-time) Markov chains, it is typically assumed that the state $X_t$ that is obtained by the process at time $t$, cannot be directly observed---hence the term ``hidden''. Rather, we can only observe realisations of the observable variable $Y_t$. The problem of interest is then typically to make inferences about this state $X_t$, given what we know about the value of the variable $Y_t$. More generally, we may be interested in the joint states $X_v$ for some time points $v\in\mathcal{U}_\emptyset$, given observations $Y_u$ at time points $u\in\mathcal{U}$; note that we do not necessarily require that $u=v$.

Suppose then that we have observed that some event $(Y_u\in O_u)$ has taken place, with $O_u\in\Sigma_u$. We here use the terminology that we \emph{update} our model with these observations, after which the updated model reflects our revised beliefs about some quantity of interest. These updated beliefs, about some function $f\in\gambles(\states_v)$, say, are then denoted
\begin{equation*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]\,,\quad\text{or similarly,}\quad\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\,\vert\,Y_u\in O_u]\,,
\end{equation*}
depending on whether we are considering a precise or an imprecise model.

Clearly, the notation that we use here is the same as what would be used for representing \emph{conditional} (lower) expectations. Indeed, when the event $(Y_u\in O_u)$ has strictly positive (lower) probability, it would seem rational to assume that the \emph{updated} belief corresponds to the \emph{conditional} belief---which, in the precise case, can be inferred by application of Bayes' rule. 

However, when this event has probability zero, but was nevertheless observed, the \emph{conditional} belief/expectation cannot be determined in the precise case, and is vacuous in the imprecise case. Nevertheless, we may in some situations still be able to \emph{update} our model in some rational way, to reflect our revised beliefs given this observation. This, then, explains the choice of terminology employed here. We will shortly give some specific examples where this is indeed possible.

\subsection{Observations with Positive (Upper) Probability}

As noted above, when our assertion $(Y_u\in O_u)$ about an observation at time points $u$ has positive probability, we can---in the precise case---update our model by application of Bayes' rule. The following gives a convenient expression for the updated expectation $\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]$, which makes use of the independence assumptions on augmented stochastic processes, as stipulated in Section~\ref{sec:aug_stochastic_processes}.

\begin{proposition}\label{prop:precise_conditioning_for_positive}
Let $P$ be an augmented stochastic process, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\Sigma_u$, and $f\in\gambles(\states_v)$. Then, the updated expectation is given by
\begin{equation*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u] \coloneqq \sum_{x_v\in\states_v}f(x_v)\frac{P(X_v=x_v, Y_u\in O_u)}{P(Y_u\in O_u)} = \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]}\,,
\end{equation*}
whenever $\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]>0$, and is undefined, otherwise.
\end{proposition}

Having defined above how to update all the precise models $P\in\mathcal{Z}$, we will now update the imprecise model through \emph{regular extension} CITE. This corresponds to simply discarding from $\mathcal{Z}$ those precise models that assign zero probability to $(Y_u\in O_u)$, updating the remaining models, and then computing the lower envelope over these updated remaining expectations.

\begin{definition}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\Sigma_u$, and $f\in\gambles(\states_v)$. Then, the updated lower expectation is defined through regular extension, by setting
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr] \coloneqq \inf\bigl\{ \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]\,:\, P\in\mathcal{Z},\, P(Y_u\in O_u)>0 \bigr\}\,,
\end{equation*}
whenever $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] >0$, and setting $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr]\coloneqq\min f$, otherwise.
\end{definition}

As is well known, the updated lower expectation that is obtained through regular extension, can be computed using the \emph{generalised Bayes' rule} CITE. We will shortly see why this alternative expression is useful from a computational perspective.
\begin{proposition}\label{prop:GBR_regular}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\Sigma_u$, and $f\in\gambles(\states_v)$. Then, if $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$, the quantity $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr]$ satisfies the generalised Bayes' rule,
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr] = \max\left\{\mu\in\reals\,:\, \lexp\bigl[P_{\observs\vert\states}(O_u\vert X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\}\,.
\end{equation*}
\end{proposition}

\subsection{Uncountable Outcome Spaces, Point Observations, and Probability Zero}\label{subsec:uncountable}

An important special case where observations have probability zero for all precise models, but where we can still make informative inferences, is when we have an uncountable outcome space $\observs$ and the observations are points $y_u\in\observs_u$. In this case, it is common practice CITE to define the updated expectation $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$ as the limit of \emph{conditional} expectations, where each conditioning event is an increasingly smaller region around this point $y_u$.

To make this concept practicable, we will henceforth assume that if $\observs$ is uncountable, then it is some set $\observs\subseteq\reals^d$, for some $d\in\nats$, and that $\Sigma$ is the restriction to $\observs$ of the Borel $\sigma$-algebra on $\reals^d$. Furthermore, we assume that $P_{\observs\vert\states}$ is $\sigma$-additive on $\Sigma$, and absolutely continuous with respect to Lebesgue measure $\lambda$ on $(\observs,\Sigma)$.

We also need some notation to denote the above-mentioned limit statements. To this end, for any function $g:\Sigma_u\to\reals$, any \emph{interior} point $y_u\in\observs_u$, and any $c\in\reals$, we write that $\lim_{B_u\to y_u}g(B_u)=c$ if for every sequence of open cubes $\{B_i\}_{i\in\nats}$ in $\Sigma_u$, centred on $y_u$ and satisfying $\lim_{i\to\infty}\lambda(B_i)=0$, the limit $\lim_{i\to\infty}g(B_i)$ exists and is equal to $c$---where $\lambda(B_i)$ is Lebesgue measure of $B_i\subseteq\observs_u$\footnote{Note that the requirement that $y_u$ is an interior point of $\observs_u$ ensures that at least one such sequence exists. Although this requirement is somewhat restrictive, the generalisation should be conceptually intuitive and straightforward---unfortunately, the formal generalisation quickly becomes cumbersome and, we feel, rather detracts from the intuition.}. 

We can now introduce the \emph{probability density function} corresponding to the measure $P_{\observs\vert\states}$. Using the above notation, for any $u\in\mathcal{U}_\emptyset$, we let $\phi_u:\observs_u\times\states_u\to\realsnonneg$ be the unique function that is defined, for all $x_u\in\states_u$ and $y_u\in\observs_u$, by
\begin{equation}\label{eq:density_is_limit}
\phi_u(y_u\vert x_u) \coloneqq \lim_{B_u\to y_u} \frac{P_{\observs_u\vert\states_u}(B_u\vert x_u)}{\lambda(B_u)}\,,
\end{equation}
whenever this limit exists, and by $\phi_u(y_u\vert x_u)\coloneqq 0$, otherwise, where we assume that $\frac{0}{0}=0$. Under the assumptions above, for every $O_u\in\sigma(\Sigma_u)$ and $x_u\in\states_u$, this function $\phi_u$ satisfies
\begin{equation}\label{eq:density_generates_measure}
P_{\observs_u\vert\states_u}(O_u\vert x_u) = \int_{O_u}\phi_u(y_u\vert x_u) \,\mathrm{d}y_u\,,
\end{equation}
where the integral is understood in the Lebesgue sense. In other words, $\phi_u(\cdot\,\vert x_u)$ is the conditional probability density function associated with the measure $P_{\observs_u\vert\states_u}(\cdot\vert x_u)$.

The updated (precise) expectation for any process $P$ can now be defined as
\begin{equation*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u] \coloneqq \lim_{B_u\to y_u} \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in B_u]\,,
\end{equation*}
whenever this limit exists, and is undefined, otherwise. This limit can be shown to exist exactly when $\mathbb{E}_P[\phi_u(y_u\vert X_u)]>0$. We now have the following (essentially well-known) result.

%$(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})$ around this point $y_u$. Under our assumption that the conditional density $\phi(y_u\vert X_u)$ is continuous, this yields the following result.

\begin{proposition}\label{prop:precise_bayes_rule_densities}
Let $(\observs,\Sigma,P_{\observs\vert\states})$ be an observable model satisfying the assumptions above, let $P$ be an augmented stochastic process, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, and $f\in\gambles(\states_v)$. Then, for every $y_u\in\observs_u$, if $\mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]>0$,
\begin{equation}\label{eq:updated_expectation_is_limit}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u] = \lim_{B_u\to y_u} \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in B_u] = \frac{\mathbb{E}_P[f(X_v)\phi_u(y_u\vert X_u)]}{\mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]}\,.
\end{equation}
\end{proposition}
The right-hand side of Equation~\eqref{eq:updated_expectation_is_limit} is, of course, the well-known Bayes' conditioning(/updating) rule for mixtures of densities. 

The imprecise model will again be updated using regular extension; discarding the precise models for which the updated expectation is undefined, and computing the lower envelope over the remainder.
\begin{definition}
Let $(\observs,\Sigma,P_{\observs\vert\states})$ be an observable model satisfying the assumptions above, let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, the updated lower expectation is given by 
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] \coloneqq \inf\{\mathbb{E}_P[f(X_v)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}, \mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]>0\}\,,
\end{equation*}
whenever $\overline{\mathbb{E}}_\mathcal{Z}[\phi_u(y_u\vert X_u)] >0$, and by $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u=y_u\bigr]\coloneqq\min f$, otherwise.
\end{definition}

Similar to the results in Section REF, this updated lower expectation can be computed by means of the generalised Bayes' rule for mixtures of densities, as follows.

\begin{proposition}\label{prop:GBR_for_densities_lower_zero}
Let $(\observs,\Sigma,P_{\observs\vert\states})$ be an observable model satisfying the assumptions above, let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\uexp[\phi_u(y_u\vert X_u)]>0$,
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] = \max\left\{\mu\in\reals\,:\, \lexp\bigl[\phi_u(y_u\vert X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\}\,.
\end{equation*}
\end{proposition}
%
%\begin{proposition}\label{prop:GBR_for_densities}
%Suppose that $\observs$ is uncountable. Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}_{<v}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\lexp[\phi_u(y_u\vert X_u)]>0$,
%\begin{equation*}
%\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] = \inf\{\mathbb{E}_P[f(X_v)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \phi_u(y_u\vert X_u)$ in that lemma's statement, and applying Proposition~\ref{prop:precise_bayes_rule_densities} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$.
%\end{proof}

%%% ATTN: I'm removing the below proposition since it's somewhat outside the scope of where this paper is heading (and in fact, isn't specific to ICT(H)MC's at all). Might put back in for extended version though.

%So, we know from the above that each of the updated precise models is interpreted as a limit of updated models, and furthermore that the updated imprecise model corresponds to the lower envelope over these limits. One might then wonder, at this point, whether the updated imprecise model itself corresponds to a limit of updated imprecise models. It turns out that this is indeed the case, provided that $\lexp[\phi_u(y_u\vert X_u)]>0$.
%
%\begin{proposition}\label{prop:GBR_for_densities_is_limit_if_continuous}
%Let $(\observs,\Sigma,P_{\observs\vert\states})$ be an observable model satisfying the assumptions above, let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\lexp[\phi_u(y_u\vert X_u)]>0$,
%\begin{align*}
%\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u=y_u] %&= \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] \geq 0\right\} \\
% &= \lim_{B_u\to y_u}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in B_u]
%\end{align*}
%\end{proposition}

\section{Inference Algorithms}\label{sec:inference_algos}

In the previous section, we have seen that we can use the generalised Bayes' rule for updating our ICTHMC with some given observations. From a computational point of view, this is particularly useful because, rather than having to solve the non-linear optimisation problem of computing
\begin{equation*}
\inf\bigl\{\mathbb{E}_P[f(X_v)\vert Y_u\in O_u]\,:\, P\in\mathcal{Z},P(Y_u\in O_u)>0\bigr\}\,,
\end{equation*}
we can focus on evaluating the function
\begin{equation*}
\lexp\bigl[P_{\observs\vert\states}(O_u\vert X_u)\bigl(f(X_v) - \mu\bigr)\bigr]\,,
\end{equation*}
or its density-analogue, for some fixed value of $\mu$. Finding the updated lower expectation is then a matter of finding the maximum value of $\mu$ for which this quantity is non-negative. As we will discuss in Section~\ref{sec:gbr}, this is a relatively straightforward problem to solve numerically.

Therefore, in order for this approach to be computationally tractable, we also require efficient algorithms to evaluate this quantity for a given value of $\mu$. In Section~\ref{sec:funcs_single_time}, we provide such an algorithm for the important case where the function $f$ depends only on a single time-point.

We start by generalising the problem so that these results are applicable both for observations of the form $(Y_u\in O_u)$, and for point-observations $(Y_u=y_u)$ in an uncountable outcome space. Writing $u=t_0,\ldots,t_n$, we note that the independence assumptions in Section~\ref{sec:aug_stochastic_processes} imply that
\begin{equation*}
P_{\observs\vert\states}(O_u\vert X_u) = \prod_{t_i\in u}P_{\observs\vert\states}(O_{t_i}\vert X_{t_i})\,,\quad\quad\text{and,}\quad\quad \phi(y_u\vert X_u) = \prod_{t_i\in u}\phi(y_{t_i}\vert X_{t_i})\,.
\end{equation*}
Hence, we can in general identify with these a collection of functions $g_{t_i}\in\gambles(\states_{t_i})$, $t_i\in u$, such that $g_{t_i}\geq 0$ for all $i\in\{0,\ldots,n\}$, and the problem of interest is now to evaluate
\begin{equation*}
\lexp\left[ \left(\prod_{i=0}^ng_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr) \right]\,.
\end{equation*}
In general, the computational complexity of evaluating this quantity depends both on the function $f\in\gambles(\states_v)$, and on how the time points $v$ relate to the time points $u$---whether we are performing inference ``into the future'' or ``into the past''. We treat some specific cases in the following sections.

\subsection{Solving the GBR}\label{sec:gbr}

As mentioned above, finding the maximum value of $\mu$ for which the function of interest in the generalised Bayes' rule is non-negative, is relatively straightforward numerically. This is because this function, parameterised in $\mu$, is very well-behaved. The proposition below explicitly states some of these properties. These are essentially well-known, and can also be found in other work REF REF REF. The statement below is therefore intended to briefly recall these properties, and is stated in the general form where we can also use it when working with densities.

\begin{proposition}\label{prop:GBR_properties}
Let $\mathbb{P}_{\rateset,\mathcal{M}}$ be an ICTMC, consider any $v\in\mathcal{U}_{\emptyset}$, any $f\in\gambles(\states_v)$, and, for all $t_i\in u$, any $g_{t_i}\in\gambles(\states_{t_i})$ such that $g_{t_i}\geq 0$. Let $G:\reals\to\reals$ be a function defined for all $\mu\in\reals$, as
\begin{equation*}
G(\mu) \coloneqq \lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\right]\,.
\end{equation*}
Then, this function: \customlabel{GBR:always:continuous}{(G1)} is continuous, \customlabel{GBR:always:monotone}{(G2)} is monotonically decreasing, \customlabel{GBR:always:concave}{(G3)} is concave, and \customlabel{GBR:always:root}{(G4)} has a root, i.e. $G(\mu)=0$ for some $\mu\in\reals$.

Furthermore, if $\lexp\bigl[\prod_{i=0}^n g_{t_i}(X_{t_i})\bigr] >0$, this function: 
\customlabel{GBR:low_pos:monotone}{(LG1)} is strictly monotonically decreasing, and \customlabel{GBR:low_pos:unique_root}{(LG2)} has a unique root.

If instead $\lexp\bigl[\prod_{i=0}^n g_{t_i}(X_{t_i})\bigr]=0$ but $\uexp\bigl[\prod_{i=0}^n g_{t_i}(X_{t_i})\bigr] >0$, then this function: \customlabel{GBR:up_pos:max_root}{(UG1)} has a maximum root $\mu_*$, \customlabel{GBR:up_pos:zero_before}{(UG2)} satisfies $G(\mu)=0$ for all $\mu\leq \mu_*$ and, \customlabel{GBR:up_pos:monotone}{(UG3)} is strictly monotonically decreasing for $\mu\geq \mu_*$.
\end{proposition}

Note that this function $G(\mu)$ in Proposition~\ref{prop:GBR_properties} can therefore behave in two essentially different ways. These correspond to the cases where the observed event has strictly positive probability for \emph{all} processes in the ICTHMC, and to where it only has positive probability for \emph{some} of these processes. These two different behaviours are graphically illustrated in Figure TODO.

**** TODO: two pictures to illustrate the function for different cases

However, note that in either case, the function is ``well-behaved'' enough to make finding its maximum root a fairly straightforward task. For instance, standard bisection algorithms can be straightforwardly applied here. Also note that, due to Propositions~\ref{prop:GBR_regular} and~\ref{prop:GBR_for_densities_lower_zero}, this maximum root will always be found in the interval $[\min f, \max f]$---this observation might be helpful in practice.

\subsection{Functions on a Single Time Point}\label{sec:funcs_single_time}

Having discussed in the previous section that finding the maximum root of the function $G(\mu)$ is relatively straightforward, it now remains to provide an efficient method to actually numerically \emph{evaluate} this function for a given value of $\mu$.

We focus on a particularly useful special case, which can be used to compute the updated lower expectation of a function $f\in\gambles(\states_s)$ on a single time point $s$, given observations at time points $u$. If $s\notin u$, then it will be notationally convenient to define $g_s\coloneqq f - \mu$, and to let $u'\coloneqq u\cup \{s\}$. We can then simply focus on computing
\begin{equation*}
\lexp\left[ \left(\prod_{i=0}^ng_{t_i}(X_{t_i})\right)\bigl(f(X_s) - \mu\bigr) \right] = \lexp\left[ \prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,.
\end{equation*}
On the other hand, if $s = t_i$ for some $t_i\in u$, we let $u'\coloneqq u$ and redefine $g_{t_i}$ as $\tilde{g}_{t_i}(x_{t_i})\coloneqq g_{t_i}(x_{t_i})\cdot (f(x_{t_i})-\mu)$---and then we immediately drop the $\tilde\,$-notation again. The point is simply to establish a uniform indexing notation over all time-points and functions. The right hand side of the above equality can now be computed using the following dynamic programming technique. 

For all $t_i\in u'$, we define auxiliary functions $g_{t_i}^+,g_{t_i}^-\in\gambles(\states_{t_i})$, as follows. Writing $u'=t_0,\ldots,t_{n+1}$, we define $g_{t_{n+1}}^+\coloneqq g_{t_{n+1}}^-\coloneqq g_{t_{n+1}}$. Then, for all $i\in\{0,\ldots,n\}$, define
\begin{equation*}
g_{t_i}^+(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
g_{t_i}(x_{t_i})\cdot\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})\geq 0$, and} \\
g_{t_i}(x_{t_i})\cdot\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})<0$,}
\end{array}\right.
\end{equation*}
and,
\begin{equation*}
g_{t_i}^-(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
g_{t_i}(x_{t_i})\cdot\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})\geq 0$, and} \\
g_{t_i}(x_{t_i})\cdot\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})<0$.}
\end{array}\right.
\end{equation*}
Clearly, backward recursion allows us to compute all these functions in a time-complexity order that is linear in the number of time points in $u'$. Furthermore, at each step, computing the quantities $\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}]$ and $\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}]$ can be done in polynomial time, due to the results in Reference BIG PAPER. In particular, these can be computed using Equation~\eqref{eq:lower_exp_in_steps} and the method described in Section~\ref{subsec:ICTMC_computations} above. So, the total complexity of computing all these functions is clearly polynomial. We now have the following result.
\begin{proposition}\label{prop:computing_product_funcs}
For all $t_i\in u'$, let $g_{t_i}$, $g_{t_i}^+$ and $g_{t_i}^-$ be as defined above. Then,
\begin{equation*}
\lexp\left[g_{t_0}^+(X_{t_0})\right] = \lexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,,\quad\quad\text{and,}\quad\quad\uexp\left[g_{t_0}^-(X_{t_0})\right] = \uexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,.
\end{equation*}
\end{proposition}
So, in order to evaluate the function of interest, it remains to compute $\lexp\left[g_{t_0}^+(X_{t_0})\right]$. Since $g_{t_0}^+$ is a function on a single time point $t_0$, this can again be done in polynomial time using the results from Reference BIG PAPER, and in particular, using Equation~\eqref{eq:unconditional_lower_exp} in Section~\ref{subsec:ICTMC_computations} above.

\section{Related Work}\label{sec:related}

\section{Conclusions and Future Work}\label{sec:conclusions}

**** The results in the previous section provided us with a way to tractably compute updated lower expectations of arbitrary functions on any single time point. Although this may seem restrictive, it immediately grants the possibility to compute updated lower expectations of arbitrary functions $f\in\gambles(\states_v)$, provided the time points $v$ come after the time points $u$ on which we are updating. This is due to the following result.

\begin{proposition}\label{prop:arbitrary_future_functions}
Consider any $\mu\in\reals$, $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}_{<v}$, $f\in\gambles(\states_v)$ and, for all $t_i\in u$, any $g_{t_i}\in\gambles(\states_{t_i})$ such that $g_{t_i}\geq 0$. Write $u=t_0,\ldots,t_n$. Then,
\begin{equation*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\right] = \lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\left(\lexp[f(X_v)\vert X_{t_n}] - \mu\right)\right]\,.
\end{equation*}
\end{proposition}
Due to this result, it suffices to first compute the quantity $\lexp[f(X_v)\vert X_{t_n}]$, which can in general be done using the results in Reference BIG PAPER. Since this conditional lower expectation is clearly a function on a single time point $t_n$, we can then apply the results from the previous section to compute the updated lower expectation.

\bibliographystyle{plain}
\bibliography{general.bib}

\newpage

\appendix

\section{Globally Required Proofs and Lemmas}

We provide the proof of Proposition~\ref{prop:GBR_properties} below; this is out of chronological order with respect to the main text, but it states a number of convenient properties of the function of interest for the Generalised Bayes' Rule, which are required in the proofs of some statements that appear before the statement of this proposition.

\begin{proof}{\bf of Proposition~\ref{prop:GBR_properties}~}
For brevity, define $g\in\gambles(\states_u)$ as $g(x_u)\coloneqq \prod_{i=0}^n g_{t_i}(x_{t_i})$ for all $x_u\in\states_u$.

For \ref{GBR:always:continuous}, i.e. continuity, consider any $\mu\in\reals$. We will prove that $G$ is continuous at $\mu$, or in other words, that for every sequence $\{\mu_i\}_{i\in\nats}\to\mu$ it holds that $\lim_{i\to\infty}G(\mu_i)=G(\mu)$. So, choose any sequence $\{\mu_i\}_{i\in\nats}\to\mu$, and consider the induced sequence of functions $\bigl\{g(X_u)\bigl(f(X_v) - \mu_i\bigr)\bigr\}_{i\in\nats}$ in $\gambles(\states_{u\cup v})$. Then, since $\{\mu_i\}_{i\in\nats}\to\mu$, clearly also $\lim_{i\to\infty}g(X_u)\bigl(f(X_v) - \mu_i\bigr)=g(X_u)\bigl(f(X_v) - \mu\bigr)$ (*** under the appropriate function norm). Using Lemma~\ref{lemma:limit_lexp_is_lexp_limit}, we therefore have
\begin{equation*}
\lim_{i\to\infty}\lexp[g(X_u)\bigl(f(X_v) - \mu_i\bigr)] = \lexp[g(X_u)\bigl(f(X_v) - \mu\bigr)]\,,
\end{equation*}
or in other words, that $\lim_{i\to\infty}G(\mu_i) = G(\mu)$. Since the sequence $\{\mu_i\}_{i\in\nats}$ was arbitrary, this concludes the proof.

We next prove \ref{GBR:always:monotone}, i.e. that $G$ is monotonically decreasing. To this end, fix any $P\in\mathbb{P}_{\rateset,\mathcal{M}}$. Then, by linearity of expectation,
\begin{align}\label{eq:gbr_linear_expansion}
\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] = \mathbb{E}_P[g(X_u)f(X_v)] - \mu\mathbb{E}_P[g(X_u)]\,.
\end{align}
Since by assumption $g\geq 0$, it must hold that $\mathbb{E}_P[g(X_u)]\geq 0$, and hence, that $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]$ is monotonically decreasing in $\mu$. Since this is true for all $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, we find that $G(\mu)$ is a lower envelope over monotonically decreasing functions, which must therefore be monotonically decreasing itself. This concludes the proof.

For \ref{GBR:always:concave}, i.e. concavity, fix any $\mu,\nu\in\reals$, and choose any $\lambda\in[0,1]$. Let $\mu'\coloneqq \lambda\mu + (1-\lambda)\nu$. We need to show that $\lambda G(\mu) + (1-\lambda)G(\nu) \leq G(\mu')$. To this end, fix any $\epsilon\in\realspos$. Then, there is some $P\in\mathbb{P}_{\rateset,\mathcal{M}}$ such that
\begin{equation*}
\mathbb{E}_P\left[g(X_u)\bigl(f(X_v) - \mu'\bigr)\right] - \epsilon < G(\mu').
\end{equation*}
By expanding the convex combination $\mu'$ using linearity of expectation, we find
\begin{align*}
 &\quad \mathbb{E}_P\left[g(X_u)\bigl(f(X_v) - \mu'\bigr)\right] \\
 &= \mathbb{E}_P\left[g(X_u)f(X_v)\right] - \mu'\cdot\mathbb{E}_P\left[g(X_u)\right] \\
 &= \mathbb{E}_P\left[g(X_u)f(X_v)\right] - \lambda\mu\cdot\mathbb{E}_P\left[g(X_u)\right] - (1-\lambda)\nu\cdot\mathbb{E}_P\left[g(X_u)\right] \\
 &= \bigl(\lambda + (1-\lambda)\bigr)\cdot\mathbb{E}_P\left[g(X_u)f(X_v)\right] - \lambda\mu\cdot\mathbb{E}_P\left[g(X_u)\right] - (1-\lambda)\nu\cdot\mathbb{E}_P\left[g(X_u)\right] \\
 &= \lambda\cdot\mathbb{E}_P\left[g(X_u)f(X_v)\right] - \lambda\mu\cdot\mathbb{E}_P\left[g(X_u)\right] +(1-\lambda)\cdot\mathbb{E}_P\left[g(X_u)f(X_v)\right] - (1-\lambda)\nu\cdot\mathbb{E}_P\left[g(X_u)\right] \\
 &= \lambda\cdot\mathbb{E}_P\left[g(X_u)\bigl(f(X_v) - \mu\bigr)\right] + (1-\lambda)\cdot\mathbb{E}_P\left[g(X_u)\bigl(f(X_v) - \nu\bigr)\right] \\
 &\geq \lambda\cdot\lexp\left[g(X_u)\bigl(f(X_v) - \mu\bigr)\right] + (1-\lambda)\cdot\lexp\left[g(X_u)\bigl(f(X_v) - \nu\bigr)\right] \\
 &= \lambda G(\mu) + (1-\lambda) G(\nu)\,,
\end{align*}
where the inequality follows from the fact that $\lambda$ and $(1-\lambda)$ are non-negative, and $P\in\mathbb{P}_{\rateset,\mathcal{M}}$---hence in particular $\lexp\leq\mathbb{E}_P$.
Combining with the earlier above inequality, we find
\begin{equation*}
\lambda G(\mu) + (1-\lambda) G(\nu) -\epsilon \leq \mathbb{E}_P\left[g(X_u)\bigl(f(X_v) - \mu'\bigr)\right] - \epsilon < G(\mu')\,.
\end{equation*}
Since the $\epsilon\in\realspos$ was arbitrary, this concludes the proof.

For statement \ref{GBR:always:root}, i.e. that it has at least one root, we distinguish two cases. First, assume that $\uexp[g(X_u)]=0$. Clearly, this implies that $\mathbb{E}_P[g(X_u)]=0$ for all $P\in\mathbb{P}_{\rateset,\mathcal{M}}$. Therefore, since $g\geq 0$, we must have that $\mathbb{E}_P[g(X_u)\vert X_v=x_v]=0$ for all $x_v\in\states_v$. By the law of iterated expectation, we therefore have
\begin{equation*}
\mathbb{E}_P[f(X_v)g(X_u)] = \mathbb{E}_P\bigl[f(X_v)\mathbb{E}_P[g(X_u)\vert X_v]\bigr] = 0\,,
\end{equation*}
and hence, by combining with Equation~\ref{eq:gbr_linear_expansion}, that $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]=0$. Since this is true for all $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, we clearly have that $G$ is identically zero for all choices of $\mu$ whenever $\uexp[g(X_u)]=0$ and hence, in this case it trivially has at least one root.

Suppose for the other case that $\uexp[g(X_u)]>0$, and set $\mu\coloneqq \min f$. Then for every $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, using the assumption $g\geq 0$,
\begin{equation*}
\mathbb{E}_P[g(X_u)f(X_v)] \geq \mathbb{E}_P[g(X_u)(\min f)] = \mu\mathbb{E}_P[g(X_u)]\,,
\end{equation*}
and hence, using Equation~\eqref{eq:gbr_linear_expansion}, we have $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0$. Since this is true for every $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, we find that $G(\mu)\geq 0$ for this choice of $\mu$. So, the function is non-negative at this $\mu$, and clearly, if it is zero, we are done.

Hence, we can assume without loss of generality that $G(\mu) > 0$. Because we also assumed that $\uexp[g(X_u)] > 0$, there must be some $P\in\mathbb{P}_{\rateset,\mathcal{M}}$ such that $\mathbb{E}_P[g(X_u)]>0$. Using this $P$, define
\begin{equation*}
\nu \coloneqq \frac{\mathbb{E}_P[g(X_u)f(X_v)]}{\mathbb{E}_P[g(X_u)]}\,.
\end{equation*}
For this same choice of $P$, we then have
\begin{equation*}
\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \nu\bigr)\bigr] = \mathbb{E}_P[g(X_u)f(X_v)] - \nu\mathbb{E}_P[g(X_u)] = 0\,,
\end{equation*}
using the choice of $\nu$ to establish the second equality. Since $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, we now have
\begin{equation*}
G(\nu) \leq \mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \nu\bigr)\bigr] = 0\,,
\end{equation*}
and since we know that $G$ is monotonically decreasing, that $\mu\leq \nu$. Since we also know that $G$ is continuous, by the intermediate value theorem, there must now be some $\mu'\in [\mu,\nu]$ such that $G(\mu') = 0$. This concludes the proof that $G$ has at least one root.

We next prove \ref{GBR:low_pos:monotone}, i.e. \emph{strict} monotonicity under the assumption that $\lexp[g(X_u)]>0$. Clearly, this assumption implies that $\mathbb{E}_P[g(X_u)]>0$ for all $P\in\mathbb{P}_{\rateset,\mathcal{M}}$, which, using Equation~\ref{eq:gbr_linear_expansion}, implies that $G$ is a lower envelope over strictly monotonically decreasing functions that each have a constant derivative in $\mu$---the latter property is notable because this prevents the formation of accumulation points, towards some lower bound, as $\mu$ is increased. This therefore implies that $G$ is strictly monotonically decreasing itself.

For statement \ref{GBR:low_pos:unique_root}, i.e. that $G$ has a \emph{unique} root under the assumption that $\lexp[g(X_u)]>0$, note that we already know that $G$ has at least one root, i.e. $G(\mu)=0$ for some $\mu\in\reals$. By combining with statement \ref{GBR:low_pos:monotone}, i.e. strict monotonicity under the assumption that $\lexp[g(X_u)]>0$, the uniqueness of this root follows immediately.

We do not explicitly prove properties \ref{GBR:up_pos:max_root}, \ref{GBR:up_pos:zero_before} and \ref{GBR:up_pos:monotone}, as they are essentially included in the statement and proof of Lemma~\ref{lemma:general_regular_extension}. In particular, the statement of that lemma establishes that $G$ has a maximum root $\mu_*$ (and in fact identifies it), which proves \ref{GBR:up_pos:max_root}. The proof of that lemma notes as the penultimate step that $G(\mu)=0$ for all $\mu\leq \mu_*$, proving \ref{GBR:up_pos:zero_before}. The fact that $G(\mu)$ is strictly monotonically decreasing for $\mu\geq \mu_*$, i.e. \ref{GBR:up_pos:monotone}, follows straightforwardly by combining the argument for statement \ref{GBR:low_pos:monotone} with the construction made in the proof of Lemma~\ref{lemma:general_regular_extension}.
\end{proof}

\section{Proofs and Lemmas for the Results in Section~\ref{sec:updating_model}}

\begin{proof}{\bf of Proposition~\ref{prop:precise_conditioning_for_positive}~}
This follows from some simple manipulations:
\begin{align*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u] &= \sum_{x_v\in\states_v} f(x_v)\frac{P(X_v=x_v, Y_u\in O_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(X_v=x_v, X_u=x_u, Y_u\in O_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(Y_u\in O_u\,\vert\,X_v=x_v, X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(Y_u\in O_u\,\vert\,X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_{u\cup v}\in\states_{u\cup v}} f(x_v)\frac{P(Y_u\in O_u\,\vert\,X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{P(Y_u\in O_u)} \\
 &= \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]}\,,
\end{align*}
where the first equality is by definition, the second equality from the law of total probability, the third by the basic properties of probability, the fourth using the independence property in the definition of augmented stochastic processes, the sixth is simple rearrangement of terms, the seventh is by definition of expectation, and the final equality **** is also trivial (basic properties, total probability, definition expectation) ***.
\end{proof}

The following lemma states a more general version of the result that the generalised Bayes' rule computes the updated lower expectation of a model under regular extension.

\begin{lemma}\label{lemma:general_regular_extension}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $f\in\gambles(\states_v)$, and $g\in\gambles(\states_u)$ such that $g\geq 0$. Then, if $\uexp[g(X_u)]>0$, it holds that
\begin{equation*}
\max\left\{\mu\in\reals\,:\, \lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\} = \inf\left\{ \frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,:\,P\in\mathcal{Z}, \mathbb{E}_P[g(X_u)]>0 \right\}\,.
\end{equation*}
\end{lemma}
\begin{proof}
Let $\mathcal{P}\coloneqq \left\{ P\in\mathcal{Z}\,:\, \mathbb{E}_P[g(X_u)] > 0\right\}$, and note that $\mathcal{P}$ is non-empty due to the assumption that $\uexp[g(X_u)]>0$. For all $P\in\mathcal{P}$, define
\begin{equation*}
\mu_P \coloneqq \frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,,
\end{equation*}
and let $\mu_*$ be defined by
\begin{equation*}
\mu_* \coloneqq \inf\left\{\mu_P\,:\,P\in\mathcal{P} \right\}\,.
\end{equation*}
Now define the following function, parameterised in $\mu$,
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)] \coloneqq \inf\{\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]\,:\,P\in\mathcal{P} \}\,,
\end{equation*}
and consider $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$. We start by showing that this quantity is non-negative. To this end, fix any $\epsilon>0$. Then, there is some $P\in\mathcal{P}$ such that
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - \mu_*)] - \epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Using Equation~\eqref{eq:gbr_linear_expansion}, the function $\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]$ is monotonically decreasing in $\mu$. Therefore, and since $\mu_*\leq \mu_P$, we have
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)] - \epsilon \leq \mathbb{E}_P[g(X_u)(f(X_v) - \mu_*)] - \epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Due to the choice of $\mu_P$, we have $\mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)]=0$, and so we find that
\begin{equation*}
-\epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Since this is true for every $\epsilon>0$, we conclude that $0\leq \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$. Next, we show that this quantity is also non-positive, or in other words, that $\mu_*$ is a root of this function. 

To this end, fix any $\epsilon>0$, and define $\epsilon'\coloneqq \nicefrac{\epsilon}{\uexp[g(X_u)]}$; since by assumption $\uexp[g(X_u)]>0$, we have $\epsilon' >0$. Now consider $P\in\mathcal{P}$ such that
\begin{equation*}
\mu_P - \epsilon' < \mu_*\,.
\end{equation*}
Then, since $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)]$ is monotonically decreasing in $\mu$, we have
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] \leq \underline{\mathbb{E}}[g(X_u)(f(X_v) - (\mu_P - \epsilon'))]\leq \mathbb{E}_P[g(X_u)(f(X_v) - (\mu_P - \epsilon'))]\,.
\end{equation*}
Expanding the r.h.s. using linearity of expectation, and by the definition of $\mu_P$, we then have
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - (\mu_P - \epsilon'))] = \mathbb{E}_P[g(X_u)f(X_v)] - \mu_P\mathbb{E}_P[g(X_u)] + \epsilon'\mathbb{E}_P[g(X_u)] = \epsilon'\mathbb{E}_P[g(X_u)]\,,
\end{equation*}
and since $P\in\mathcal{P}\subseteq\mathcal{Z}$,
\begin{equation*}
\epsilon'\mathbb{E}_P[g(X_u)] \leq \epsilon'\uexp[g(X_u)]=\epsilon\,,
\end{equation*}
and so we find that
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] \leq \epsilon\,.
\end{equation*}
Since this is true for every $\epsilon>0$, and since we already know that $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$ is non-negative, we conclude that
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] = 0\,.
\end{equation*}

Now consider any $\mu' > \mu_*$. There must then be some $P\in\mathcal{P}$ such that $\mu_*\leq \mu_P < \mu'$, and furthermore,
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu')] \leq \mathbb{E}_P[g(X_u)(f(X_v) - \mu')] < \mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)] = 0\,,
\end{equation*}
where the strict inequality follows from the fact that $\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]$ is strictly monotonically decreasing, and $\mu_P<\mu'$. Since this is true for every $\mu'>\mu_*$, we conclude that
\begin{equation*}
\mu_* = \max\left\{ \mu\in\reals\,:\, \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)] \geq 0 \right\}\,.
\end{equation*}

Furthermore, as was essentially already established in the proof of case~\ref{GBR:always:root} in Proposition~\ref{prop:GBR_properties}, the function $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr]$ is identically zero for all $P\in\mathcal{Z}$ for which $\mathbb{E}_P[g(X_u)]=0$, that is, those $P\in\mathcal{Z}$ that are not in $\mathcal{P}$. Hence, we have 
\begin{equation*}
\lexp\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr] = \min\left\{\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)],\,0 \right\}\,,
\end{equation*}
from which we conclude that $\lexp\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr]$ is strictly negative whenever $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)]$ is. In other words, we have that
\begin{equation*}
\inf\left\{\frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,:\,P\in\mathcal{P}\right\} = \mu_* = \max\left\{ \mu\in\reals\,:\, \lexp[g(X_u)(f(X_v) - \mu)] \geq 0 \right\}
\end{equation*}
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_regular}~}
This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u]$ in that lemma's statement, and applying Proposition~\ref{prop:precise_conditioning_for_positive} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]$.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:precise_bayes_rule_densities}~}
**** Essentially a special case of the statement for the imprecise version.

{\bf Removed imprecise version, need special case}
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_for_densities_lower_zero}~}
This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \phi_u(y_u\vert X_u)$ in that lemma's statement, and applying Proposition~\ref{prop:precise_bayes_rule_densities} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$.
\end{proof}

%*************************
%
%
%We need the following result for the proofs of Propositions~\ref{prop:GBR_for_densities} and~\ref{prop:GBR_for_densities_is_limit_if_continuous}.
%\begin{lemma}\label{lemma:unique_root}
%Suppose that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] = 0$ for some $\mu,\mu'\in\reals$. Then, if $\lexp[\phi(y_u\vert X_u)]>0$, it holds that $\mu=\mu'$.
%\end{lemma}
%\begin{proof}
%Let $\mu,\mu'$ be any two roots of the function of interest, and assume without loss of generality that $\mu\leq\mu'$. Fix any $\epsilon>0$, and define $\epsilon^*\coloneqq \epsilon\cdot \lexp\left[\phi(y_u\vert X_u) \right]$. Since $\lexp[\phi(y_u\vert X_u)] > 0$, it clearly holds that $\epsilon^*>0$. Now, since
%\begin{equation*}
%0 = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] = \inf\left\{ \mathbb{E}_P\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] \,:\, P\in\wprocesses_{\rateset,\mathcal{M}}\right\}\,,
%\end{equation*}
%there must exist some process $P_\mu\in\wprocesses_{\rateset,\mathcal{M}}$ such that $0\leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*$.
%
%By linearity of expectation, we have for any $\nu$ that
%\begin{align*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\nu \bigr)\right] %&= \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) - \phi(y_u\vert X_u)\nu \right] %\\
% &= \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) \right] - \mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u)\nu \right] \\
% = \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) \right] - \nu\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]\,,
%\end{align*}
%and hence, we see that the function $\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\nu \bigr)\right]$ is monotonically decreasing in $\nu$. Since by assumption $\mu\leq\mu'$, and combining with the above, we see that
%\begin{equation*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*\,.
%\end{equation*}
%
%Furthermore, since $\mu'$ is also a root, we have that
%\begin{equation*}
%0 = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right]\,,
%\end{equation*}
%and hence, combining with the above,
%\begin{equation*}
%0 \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*\,,
%\end{equation*}
%which clearly implies that
%\begin{equation*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] - \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] < \epsilon^*\,.
%\end{equation*}
%Expanding this difference using linearity of expectation, we have
%\begin{align*}
% &\quad \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] - \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] 
% &= -\mu\mathbb{E}_{P_\mu}\left[\prod_{i=0}^n\phi(y_{t_i}\vert X_{t_i}) \right] + \mu'\mathbb{E}_{P_\mu}\left[\prod_{i=0}^n\phi(y_{t_i}\vert X_{t_i}) \right] \\
% = (\mu' - \mu)\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]\,,
%\end{align*}
%and hence that $(\mu' - \mu) < \nicefrac{\epsilon^*}{\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]}$. Since $\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right] \geq \lexp\left[\phi(y_u\vert X_u) \right]$, we find
%\begin{align*}
%(\mu' - \mu) &< \frac{\epsilon^*}{\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]} \leq \frac{\epsilon^*}{\lexp\left[\phi(y_u\vert X_u) \right]} = \frac{\epsilon\cdot\lexp\left[\phi(y_u\vert X_u) \right]}{\lexp\left[\phi(y_u\vert X_u) \right]} = \epsilon\,.
%\end{align*}
%Hence, we have found that $(\mu' - \mu) = \abs{\mu'-\mu} < \epsilon$, using the assumption $\mu\leq \mu'$ to establish the equality. Since this is true for every $\epsilon>0$, we conclude that indeed $\mu=\mu'$.
%\end{proof}
%
%\begin{proof}[Proof of Proposition~\ref{prop:GBR_for_densities}]
%Let $\mu$ be the unique root of $\lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]$.
%Then, clearly,
%\begin{equation*}
%0 = \lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] \leq \mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]\,,
%\end{equation*}
%for every $P\in\wprocesses_{\rateset,\mathcal{M}}$. By linearity of expectation,
%\begin{align*}
%\mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] &= \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]-\mu\mathbb{E}_P[\phi(y_u\vert X_u)]\,,
%\end{align*}
%and hence
%\begin{align*}
%0 &\leq \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] - \mu\mathbb{E}_P[\phi(y_u\vert X_u)] \\
%\mu\mathbb{E}_P[\phi(y_u\vert X_u)] &\leq \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] \\
%\mu &\leq \frac{\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]}{\mathbb{E}_P[\phi(y_u\vert X_u)]} = \mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,,
%\end{align*}
%which clearly implies that
%\begin{equation*}
%\mu \leq \inf\{\mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}\,.
%\end{equation*}
%
%So, $\mu$ is a lower bound on $\inf\{\mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}$. It remains to show that this bound is tight, or equivalently, that for every $\epsilon>0$, there is some $P\in\mathcal{Z}$, such that $\mathbb{E}_P[f(X_s)\vert Y_u=y_u]-\mu < \epsilon$. So, fix any $\epsilon>0$, and let $\epsilon^*\coloneqq \epsilon\cdot\lexp[\phi(y_u\vert X_u)]$. Since by assumption $\lexp[\phi(y_u\vert X_u)]>0$, we clearly have that $\epsilon^*>0$. Therefore, and since $\mu$ is a root of $\lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]$, there must exist some $P\in\wprocesses_{\rateset,\mathcal{M}}$ such that
%\begin{equation*}
%0 \leq \mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] < \epsilon^*\,.
%\end{equation*}
%Hence, by linearity of expectation,
%\begin{align*}
%\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]-\mu\mathbb{E}_P[\phi(y_u\vert X_u)] &< \epsilon^* \\
%\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] &< \mu\mathbb{E}_P[\phi(y_u\vert X_u)] + \epsilon^* \\
%\frac{\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]}{\mathbb{E}_P[\phi(y_u\vert X_u)]} &< \mu + \frac{\epsilon}{\mathbb{E}_P[\phi(y_u\vert X_u)]} \\
%\mathbb{E}_P[f(X_s)\vert Y_u=y_u] - \mu &< \frac{\epsilon^*}{\mathbb{E}_P[\phi(y_u\vert X_u)]} \leq \frac{\epsilon^*}{\lexp[\phi(y_u\vert X_u)]} = \epsilon\,.
%\end{align*}
%\end{proof}


The argument below proves the properties of the density $\phi_u$ that are claimed in Section~\ref{subsec:uncountable}; in particular, that $\phi_u$ satisfies Equation~\eqref{eq:density_generates_measure}.
\begin{proof}
Due to the assumptions in Section~\ref{subsec:uncountable}, and by the Radon-Nikodym theorem, we can associate with $P_{\observs\vert\states}$ a measurable function $\psi_u:\observs_u\times\states_u\to\realsnonneg$ such that, for all $x_u\in\states_u$ and $O_u\in\Sigma_u$,
\begin{equation*}
P_{\observs_u\vert\states_u}(O_u\vert x_u) = \int_{O_u}\psi_u(y_u\vert x_u) \,\mathrm{d}y_u\,.
\end{equation*}
Furthermore, since $\int_{\observs}\psi_u(y_u\vert x_u) \,\mathrm{d}y_u = P_{\observs_u\vert\states_u}(\observs_u\vert x_u)=1$, $\psi_u$ is absolutely integrable on $\observs_u$. Therefore, by the Lebesgue differentiation theorem, for $\lambda$-almost every $y_u\in\observs_u$, it holds that
\begin{equation*}
\psi_u(y_u\vert x_u) = \lim_{B_u\to y_u} \frac{1}{\lambda(B_u)} \int_{B_u} \psi(\tilde{y}_u\vert x_u)\,\mathrm{d}\tilde{y}_u\,.
\end{equation*}
At those $y_u\in\observs_u$ where this equality holds, we then find using the choice of $\psi_u$ that
\begin{equation*}
\psi_u(y_u\vert x_u) = \lim_{B_u\to y_u} \frac{1}{\lambda(B_u)} \int_{B_u} \psi(\tilde{y}_u\vert x_u)\,\mathrm{d}\tilde{y}_u = \lim_{B_u\to y_u} \frac{P_{\observs_u\vert\states_u}(B_u\vert x_u)}{\lambda(B_u)}\,.
\end{equation*}
In other words, the limit expression on the r.h.s. of this equality exists (at least) $\lambda$-almost everywhere---and hence, the same is true for the limit in Equation~\eqref{eq:density_is_limit}. Furthermore, this implies that $\phi_u(\cdot\,\vert x_u)$ differs from $\psi_u(\cdot\,\vert x_u)$ at most on a set of Lebesgue measure zero---the above r.h.s. limit might still exist even if the other equalities do not hold. Due to the choice of $\psi_u$, this immediately implies Equation~\eqref{eq:density_generates_measure}.
\end{proof}


We (probably still) need (some of) the following three results for the proof of Proposition~\ref{prop:precise_bayes_rule_densities}. *** Previously needed for statement of imprecise version, which I removed.

\begin{proposition}\label{prop:decomp}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $f\in\gambles(\states_v)$, and $g\in\gambles(\observs_u)$. Then,
\begin{equation*}
\underline{\mathbb{E}}_\mathcal{Z}\left[ f(X_v)g(Y_u) \right] = \lexp\left[ f(X_v)\mathbb{E}_{\observs\vert\states}[g(Y_u)\vert X_u] \right] 
\end{equation*}
\end{proposition}
\begin{proof}
Fix any $P\in\mathcal{Z}$. Then,
\begin{align*}
\mathbb{E}_P\bigl[ f(X_v)g(Y_u) \bigr] &= \mathbb{E}_P\bigl[ \mathbb{E}_P\left[ f(X_v)g(Y_u) \vert X_v,X_u \right] \bigr] \\
&= \mathbb{E}_P\bigl[ f(X_v)\mathbb{E}_P[ g(Y_u) \vert X_v,X_u ] \bigr] \\
&= \mathbb{E}_P\bigl[ f(X_v)\mathbb{E}_P[ g(Y_u) \vert X_u ] \bigr] \\
&= \mathbb{E}_{P_\states}\bigl[ f(X_v)\mathbb{E}_{\observs\vert\states}[ g(Y_u) \vert X_u ] \bigr] \,,
\end{align*}
where the first and second equality follow from the basic properties of expectation, the third equality is due to the independence assumptions in Section~\ref{sec:aug_stochastic_processes}, and the final equality uses the facts that the (outer) expectation is only concerned with states, and that the probability $P_{\observs\vert\states}$ is shared by all $P\in\mathcal{Z}$. Since this is true for every $P\in\mathcal{Z}$, the result now follows.
\end{proof}

\begin{lemma}\label{lemma:dirac_delta_gets_density_value}
Consider any sequence $\{\delta_i\}_{i\in\nats}\to 0^+$ in $\realspos$. Then, if $\phi(y_u\vert x_u)$ is continuous around $y_u$,
\begin{equation*}
\lim_{i\to\infty} \frac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u] = \phi(y_u\vert x_u)\,,
\end{equation*}
where $\lambda(\mathcal{B}_i)\coloneqq \lambda((y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2}))$ is Lebesgue measure of the region $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$.
\end{lemma}
\begin{proof}
Fix any $i\in\nats$, and note that
\begin{align*}
\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u] &= \int_{\observs_u}\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(y)\phi(y\vert x_u) dy 
= \int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\phi(y\vert x_u) dy\,.
\end{align*}
Let $\underline{\phi}_i\coloneqq \inf\{\phi(y\vert x_u):y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\}$ and $\overline{\phi}_i\coloneqq \sup\{\phi(y\vert x_u):y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\}$. Then, since $\underline{\phi}_i \leq \phi(y\vert x_u)\leq \overline{\phi}_i$ for all $y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$, we clearly have that
\begin{align*}
\underline{\phi}_i = \underline{\phi}_i\cdot\frac{\lambda(\mathcal{B}_i)}{\lambda(\mathcal{B}_i)} = \underline{\phi}_i\cdot\frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}dy &= \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\underline{\phi}_idy
 \\
 &\leq \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\phi(y\vert x_u) dy \\
 &\leq \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\overline{\phi_i} dy  = \overline{\phi}_i\,.
\end{align*}
Hence, for every $i\in\nats$, we have that $\underline{\phi}_i\leq\nicefrac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u]\leq\overline{\phi}_i$, and since also clearly $\underline{\phi}_i\leq \phi(y_u\vert x_u)\leq \overline{\phi}_i$, it follows that
\begin{equation*}
\abs{\phi(y_u\vert x_u) - \frac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u]} \leq \overline{\phi}_i - \underline{\phi}_i\,,
\end{equation*}
and so we see that it suffices to show that $\lim_{i\to\infty}\overline{\phi}_i - \underline{\phi}_i = 0$, or equivalently, that for every $\epsilon\in\realspos$, there is some $N\in\nats$ such that, for every $i>N$, $\overline{\phi}_i-\underline{\phi}_i < \epsilon$. So, fix any $\epsilon\in\realspos$. Since we assumed that $\phi(y\vert x_u)$ is continuous around $y_u$, there exists some $\delta\in\realspos$ such that, for every $\Delta\in(-\delta,\delta)$,
\begin{equation}\label{eq:dirac_bound_close_enough}
\abs{\phi(y_u\vert x_u) - \phi(y_u+\Delta\vert x_u)} < \frac{\epsilon}{4}\,.
\end{equation}
Consider this $\delta$. Then, since $\{\delta_i\}_{i\in\nats}\to 0^+$, there exists some $N\in\nats$ such that, for all $i>N$, $\delta_i < \delta$. Consider this $N$, and choose any $i>N$; it now remains to show that $\overline{\phi}_i-\underline{\phi}_i < \epsilon$.

Let $\underline{\phi}_*\coloneqq \inf\{ \phi(y\vert x_u):y\in(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2}) \}$ and $\overline{\phi}_*\coloneqq \sup\{ \phi(y\vert x_u):y\in(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2}) \}$. Then, since $\delta_i<\delta$, we clearly have $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\subset (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})$, and hence $\underline{\phi}_* \leq \underline{\phi}_i$ and $\overline{\phi}_i\leq \overline{\phi}_*$. Therefore, it suffices to show that $\overline{\phi}_*-\underline{\phi}_* < \epsilon$. Since it follows trivially from Equation~\eqref{eq:dirac_bound_close_enough} that $\phi(y_u\vert x_u)-\underline{\phi}_*\leq\nicefrac{\epsilon}{4}$ and $\overline{\phi}_*-\phi(y_u\vert x_u)\leq\nicefrac{\epsilon}{4}$, we have
\begin{equation*}
\overline{\phi}_* - \underline{\phi}_* = \overline{\phi}_* - \phi(y_u\vert x_u) + \phi(y_u\vert x_u) - \underline{\phi}_* \leq \frac{\epsilon}{4}+\frac{\epsilon}{4} = \frac{\epsilon}{2} < \epsilon\,,
\end{equation*}
which concludes the proof.
\end{proof}

\begin{lemma}\label{lemma:limit_lexp_is_lexp_limit}
Consider any $u\in\mathcal{U}_\emptyset$ and any convergent sequence $\{f_i\}_{i\in\nats}\to f$ in $\gambles(\states_u)$. Then, $\lim_{i\to\infty}\lexp[f_i(X_u)]=\lexp[f(X_u)]$.
\end{lemma}
\begin{proof}
We will show that, for every $\epsilon>0$, there is some $n\in\nats$ such that for all $i>n$, it holds that $\abs{\lexp[f_i(X_u)]-\lexp[f(X_u)]} < \epsilon$. So, consider any $\epsilon>0$, and define $\epsilon^*\coloneqq \nicefrac{\epsilon}{4}$. Because $\{f_i\}_{i\in\nats}\to f$, there is some $n\in\nats$ such that, for all $i>n$, it holds that $\norm{f_i - f}<\epsilon^*$. 

Consider now any $i>n$. Because $\norm{f_i - f}<\epsilon^*$, it clearly holds for every $P\in\wprocesses_{\rateset,\mathcal{M}}$ that $\abs{\mathbb{E}_P[f_i(X_u)] - \mathbb{E}_P[f(X_u)]}<\epsilon^*$, and hence
\begin{equation}\label{eq:lemma_converges_expectation_close}
\mathbb{E}_P[f_i(X_u)] - \epsilon^* < \mathbb{E}_P[f(X_u)] < \mathbb{E}_P[f_i(X_u)] + \epsilon^*\,.
\end{equation}
Furthermore, because $\lexp[\cdot]$ computes an infimum, there must be $P_i,P\in\wprocesses_{\rateset,\mathcal{M}}$ such that
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - \epsilon^* < \lexp[f_i(X_u)] \leq \mathbb{E}_{P}[f_i(X_u)]\,,
\end{equation*}
and,
\begin{equation*}
\mathbb{E}_{P}[f(X_u)] - \epsilon^* < \lexp[f(X_u)] \leq \mathbb{E}_{P_i}[f(X_u)]\,.
\end{equation*}
Applying Equation~\eqref{eq:lemma_converges_expectation_close} to the r.h.s. of these equalities, we find that
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - \epsilon^* < \mathbb{E}_{P}[f(X_u)] + \epsilon^*\,,\quad\text{and,}\quad \mathbb{E}_{P}[f(X_u)] - \epsilon^* < \mathbb{E}_{P_i}[f_i(X_u)] + \epsilon^*\,,
\end{equation*}
which when combined implies
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - 2\epsilon^* < \mathbb{E}_{P}[f(X_u)] < \mathbb{E}_{P_i}[f_i(X_u)] + 2\epsilon^*\,,
\end{equation*}
or in other words that $\abs{\mathbb{E}_{P_i}[f_i(X_u)] - \mathbb{E}_{P}[f(X_u)]} < 2\epsilon^*$.

Now, by the choice of $P_i$ and $P$, we have
\begin{align*}
 &\quad \abs{\lexp[f_i(X_u)]-\lexp[f(X_u)]} \\
 &\leq \abs{\lexp[f_i(X_u)] - \mathbb{E}_{P_i}[f_i(X_u)]} + \abs{\lexp[f(X_u)] - \mathbb{E}_{P}[f(X_u)]} + \abs{\mathbb{E}_{P_i}[f_i(X_u)] - \mathbb{E}_{P}[f(X_u)]} \\
 &< \epsilon^* + \epsilon^* + 2\epsilon^* = 4\epsilon^* = \epsilon\,.
\end{align*}
\end{proof}

%\begin{proof}{\bf of Proposition~\ref{prop:GBR_for_densities_is_limit_if_continuous}~}
%We will show that, for any $\{\delta_i\}_{i\in\nats}\to 0^+$, it holds that
%\begin{equation*}
%\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\}\,.
%\end{equation*}
%So, consider any sequence $\{\delta_i\}_{i\in\nats}\to 0^+$. Note first of all that, because $\lexp[\phi(y_u\vert X_u)]>0$, and due to continuity of $\phi(y_u\vert X_u)$, we must also have $\lexp[\phi(y_u + \Delta \vert X_u)]>0$ for all $\Delta$ in some interval $(-\delta,\delta)$. Therefore, and due to monotonicity of measure, it follows that we must also have $\lexp[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]]>0$ for all $i\in\nats$.
%
%Now, define an induced sequence $\{\mu_i\}_{i\in\nats}$ by
%\begin{equation*}
%\mu_i \coloneqq \underline{\mathbb{E}}_{\mathcal{Z}}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \max\left\{ \mu\in\reals : \underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu \bigr) \right] \geq 0\right\}\,,
%\end{equation*}
%and note in particular that then
%\begin{equation*}
%\underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu_i \bigr) \right] = 0\,,
%\end{equation*}
%for every $i\in\nats$. Hence, using Proposition~\ref{prop:decomp} we have that, for every $i\in\nats$,
%\begin{equation*}
%0 = \underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu_i \bigr) \right] = \lexp\left[ \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]\bigl( f(X_v) - \mu_i \bigr) \right]\,.
%\end{equation*}
%For every $i\in\nats$, let $\lambda(\mathcal{B}_i)\coloneqq \lambda((y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2}))$ denote Lebesgue measure of the region $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$.
%Then, by non-negative homogeneity, we have
%\begin{equation}\label{eq:all_steps_zero}
%0 = \lexp\left[\frac{1}{\lambda(\mathcal{B}_i)} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]\bigl( f(X_v) - \mu_i \bigr) \right]\,.
%\end{equation}
%
%Now, since $\mu_i = \underline{\mathbb{E}}_{\mathcal{Z}}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})]$, it follows that $\min f\leq \mu_i\leq \max f$ and therefore, that the sequence $\{\mu_i\}_{i\in\nats}$ exists in the (compact) interval $[\min f, \max f]$. Let now $\{\mu_{i_j}\}_{j\in\nats}$ be any convergent subsequence of $\{\mu_i\}_{i\in\nats}$, for which $\lim_{j\to\infty}\mu_{i_j}=:\mu_{j_*}\in[\min f,\max f]$---the existence of such a sequence is guaranteed by the Bolzano-Weierstrass theorem.
%
%Since the sequence $\{\mu_{i_j}\}_{j\in\nats}$ is convergent, we clearly also have that the sequence $\{f(X_v)-\mu_{i_j}\}_{j\in\nats}$ in $\gambles(\states_v)$ is convergent. Furthermore, as we know from Lemma~\ref{lemma:dirac_delta_gets_density_value}, the sequence 
%\begin{equation*}
%\left\{\frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right\}_{j\in\nats}
%\end{equation*}
%in $\gambles(\states_u)$ is convergent as well. Therefore in particular, we see that
%\begin{equation*}
%\lim_{j\to\infty} \frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_j}) = \phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})\,.
%\end{equation*}
%Using Lemma~\ref{lemma:limit_lexp_is_lexp_limit}, we therefore find
%\begin{equation*}
%\lim_{j\to\infty} \lexp\left[\frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_j})\right] = \lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})]\,,
%\end{equation*}
%and, using Equation~\eqref{eq:all_steps_zero}, that $\lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})] = 0$.
%
%Since we know from Proposition~\ref{prop:GBR_properties} that the function $\lexp[\phi(y_u\vert X_u)(f(X_v) - \mu)]$ has a unique root (because by assumption $\lexp[\phi(y_u\vert X_u)]>0$), say $\mu_*$, we conclude from this that $\mu_{j_*}=\mu_*$. Furthermore, since the convergent subsequence $\{\mu_{i_j}\}_{j\in\nats}$ was arbitrary, we find that $\mu_*$ is the limit of \emph{every} convergent subsequence of $\{\mu_i\}_{i\in\nats}$.
%
%We now first show that the original sequence $\{\mu_i\}_{i\in\nats}$ also converges, and that $\lim_{i\to\infty}\mu_i = \mu_{*}$. To this end, assume \emph{ex absurdo} that this is false. Then, there exists some $\epsilon\in\realspos$ such that, for every $N\in\nats$, there is some $k>N$ for which $\abs{\mu_k - \mu_{*}} \geq \epsilon$. Therefore, we can construct a subsequence $\{\mu_{i_k}\}_{k\in\nats}$ such that $\abs{\mu_{i_k}-\mu_{*}}\geq \epsilon$, for all $k\in\nats$. Using a similar argument to the above, this sequence is in the (compact) interval $[\min f, \max f]$ and therefore has a convergent subsequence $\{\mu_{i_{k_\ell}}\}_{\ell\in\nats}$, with $\lim_{\ell\to\infty}\mu_{i_{k_\ell}} =: \mu_{\ell_*}$ satisfying $\abs{\mu_{\ell_*} - \mu_{*}}\geq\epsilon$. However, the sequence $\{\mu_{i_{k_\ell}}\}_{\ell\in\nats}$ is clearly a convergent subsequence of $\{\mu_i\}_{i\in\nats}$ and hence, as we have just seen, we must have $\lim_{\ell\to\infty}\mu_{i_{k_\ell}} = \mu_{\ell_*} = \mu_{*}$. This contradicts the fact that $\abs{\mu_{\ell_*} - \mu_{*}}\geq\epsilon$ and hence, we can conclude that $\{\mu_i\}_{i\in\nats}$ converges to a $\mu_*$.
%
%In summary, we have shown that $\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})]$ exists and is equal to $\mu_*$. The remainder of the proof is now straightforward. Since we know from Proposition~\ref{prop:GBR_properties} that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right]$ is strictly monotonically decreasing in $\mu$, and that this function has a unique root---which we know is given by $\mu_*$---we must have that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] < 0$ for every $\mu>\mu_*$, 
%or in other words, that
%\begin{equation*}
%\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \mu_* = \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\}\,.
%\end{equation*}
%Since this holds for every sequence $\{\delta_i\}_{i\in\nats}\to 0^+$, we conclude that indeed, as claimed,
%\begin{align*}
% \underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u=y_u] %\\
%&= \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\} \\
% &= \lim_{\delta\to 0^+}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})] \,.
%\end{align*}
%\end{proof}

%\begin{remark}
%The below contains some notes / failed proof attempts to generalise the above result to hold under regular extension.
%
%********************
%
%We next establish that this limit $\mu_{i_*}$ is independent of the exact subsequence $\{\mu_{i_j}\}_{j\in\nats}$. To this end, consider any sequence $\{\epsilon_{j}\}_{j\in\nats}\to 0^+$. Then, for all $j\in\nats$, due to the definition of $\mu_{i_j}$, it follows from Proposition~\ref{prop:GBR_regular} that there is some $P_j\in\mathcal{Z}$ such that $\mathbb{E}_{P_j}[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]]>0$, and for which
%\begin{equation*}
%\mu_{i_j}\leq \nu_j\coloneqq \frac{\mathbb{E}_{P_j}\bigl[f(X_v)\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\bigr]}{\mathbb{E}_{P_j}[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]]} < \mu_{i_j} + \epsilon_j\,.
%\end{equation*}
%Since $\{\epsilon_j\}_{j\in\nats}\to 0^+$, and because $\{\mu_{i_j}\}_{j\in\nats}\to \mu_{i_*}$, this clearly implies that also $\{\nu_j\}_{j\in\nats}\to \mu_{i_*}$.
%
%Therefore, we see that also
%\begin{equation}\label{}
%\lim_{j\to\infty} \lexp\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = \lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{i_*})]
%\end{equation}
%Furthermore, for all $j\in\nats$, we clearly have
%\begin{align*}
% &\quad \lexp\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] \\
% &\leq
% &\quad \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] \\
% &= \frac{1}{\delta_{i_j}}\mathbb{E}_{P_j}\left[ f(X_v) \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right] - \frac{\nu_j}{\delta_{i_j}}\mathbb{E}_{P_j}\left[ \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right] \\
% &= 0\,,
%\end{align*}
%from which it follows that
%\begin{equation*}
%\lim_{j\to\infty} \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = 0\,.
%\end{equation*}
%Invoking Lemma~\ref{lemma:dirac_delta_gets_density_value} once more, and taking limits separately, we find
%\begin{equation}\label{eq:precise_limit_also_approaches}
% \lim_{j\to\infty} \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = \lim_{j\to\infty} \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right] = 0\,.
%\end{equation}
%
%*** 
%
%okay, let's see if I can set the below $\epsilon$ to something useful.
%
%possible options: 
%\begin{itemize}
%\item Construct a subsequence such that precise func is non-positive, then set $\epsilon=0$.
%\item Construct a subsequence such that $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]$ are all greater than a given value, set $\epsilon$ to that value (times $\Delta$).
%\item All smaller than some value? Not sure if that helps.
%\end{itemize}
%
%Assume $\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right]>0$, which implies $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]>0$, but now furthermore assume $\lim_{j\to\infty}\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]=0$ (or at least in every convergent subsequence, which exists). This is the worst case scenario.
%
%** Show that $\abs{\tilde{\nu}_j - \nu_j}\to 0$, which implies $\tilde{\nu}_j\to\mu_{i_*}$ from the right, which means that we can get strictly in between $\mu_{i_*}$ and $\mu'$, which gives us the desired slope since we know we are exactly zero at $\tilde{\nu}_j$ and are strictly monotonically decreasing in $j$'s precise function.
%
%Maybe force $j$ such that
%\begin{align*}
%\uexp\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*}) - \frac{1}{\delta_{i_j}}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_*})\right] < \epsilon\,, \\
%\text{and}, \\
%\uexp\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{*}) - \frac{1}{\delta_{i_j}}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{*})\right] < \epsilon
%\end{align*}
%This is definitely possible. Then take $\nu_j\to\mu_{i_*}$ as before. Write $\psi_j(y_u\vert X_u)$ for the delta, for convenience. We clearly have $\tilde{\nu}_j > \mu_*$.
%
%\begin{align*}
%0 &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\tilde{\nu}_j)\right] - \mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)(f(X_v)-\nu_j)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)f(X_v)-\psi_j(y_u\vert X_u)f(X_v)\right] - \tilde{\nu}_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)f(X_v)-\psi_j(y_u\vert X_u)f(X_v)\right] + \mu_{i_*}\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu_{i_*}\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &\quad\quad - \tilde{\nu}_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*})-\psi_j(y_u\vert X_u)f(X_v)\right] + (\mu_{i_*} - \tilde{\nu}_j)\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right]  \\
% &\quad\quad + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*})-\psi_j(y_u\vert X_u)(f(X_v)-\mu_{i_*})\right] \\
% &\quad\quad + (\mu_{i_*} - \tilde{\nu_j})\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + (\nu_j-\mu_{i_*})\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
%\end{align*}
%
%Actually maybe go the other way. Choose $P_j$ so that $\phi$ is satisfied: $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] >0$, and
%\begin{equation*}
%\mu_* \leq \tilde{\nu}_j < \mu_* + \epsilon_j\,.
%\end{equation*}
%This also has the advantage that due to continuity, $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] >0\Rightarrow \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)]>0$.
%
%\begin{align*}
%0 &= \mathbb{E}_{P_j}[\phi(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \mathbb{E}_{P_j}[f(X_v)\psi_j(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \mathbb{E}_{P_j}[f(X_v)\psi_j(y_u\vert X_u)] \\
% &\quad\quad - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] + \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u) - \phi(y_u\vert X_u)] \\
% &\quad\quad + \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)]
%\end{align*}
%Afschatbaar naar twee kanten, dus
%\begin{equation*}
%-\epsilon_j < \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)] < \epsilon_j\,.
%\end{equation*}
%We also know that
%\begin{equation*}
%0 = \lexp[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})] \leq \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})]
%\end{equation*}
%and
%\begin{align*}
% &\quad \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})] \\
% &= \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})]
%\end{align*}
%
%*******************
%
%New plan:
%\begin{itemize}
%\item Assume ex absurdo that $\mu_*>\mu_{i_*}$.
%\item Then we can approach the $\phi$ GBR strictly to the right of $\mu_{i_j}$, using some $\tilde{\nu}<\mu_*$, once the sequence is close enough to $\mu_{i_*}$;
%\item Far enough in the sequence, $\phi$ and $\psi_j$ become so close that we can cap the wiggle room of all precise processes;
%\item This yields a point $\tilde{\nu}>\mu_{i_j}$ for which the $\psi_j$ GBR is still non-negative, which contradicts the definition of $\mu_{i_j}$.
%\end{itemize}
%Assuming we're approaching $\mu_{i_*}$ from the left, we have
%\begin{equation*}
%\left\{\lexp[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)]\right\}_{j\in\nats} \to 0^-
%\end{equation*}
%
%Choose $P_j$ and $\nu_j$ as before. Then,
%\begin{align*}
%\lexp[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)] &\leq \mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)] \\
% &= \mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)(f(X_v)-\nu_j)] - (\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)] \\
% &= -(\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)] \\
% &= -(\mu_* - \nu_j)(\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)-\phi(y_u\vert X_u)] + \mathbb{E}_{P_j}[\phi(y_u\vert X_u)]) \\
% &= -(\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)-\phi(y_u\vert X_u)] - (\mu_* - \nu_j)\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]
%\end{align*}
%
%
%*******************
%
%
%***
%
%Now, consider any $\mu'>\mu_{i_*}$, and define $\Delta\coloneqq \nicefrac{(\mu'-\mu_{i_*})}{2}$. Because $\{\nu_j\}_{j\in\nats}\to\mu_{i_*}$, there is then some $N\in\nats$ such that, for all $j>N$, it holds that $\nu_j<\mu'-\Delta$. Next, define $\epsilon\coloneqq TODO$. Due to Equation~\eqref{eq:precise_limit_also_approaches}, there is then some $N'\in\nats$ such that, for all $j>N'$, it holds that
%\begin{equation*}
%\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right] < \epsilon\,.
%\end{equation*}
%Consider now any $j>\max\{N,N'\}$. Because $P_j\in\mathcal{Z}$, we then find that
%\begin{align*}
%\lexp\left[\phi(y_u\vert X_u)(f(X_v) - \mu')\right] &\leq \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \mu')\right] \\
% &= \mathbb{E}_{P_j}\left[f(X_v)\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% = \mathbb{E}_{P_j}\left[f(X_v)\phi(y_u\vert X_u)\right] - \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] &+ \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &< \epsilon + \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &= \epsilon - (\mu' - \nu_j)\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &< \epsilon - \Delta\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
%\end{align*}
%
%********************
%\end{remark}


\section{Proofs and Lemmas for the Results in Section~\ref{sec:inference_algos}}

We need the following lemma for the proof of Proposition~\ref{prop:computing_product_funcs}.
\begin{lemma}\label{lemma:product_func_induction}
For all $t_i\in u'$, let $g_{t_i}$, $g_{t_i}^+$ and $g_{t_i}^-$ be as defined in Section~\ref{sec:funcs_single_time}. Then, for all $t_i\in u'$,
\begin{equation*}
g_{t_i}^+ = \lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,, \quad\quad\text{and,} \quad\quad g_{t_i}^- = \uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,.
\end{equation*}
\end{lemma}
\begin{proof}
We provide a proof by induction. Clearly, the result is trivial for $t_i=t_{n+1}$. So, assume that it is true for $i$. We show that it is then also true for $i-1$ (with $i>0$).

We focus on $g_{t_{i-1}}^+$, and consider the two cases in its definition separately. So, consider any $x_{t_{i-1}}\in\states_{t_{i-1}}$. Then, if $g_{t_{i-1}}(x_{t_{i-1}})\geq 0$, we have
\begin{align*}
g_{t_{i-1}}^+(x_{t_{i-1}}) &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[g_{t_{i}}^+(X_{t_{i}})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
 &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[\lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
 &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\ 
 &= \lexp\left[g_{t_{i-1}}(x_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right]\,,
\end{align*}
where the first equality is by definition, the second is by the induction hypothesis, the third by iterated lower expectation (Proposition REF), and the final by non-negative homogeneity of lower expectation and the assumption that $g_{t_{i-1}}(x_{t_{i-1}})\geq 0$.

For the other case, assume that $g_{t_{i-1}}(x_{t_{i-1}})< 0$. Then,
\begin{align*}
g_{t_{i-1}}^+(x_{t_{i-1}}) &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[g_{t_{i}}^-(X_{t_{i}})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[\uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= -g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[-\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= \lexp\left[g_{t_{i-1}}(x_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right]\,,
\end{align*}
where the first equality is by definition, the second equality by the induction hypothesis, the third by iterated upper expectation (Proposition REF), the fourth by conjugacy of upper- and lower expectation, and the final by non-negative homogeneity of lower expectation and the assumption that $g_{t_{i-1}}(x_{t_{i-1}})<0$.

Since this covers both cases in the definition of $g_{t_{i-1}}^+(x_{t_{i-1}})$, we find that
\begin{equation*}
g_{t_{i-1}}^+(X_{t_{i-1}}) = \lexp\left[g_{t_{i-1}}(X_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}\right] = \lexp\left[\prod_{j={i-1}}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}\right]\,,
\end{equation*}
which concludes the proof for $g_{t_{i-1}}^+$. The proof for $g_{t_{i-1}}^-$ is completely analogous.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:computing_product_funcs}~}
By combining Lemma~\ref{lemma:product_func_induction} with iterated lower expectation (Proposition REF), we have
\begin{equation*}
\lexp\left[g_{t_0}^+(X_{t_0})\right] = \lexp\left[\lexp\left[\prod_{j=0}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_0}\right]\right] = \lexp\left[\prod_{j=0}^{n+1}g_{t_j}(X_{t_j})\right] = \lexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,,
\end{equation*}
and similarly for the upper expectation.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:arbitrary_future_functions}~}
Due to iterated lower expectation (Proposition REF), we have
\begin{equation*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\right] = \lexp\left[\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u\right]\right]\,.
\end{equation*}
Now consider any $x_u\in\states_u$. Then,
\begin{align*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] &= \lexp\left[\left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\lexp\left[\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_u=x_u\right] - \mu\right) \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_{t_n}=x_{t_n}\right] - \mu\right)\,,
\end{align*}
where the first equality is due to the basic properties of (lower) expectation, the second by non-negative homogeneity of lower expectation and the assumption that $g_{t_i}\geq 0$, the third by basic properties of lower expectation, and the fourth by the imprecise Markov property of ICTMC's (Proposition REF), and the assumption that $u<v$.

Since this is true for all $x_u\in\states_u$, we therefore have
\begin{align*}
 &\lexp\left[\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u\right]\right] \\
 &\quad\quad= \lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_{t_n}\right] - \mu\right)\right]\,.
\end{align*}
\end{proof}

%\section{Computing Functions that are Products}
%
%
%
%We here adopt a small change of notation compared to the above, to prevent having to deal with special cases. Consider any $u'\in\mathcal{U}_{\emptyset}$ such that $u'=t_0,t_1,\ldots,t_n$ with $n\geq 1$, define $u\coloneqq u'\setminus t_0$ and, for all $i\in\{1,\ldots,n\}$, consider any $g_i\in\gambles(\states_{t_i})$. Let $f\in\gambles(\states_u)$ be defined as $f(x_u)\coloneqq \prod_{i=1}^n g_i(x_{t_i})$, for all $x_u\in\states_u$, with $x_{t_i}\in x_u$ for all $i\in\{1,\ldots,n\}$. We now seek to compute
%\begin{align*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[f(X_u)\vert X_{t_0}\right] &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[f(X_{t_1},\ldots,X_{t_n})\vert X_{t_0}\right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[\prod_{i=1}^ng_i(X_{t_i})\vert X_{t_0}\right]\,.
%\end{align*}
%If all the $g_i$, $i\in\{1,\ldots,n\}$, satisfy $g_i\geq 0$, we can apply the same procedure as described for functions that are sums, exchanging sums for products where appropriate. However, the general case is slightly more involved since we cannot simply factorise out the non-negative functions (i.e. lower expectations only satisfy non-negative homogeneity). However, the below dynamic programming procedure does the trick.
%
%Define $\tilde{g}_n^+\coloneqq\tilde{g}_n^-\coloneqq g_n$ and, for all $i\in\{1,\ldots,n-1\}$, define
%\begin{equation*}
%\tilde{g}_i^+(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
%g_i(x_{t_i})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^+(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})\geq 0$, and} \\
%g_i(x_{t_i})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^-(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})<0$\,,} \\
%\end{array}\right.
%\end{equation*}
%and,
%\begin{equation*}
%\tilde{g}_i^-(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
%g_i(x_{t_i})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^-(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})\geq 0$, and} \\
%g_i(x_{t_i})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^+(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})<0$\,,} \\
%\end{array}\right.
%\end{equation*}
%for all $x_{t_i}\in\states_{t_i}$. Clearly, backward recursion (dynamic programming) allows us to compute all these functions in linear time w.r.t. $n$. We now have the following result.
%\begin{proposition}
%For any $i\in\{1,\ldots,n\}$, it holds that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_i^+(X_{t_i})\,\vert\, X_{t_{i-1}}] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right]\,,
%\quad\text{and,}\quad
%\overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_i^-(X_{t_i})\,\vert\, X_{t_{i-1}}] = \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right]\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%We provide a proof by (backward) induction. Clearly, the result is trivial for $i=n$. Now, assume that it is true for $i$ (with $i\geq 2$). We show that it is also true for $i-1$. Hence, we will show that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_{i-1}^+(X_{t_{i-1}})\,\vert\, X_{t_{i-2}}] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j={i-1}}^n g_j(X_{t_j}) \vert X_{t_{i-2}} \right]\,,
%\end{equation*}
%and similarly for the second statement. We start from the definition of $\tilde{g}_{i-1}^+$, and consider the two cases in that definition separately. So, consider any $x_{t_{i-1}}\in\states_{t_{i-1}}$. Then, if $g_{i-1}(x_{t_{i-1}}) \geq 0$, we find
%\begin{align*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) &= g_{i-1}(x_{t_{i-1}})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i}^+(X_{t_{i}}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% = g_{i-1}(x_{t_{i-1}})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ g_{i-1}(x_{t_{i-1}})\cdot\prod_{j=i}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] 
% = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i-1}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,,
%\end{align*}
%where the first equality is by definition, the second equality follows from the induction hypothesis, the third equality follows from non-negative homogeneity of lower expectation, and the last equality follows from the basic rules of (lower) expectation (i.e., $\underline{\mathbb{E}}[f(X,Y)\vert X=x]=\underline{\mathbb{E}}[f(x,Y)\vert X=x]$).
%
%If, on the other hand, $g_{i-1}(x_{t_{i-1}}) < 0$, we find
%\begin{align*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) = g_{i-1}(x_{t_{i-1}})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i}^-(X_{t_{i}}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% &= g_{i-1}(x_{t_{i-1}})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% = g_{i-1}(x_{t_{i-1}})\cdot -\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ - \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% &= \lvert g_{i-1}(x_{t_{i-1}})\rvert \cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ - \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ -\lvert g_{i-1}(x_{t_{i-1}})\rvert\cdot \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] 
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[  g_{i-1}(x_{t_{i-1}})\cdot \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,,
%\end{align*}
%where the first equality is by definition, the second equality follows from the induction hypothesis, the third equality follows from conjugacy of lower- and upper expectation, the fourth equality follows from the assumption that $g_{i-1}(x_{t_{i-1}}) < 0$, the fifth equality follows from non-negative homogeneity of upper expectation, and the last equality follows from the basic rules of (lower) expectation, as above.
%
%So, in both cases, we find that
%\begin{equation*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,.
%\end{equation*}
%Since this is true for every $x_{t_{i-1}}\in\states_{t_{i-1}}$, we now find by substitution that
%\begin{align*}
%&\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i-1}^+(X_{t_{i-1}}) \vert X_{t_{i-2}} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right] \vert X_{t_{i-2}} \right] \\
%=&~ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}, X_{t_{i-2}} \right] \vert X_{t_{i-2}} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-2}} \right]\,,
%\end{align*}
%where the second equality follows from the imprecise Markov property of $\wprocesses_{\rateset,\mathcal{M}}$, and the third equality follows from the rule of iterated lower expectation. This concludes the proof for the first statement. The proof for the second statement is the same, \emph{mutatis mutandis}.
%\end{proof}
%In particular, the above result implies that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_1^+(X_{t_1})\vert X_{t_0} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{i=1}^ng(X_{t_i})\vert X_{t_0} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ f(X_u) \vert X_{t_0} \right]\,,
%\end{equation*}
%and immediately suggest an algorithm with total runtime complexity $O(n\lvert\states\rvert C)$, where $C$ is again the time complexity of evaluating $L_{t_{i-1}}^{t_i}g_i$.


\end{document}
