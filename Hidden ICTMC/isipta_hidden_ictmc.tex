%\documentclass[10pt,a4paper]{paper}
%\documentclass[3p]{elsarticle}
%\documentclass[a4paper,reqno]{amsart}
\documentclass[twoside,11pt]{article}
\usepackage{isipta}


\usepackage[british]{babel}
%\usepackage[garamond]{mathdesign}

\usepackage{authblk}

\usepackage{hyperref,url}

\usepackage{mathptmx}
\usepackage{amsmath}
\usepackage{courier}
\usepackage{amssymb}
%\usepackage{mathtools}
%\usepackage{amsthm}

\usepackage{enumerate}
\usepackage{enumitem,multicol}
\usepackage{tikz}
\usepackage{nicefrac}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\usepackage{graphicx}

%\usepackage{eufrak}

%\usepackage{hyperref}
%\usepackage{pdfsync}
%\usepackage{authblk}

\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}

%\theoremstyle{definition}
%\newtheorem{exmp}{Example}%[section]
 
\renewcommand{\ttdefault}{cmtt}
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{definition}{Definition}
%\newtheorem{remark}{Remark}
%\newtheorem*{remark*}{Remark}

%\newtheorem{claim}{Claim}[theorem]
%\newtheorem*{claim*}{Claim}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}

% - macros

\newcommand{\nats}{\mathbb{N}}
\newcommand{\natswith}{\nats_{0}}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\realspos}{\reals_{>0}}
\newcommand{\realsnonneg}{\reals_{\geq 0}}

\newcommand{\states}{\mathcal{X}}
\newcommand{\observs}{\mathcal{Y}}

\newcommand{\paths}{\Omega}
%\newcommand{\path}{\omega}

\newcommand{\power}{\mathcal{P}(\paths)}
\newcommand{\nonemptypower}{\power_{\emptyset}}
\newcommand{\events}{\mathcal{E}}
%\newcommand{\nonemptyevents}{\events^{\emptyset}}
\newcommand{\filter}[1][t]{\mathcal{F}_{#1}}
\newcommand{\eventst}[1][t]{\events_{#1}}

\newcommand{\processes}{\mathbb{P}}
\newcommand{\mprocesses}{\processes^{\mathrm{M}}}

\newcommand{\hmprocesses}{\processes^{\mathrm{HM}}}

\newcommand{\wprocesses}{\processes^{\mathrm{W}}}
\newcommand{\wmprocesses}{\processes^{\mathrm{WM}}}

\newcommand{\whmprocesses}{\processes^{\mathrm{WHM}}}

\newcommand{\lexp}{\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}}
\newcommand{\uexp}{\overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}}

\newcommand{\lt}{\underline{T}}
\newcommand{\lbound}{L}

\newcommand{\gambles}{\mathcal{L}}
\newcommand{\gamblesX}{\gambles(\states)} 

\newcommand{\ind}[1]{\mathbb{I}_{#1}}

\newcommand{\rateset}{\mathcal{Q}}
\newcommand{\lrate}{\underline{Q}}

\newcommand{\asa}{\Leftrightarrow}
\newcommand{\then}{\Rightarrow}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\abs}[1]{\left\vert #1 \right\vert}

\newcommand{\coloneqq}{:\!=}

\newcommand{\opinset}{\,\,\widetilde{\in}\,\,}

\newcommand{\argmin}{\arg\min}

\newcommand{\exampleend}{\hfill$\Diamond$}

\newcommand{\ictmc}{{ICTMC}}

\def\presuper#1#2%
  {\mathop{}%
   \mathopen{\vphantom{#2}}^{#1}%
   \kern-\scriptspace%
   #2}

\title{Imprecise Continuous-Time Hidden Markov Chains}

% \author[1]{Thomas E. Krak\thanks{t.e.krak@uu.nl}}
% \author[2]{Jasper de Bock\thanks{jasper.debock@ugent.be}}
% \affil[1]{Universiteit Utrecht}
% \affil[2]{Ghent University}

%\renewcommand\Authfont{\flushleft\textsc}
%\renewcommand\Affilfont{\normalfont\normalsize}
%\setlength{\affilsep}{1em}

\author{Thomas Krak \and Jasper De Bock \and Arno Siebes}

%\author[*]{Thomas Krak}
%\author[$\dagger$]{Jasper De Bock}
%
%\affil[ ]{${}^*$\texttt{t.e.krak@uu.nl}}
%\affil[ ]{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof\\
%3584 CC Utrecht\\
%The Netherlands}
%
%\affil[ ]{}
%
%\affil[$\dagger$]{\texttt{jasper.debock@ugent.be}}
%\affil[ ]{Ghent University\\
%Department of Electronics and Information Systems\\
%Technologiepark -- Zwijnaarde 914 \\
%9052 Zwijnaarde \\ 
%Belgium}

%\author{\normalfont Thomas Krak
%\large\hfill\texttt{t.e.krak@uu.nl}}
%\affil{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof \\
%3584 CC Utrecht \\
%The Netherlands}
%\author{\normalfont Jasper De Bock\large\hfill\texttt{jasper.debock@ugent.be}}
%\affil{Ghent University\\
% Department of Electronics and Information Systems\\
%Technologiepark -- Zwijnaarde 914 \\
%9052 Zwijnaarde \\ 
%Belgium
%}
%\author{\normalfont Arno Siebes
%\large\hfill\texttt{a.p.j.m.siebes@uu.nl}}
%\affil{Utrecht University\\
%Department of Information and Computing Sciences\\Princetonplein 5, De Uithof \\
%3584 CC Utrecht \\
%The Netherlands
%\vspace{-0.4cm}}
%\author{Thomas Krak and Jasper de Bock}


\begin{document}

% \author{{\bf Thomas E. Krak} \\ Utrecht}
% \address{Utrecht University}
% \curraddr{}
% \email{t.e.krak@uu.nl}
% \thanks{}

%\author{Jasper de Bock \\ Ghent}
%\address{Ghent University}

%\author{
	%{\bf Thomas E. Krak} \quad\quad {\bf Jasper de Bock} \\
%	Utrecht University \quad Ghent University \\
	%Department of Information and Computing Sciences \\
	%Princetonplein 5, De Uithof \\
	%3584 CC Utrecht \\
	%The Netherlands \\
%	\texttt{\quad\quad t.e.krak@uu.nl} \quad\quad \texttt{jasper.debock@ugent.be}
%\and
	%{\bf Jasper de Bock} \\
%	Ghent University \\
	%SYSTeMS Research Group \\
	%Technologiepark -- Zwijnaarde 914 \\
	%9052 Zwijnaarde \\ 
	%Belgium \\
%	\texttt{jasper.debock@ugent.be}
%}
\date{}
\maketitle

% \noindent
% {\it Ghent University, Data Science Lab, Technologiepark -- Zwijnaarde 914, 9052 Zwijnaarde, Belgium}


\begin{abstract}
Lorem ipsum.
\end{abstract}

\section{Introduction}\label{sec:introduction}

\section{Preliminaries}

*** basic notatie

\subsection{State Space and Stochastic Processes}

*** blabla state space $\states$

\begin{definition}[Stochastic Process]
Bla
\end{definition}

\begin{definition}[Well-Behaved Stochastic Process]
Bla
\end{definition}

\begin{definition}[Transition Matrix]
Bla
\end{definition}

\begin{definition}[Rate Matrix]
Bla
\end{definition}

\begin{definition}[Outer-Partial Derivatives]
Bla
\end{definition}

\begin{proposition}
**** For w.b. processes, outer partials are non-empty, bounded and closed sets of rate-matrices.
\end{proposition}

\subsection{Imprecise Continuous-Time Markov Chains}

**** Hier herhaling definities en benodigde eerdere resultaten

\begin{definition}[ICTMC]
Bla *** maybe just focus on $\wprocesses_{\rateset,\mathcal{M}}$?
\end{definition}


\section{Imprecise Continuous-Time Hidden Markov Chains}

\subsection{Observables}

Consider an observable random variable $Y$ taking values in some set $\observs\subseteq\reals^d$, for some fixed $d\in\nats$. This variable is associated with an observable model, as follows.

\begin{definition}[Observable Model]
An \emph{observable model} is a tuple $(\observs,\Sigma,P_{\observs\vert \states})$, where $\observs$ is an outcome space, $\Sigma$ is some appropriate $\sigma$-algebra on $\observs$ (see below), and, for every $x\in\states$, $P_{\observs\vert\states}(\cdot\vert x)$ is a ($\sigma$-additive) probability measure on $(\observs,\Sigma)$ such that, furthermore, if $\observs$ is uncountable, $P_{\observs\vert\states}(\cdot\vert x)$ is absolutely continuous with respect to Lebesgue measure on $(\observs,\Sigma)$.
\end{definition}
If $\observs$ is at most countable, then we assume that $\Sigma$ is the discrete $\sigma$-algebra on $\observs$, i.e., the power set of $\observs$. Clearly, $P_{\observs\vert\states}(\cdot\vert x)$ can then be associated with a probability mass function on $\observs$: the restriction of $P_{\observs\vert\states}(\cdot\vert x)$ to $\{E\in\Sigma\,:\,\lvert E\rvert = 1\}$, which by slight abuse of notation we will simply denote $P_{\observs\vert\states}(\cdot\vert x)$. In that case, for any bounded function $f:\observs\to\reals$, we can express the conditional expectation, given any $x\in\states$, as
\begin{equation*}
\mathbb{E}_{\observs\vert\states}[f(Y)\vert X=x] \coloneqq \sum_{y\in\observs} f(y) P_{\observs\vert\states}(y\vert x)\,.
\end{equation*}

On the other hand, if $\observs$ is uncountable, then we will assume that $\Sigma$ is the restriction to $\observs$ of the Borel $\sigma$-algebra on $\reals^d$ and that, for every $x\in\states$, $P_{\observs\vert\states}(\cdot\vert x)$ is absolutely continuous with respect to Lebesgue measure $\lambda$ on $(\observs,\Sigma)$\footnote{Note that this imposes some mild regularity assumptions on the entire model $(\observs,\Sigma,P_{\observs\vert\states})$, rather than just on $P_{\observs\vert\states}$. For instance, it implies that we cannot choose $\observs$ to be the Cantor set. Regardless, such pathological examples should not really arise in practice, and so we do not consider this restriction to be problematic.}. By the Radon-Nikodym theorem CITE, we can then associate with $P_{\observs\vert\states}(\cdot\vert x)$ a measurable function $\phi(\cdot\vert x):\observs\to\realsnonneg$ such that, for every $O\in\Sigma$,
\begin{equation*}
P_{\observs\vert\states}(O\vert x) = \int_O\phi(y\vert x)dy\,,
\end{equation*}
where the integral is understood to be taken with respect to Lebesgue measure. In other words, $\phi(\cdot\vert x)$ is ``the''\footnote{It is only uniquely determined up to a $\lambda$-null set, but we assume that a specific one is chosen, which we denote $\phi(\cdot\vert x)$.} probability density function associated with $P_{\observs\vert\states}(\cdot\vert x)$. Therefore in particular, for any measurable function $f:\observs\to\reals$, we can express its conditional expectation, given any $x\in\states$, as
\begin{equation*}
\mathbb{E}_{\observs\vert\states}[f(Y)\vert X=x] \coloneqq \int_\observs f(y) dP_{\observs\vert\states}(y\vert x) = \int_\observs f(y)\phi(y\vert x)dy\,.
\end{equation*}

In the sequel, we will for convenience assume that these densities $\phi(\cdot\vert x)$ are chosen so that they are continuous---and that this is in fact possible. While being perhaps somewhat unsatisfying from a mathematical point of view, we feel that this assumption vastly improves the clarity with which we can state results and explain our lines of reasoning. Furthermore, although this assumption is somewhat restrictive theoretically---if one wants to purposefully construct pathological examples---it will arguably hold for every probability measure that one intends to use in practice. Finally, if one insists that this assumption should be dropped, then a slightly weaker version of all our results still holds---replacing ``for every $y\in\observs$'' statements, by ``for $\lambda$-almost every $y\in\observs$''; that is, all relevant statements then still hold outside a Lebesgue null-set.
%\begin{remark}
%Throughout this work, we want to leave open the choice of whether $\observs$ is taken to be finite, countable, or uncountable. To prevent excessive case-work in our definitions, and in the interest of brevity, we therefore stipulate the following. Whenever, in the sequel, we write something to the effect of ``...$P$ a $\sigma$-additive probability measure on $(\observs,\Sigma)$...'', we implicitly append ``...such that, when $\observs$ is uncountable, $P$ is absolutely continuous with respect to Lebesgue measure on $(\observs,\Sigma)$''. When this property is to be proven, rather than assumed, we will of course be explicit.
%\end{remark}

When considering (multiple) explicit time points, we use notation analogous to that used for states. In particular, $\observs_t\coloneqq\observs$ for any time $t\in\realsnonneg$, and for any $u\in\mathcal{U}$ with $u=t_0,\ldots,t_n$, we write $\observs_u\coloneqq \observs_{t_0}\times\cdots\observs_{t_n}$. We then let $(\observs_u,\Sigma_u,P_{\observs_u\vert\states_u})$ be the obvious product probability space, i.e., $\Sigma_u$ is the tensor-product $\sigma$-algebra over the $\Sigma_i$, and for every $x_u\in\states_u$, $P_{\observs_u\vert\states_u}(\cdot\vert x_u)$ is the product measure over the $P_{\observs_{t_i}\vert\states_{t_i}}(\cdot\vert x_{t_i})=P_{\observs\vert\states}(\cdot\vert x_{t_i})$.

\subsection{Augmented Stochastic Processes}\label{sec:aug_stochastic_processes}
We now move on to use this notion of observable models in defining augmented stochastic processes, which will be the stochastic model underlying---precise---continuous time \emph{hidden} stochastic processes. To this end, we will henceforth consider some fixed measurable space $(\observs,\Sigma)$ satisfying the assumptions discussed in Section REF. 

Similar to stochastic processes, such an augmented process is said to be in a certain state $x\in\states$ at each time $t\in\realsnonneg$, but now also outputs an observation $y\in\observs$ at each time $t$. This joint behaviour over time can therefore be described using a path $\omega:\realsnonneg\to\states\times\observs$, where $\omega(t)=(x_t,y_t)$ describes the state $x_t$ and observation $y_t$ that are obtained at time $t$. For any $u\in\mathcal{U}$, we let $\omega\vert_u$ denote the restriction of $\omega$ to $u$. Then for any $x_u\in\states_u$ and $y_u\in\observs_u$, we write $\omega\vert_u=(x_u,y_u)$ if, for all $t\in u$, $\omega(t)=(x_t,y_t)$. By slight abuse of notation, we also simply write $\omega\vert_u=x_u$ when the coordinate projection of $\omega\vert_u$ onto $\states_u$ equals $x_u$, and similarly for $\omega\vert_u=y_u$. In particular for the latter case, we write for any $O\in\Sigma$, that $\omega(t)\in O$ when the coordinate projection of $\omega(t)$ onto $\observs$ is in $O$. A similar interpretation is given to $\omega\vert_u \in O_u$, with $O_u\in\Sigma_u$.

We now let $\Omega$ be any set of paths that satisfies
\begin{equation}\label{eq:paths_big_enough}
(\forall u\in\mathcal{U}_\emptyset)(\forall x_u\in\states_u)(\forall y_u\in\observs_u)(\exists \omega\in\Omega)\,:\,\omega\vert_u=(x_u,y_u)\,.
\end{equation}
This set $\Omega$ will be the outcome space of an augmented stochastic process. We let $\mathcal{P}(\Omega)$ be the power set of $\Omega$, and let $\mathcal{P}(\Omega)_\emptyset\coloneqq \mathcal{P}(\Omega)\setminus\emptyset$. An augmented stochastic process will then be defined below as a specific coherent conditional probability on a set $\mathcal{C}^{\states\observs}\subseteq \mathcal{P}(\Omega)\times \mathcal{P}(\Omega)_\emptyset $, which we construct as follows.

For any $t\in\realsnonneg$ and any $x\in\states$, the elementary \emph{state} event is denoted
\begin{equation*}
(X_t=x) \coloneqq \left\{ \omega\in\Omega\,:\,\omega(t)=x \right\}\,.
\end{equation*}
For any $u\in\mathcal{U}$, we then let $\mathcal{S}_u$ be the set of elementary state events whose time point is either preceded by, or belongs to, $u$. That is,
\begin{equation*}
\mathcal{S}_u \coloneqq \left\{ (X_t=x)\,:\, x\in\states,\, t\in\reals_{>u}\cup u \right\}\,,
\end{equation*}
and we then let $\langle\mathcal{S}_u\rangle$ be the algebra that is generated by this set of elementary state events.

Similarly, elementary \emph{output} events are defined, for any $t\in\realsnonneg$ and any $O\in\Sigma$, as
\begin{equation*}
(Y_t \in O) \coloneqq \{ \omega\in\Omega\,:\,\omega(t)\in O \}\,,
\end{equation*}
we let $\mathcal{O}_u$ be the set of elementary output events whose time point is either preceded by or belongs to $u$, and the corresponding algebra that is generated by this set is denoted $\langle\mathcal{O}_u\rangle$. To avoid confusion, we want to emphasise at this point that, while $\Sigma$ is a $\sigma$-algebra on $\observs$, the set $\langle \mathcal{O}_u\rangle$ is only an algebra---only closed under \emph{finite} unions and intersections (and complements in $\Omega$)---with respect to the time points that we consider. 

In order to jointly consider state and output values at given time points, we define for any $u\in\mathcal{U}$ the set $\mathcal{A}_u\coloneqq \langle \{ X\cap Y\,:\,X\in\langle\mathcal{S}_u\rangle, Y\in\langle\mathcal{O}_u\rangle\} \rangle$ to be the ``joint'' algebra of $\langle\mathcal{S}_u\rangle$ and $\langle\mathcal{O}_u\rangle$. To make this somewhat less abstract, this set will contain events that are for example of the form $(X_t=x, Y_s\in O)=\{\omega\in\Omega\,:\,\omega(t)=x,\omega(s)\in O\}$.

It is easily verified from Equation~\eqref{eq:paths_big_enough} that, for any $u\in\mathcal{U}$ and $x_u\in\states_u$, the event $(X_u=x_u)\coloneqq\left\{\omega\in\Omega\,:\,\omega\vert_u=x_u\right\}$ is non-empty, whence $(A,X_u=x_u)\in \mathcal{P}(\Omega)\times \mathcal{P}(\Omega)_\emptyset$ for all $A\in\mathcal{A}_u$, and so it follows that
\begin{equation*}
\mathcal{C}^{\states\observs} \coloneqq \left\{ (A, X_u=x_u)\,:\, u\in\mathcal{U}, x_u\in\states_u, A\in\mathcal{A}_u \right\}
\end{equation*}
is a subset of $\mathcal{P}(\Omega)\times \mathcal{P}(\Omega)_\emptyset$. It will furthermore be useful to define the following set of conditional events, and it is easily verified that this is a subset of $\mathcal{C}^{\states\observs}$:
\begin{equation*}
\mathcal{C}^{\states} \coloneqq \{(A,X_u=x_u)\,:\,u\in\mathcal{U},x_u\in\states_u,A\in\langle\mathcal{S}_u\rangle\}\,,
\end{equation*}
which are those conditional events that are only concerned with states.

\begin{definition}\label{def:generating_process}
A coherent conditional probability $P$ on $\mathcal{C}^{\states\observs}$ is called an \emph{augmented stochastic process} if, for every $v\in\mathcal{U}_{\emptyset}$, $u\in\mathcal{U}$, $O_v\in\langle\mathcal{O}_v\rangle$, $t\in\realsnonneg$, and $x_t\in\states_t$,
\begin{itemize}
\item $P(Y_t\in \cdot\,\,\vert X_t=x_t)$ is a $\sigma$-additive probability measure on $(\observs,\Sigma)$;
\item $P(Y_v\in O_v\vert X_v,X_u)=P(Y_v\in O_v\vert X_v)$;
\item $P(Y_v\in O_v\vert X_v)=\prod_{s\in v}P(Y_s\in O_s\vert X_s)$.
\end{itemize}
We denote the entire set of augmented stochastic processes by $\mathbb{P}_{\states\observs}$.
\end{definition}

\begin{corollary}
For any augmented stochastic process $P\in\mathbb{P}_{\states\observs}$, its restriction $P_\states$ to $\mathcal{C}^\states$ is a stochastic process, i.e., $P_\states\in\processes$.
\end{corollary}
\begin{proof}
The statement holds by convenient abuse of notation, since stochastic processes $P\in\processes$ are, by definition, coherent conditional probabilities on the set $\mathcal{C}^\mathrm{SP}$---which is a collection of sets of paths $\omega:\realsnonneg\to\states$. However, $\mathcal{C}^\mathrm{SP}$ is clearly isomorphic to $\mathcal{C}^\states$, so any coherent conditional probability $P_\states$ on $\mathcal{C}^\states$ obviously induces an equivalent (under the aforementioned isomorphism on their domains) coherent conditional probability on $\mathcal{C}^\mathrm{SP}$, which we again denote $P_\states$. Since the restriction $P_\states$ of $P$ to $\mathcal{C}^\states$ is trivially a coherent conditional probability, the result follows.
\end{proof}

We next establish that augmented stochastic processes are well-defined, and in particular, that they are constructable, in the following sense.
\begin{proposition}\label{prop:generating_process_constructable}
Consider any stochastic process $P\in\processes$ and any observable model $(\observs,\Sigma,P_{\observs\vert\states})$. Then, there exists an augmented stochastic process $P^*$ such that $P^*_\states=P$ and, for all $t\in\realsnonneg$, it holds that $P^*(Y_t\in O\vert X_t=x)=P_{\observs\vert\states}(O\vert x)$ for all $O\in\Sigma$ and $x\in\states$.
\end{proposition}

%\begin{proposition}\label{prop:fully_observable_exists}
%Every generating stochastic process can be coherently extended to an augmented stochastic process.
%\end{proposition}
%
%Equation~\eqref{eq:bayes_rule_densities} is, of course, the well-known Bayes' conditioning rule for mixtures of densities. Our reason for defining the processes of interest in such a seemingly roundabout way, is that the probability $P(X_u=x_u\vert Y_u\in \{y_u\})$ does not follow uniquely after extending from the domain $\mathcal{C}^{\states\observs\vert\states}$. Indeed, in the classical, Kolmogorovian setting, this conditional probability can by definition (CITE BILLINGSBEY, Section 34) be identified with \emph{any} measurable function that satisfies the law of total probability, i.e.,
%\begin{equation}\label{eq:law_total_prob_kolmogorov}
%\int_{\observs_u} P(X_u=x_u\vert Y_u\in \{y_u\}) \phi_u(y_u)dy_u = P(X_u=x_u)\,.
%\end{equation}
%Less restrictive still, in the context of coherent conditional probabilities, $P(X_u\vert Y_u\in\{y_u\})$ can in fact be (coherently) identified with \emph{any} probability mass function on $\states_u$.
%
%Our specific choice in Equation~\eqref{eq:bayes_rule_densities} can be motivated by (well-established) convention---it obviously satisfies Equation~\eqref{eq:law_total_prob_kolmogorov}---as well as the following intuitive interpretation.
%\begin{proposition}
%Let $P$ be an augmented stochastic process, and suppose that $\observs$ is uncountable. Then, for every $u\in\mathcal{U}_\emptyset$, every $x_u\in\states_u$, and $\lambda$-\emph{almost every} $y_u\in\observs_u$, if $\phi_u(y_u)>0$,
%\begin{equation}\label{eq:point_conditional_is_limit_almost_everywhere}
%P(X_u=x_u\vert Y_u\in \{y_u\}) = \lim_{\delta\to 0^+} P\bigl(X_u=x_u\vert Y_u\in (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})\bigr)\,.
%\end{equation}
%Furthermore, if the conditional density $\phi_u(\cdot\vert x_u)$ is continuous, then Equation~\eqref{eq:point_conditional_is_limit_almost_everywhere} holds for \emph{every} $y_u\in\observs_u$ for which $\phi_u(y_u)>0$.
%\end{proposition}
%\begin{proof}
%***** This is essentially a special case of Proposition~\ref{prop:GBR_for_densities_is_limit_if_continuous}, replacing Lemma~\ref{lemma:dirac_delta_gets_density_value} by the Lebesgue differentiation theorem when we drop the assumption that $\phi_u(\cdot\vert x_u)$ is continuous.
%\end{proof}


\subsection{Imprecise Continuous-Time Hidden Markov Chains}

\begin{definition}
An augmented stochastic process $P$ is called \emph{consistent} with an observable model $(\observs,\Sigma,P_{\observs\vert\states})$ if, for every $t\in\realsnonneg$, $x\in\states$, and $O\in\Sigma$, it holds that $P(Y_t\in O\,\vert\,X_t=x)=P_{\observs\vert\states}(O\,\vert\,x)$.

When $P$ is consistent with an observable model, we write $P\sim P_{\observs\vert\states}$.
\end{definition}

\begin{definition}\label{def:hidden_ictmc}
Consider a non-empty bounded set of rate matrices $\rateset$, a non-empty set $\mathcal{M}$ of probability mass functions on $\states$, and an observable model $(\observs,\Sigma,P_{\observs\vert\states})$. Then, the corresponding \emph{imprecise continuous-time hidden Markov chain} (ICTHMC) is a set $\mathcal{Z}$ of augmented stochastic processes, defined by
\begin{equation*}
\mathcal{Z} \coloneqq \left\{ P\in\mathbb{P}_{\states\observs} \,:\, P_{\states}\in\wprocesses_{\rateset,\mathcal{M}},\, P\sim P_{\observs\vert\states}\right\}\,.
\end{equation*}
\end{definition}

**** Blabla lower expectation is infimum

\section{Updating the Model}\label{sec:updating_model}

In the context of \emph{hidden} (continuous-time) Markov chains, it is typically assumed that the state $X_t$ that is obtained by the process at time $t$, cannot be directly observed---hence the term ``hidden''. Rather, we can only observe realisations of the observable variable $Y_t$. The problem of interest is then typically to make inferences about this state $X_t$, given what we know about the value of the variable $Y_t$. More generally, we may be interested in the joint states $X_v$ for some time points $v\in\mathcal{U}_\emptyset$, given observations $Y_u$ at time points $u\in\mathcal{U}$; note that we do not necessarily require that $u=v$.

We here use the terminology that we \emph{update} our model with some given observations, after which the updated model reflects our revised beliefs about some quantity of interest. These updated beliefs, about some function $f\in\gambles(\states_v)$, say, are then denoted
\begin{equation*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]\,,\quad\text{or similarly,}\quad\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\,\vert\,Y_u\in O_u]\,,
\end{equation*}
depending on whether we are considering a precise or an imprecise model.

Clearly, the notation that we use here is the same as what would be used for representing \emph{conditional} (lower) expectations. However, note that the domain $\mathcal{C}^{\states\observs}$ does not allow conditioning on observations; so, we are not, strictly speaking, overloading the notation. Nevertheless, when the event $(Y_u\in O_u)$ has strictly positive (lower) probability, it would indeed seem rational to assume that the \emph{updated} belief corresponds to the \emph{conditional} belief---which, in the precise case, can be inferred by application of Bayes' rule. 

However, when this event has probability zero, but was nevertheless observed, the \emph{conditional} belief/expectation cannot be determined in the precise case, and is vacuous in the imprecise case. Nevertheless, we may in some situations still be able to \emph{update} our model in some rational way, to reflect our revised beliefs given this observation. This, then, explains the choice of terminology employed here. We will shortly give some specific examples where this is indeed possible.

\subsection{Observations with Positive (Upper) Probability}

As noted above, when our assertion $(Y_u\in O_u)$ about an observation at time points $u$ has positive probability, we can---in the precise case---update our model by application of Bayes' rule. The following gives a convenient expression for the updated expectation $\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]$, which makes use of the independence properties in Definition~\ref{def:generating_process}.

\begin{proposition}\label{prop:precise_conditioning_for_positive}
Let $P$ be an augmented stochastic process, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\langle\mathcal{O}_u\rangle$, and $f\in\gambles(\states_v)$. Then, the updated expectation is given by
\begin{equation*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u] \coloneqq \sum_{x_v\in\states_v}f(x_v)\frac{P(X_v=x_v, Y_u\in O_u)}{P(Y_u\in O_u)} = \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]}\,,
\end{equation*}
whenever $\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]>0$, and is undefined, otherwise.
\end{proposition}

Similarly, we update the imprecise model by means of the \emph{generalised Bayes' rule} CITE CITE, and in particular through \emph{regular extension} CITE, as follows.
\begin{definition}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\langle\mathcal{O}_u\rangle$, and $f\in\gambles(\states_v)$. Then, the updated lower expectation is given by the \emph{generalised Bayes' rule},
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr] \coloneqq \max\left\{\mu\in\reals\,:\, \lexp\bigl[\mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u]\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\}\,,
\end{equation*}
whenever $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] >0$, and by $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr]\coloneqq\min f$, otherwise.
\end{definition}

When the event $(Y_u\in O_u)$ has positive lower probability, i.e. when $\underline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$, then this event obviously has positive probability for all $P\in\mathcal{Z}$. Hence, each precise model $P$ in the set $\mathcal{Z}$ can then be updated with this observation---using Proposition~\ref{prop:precise_conditioning_for_positive}. In this case, the updated imprecise model corresponds to the lower envelope over all these updated precise models.

\begin{proposition}\label{prop:GBR_positive_lower}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\langle\mathcal{O}_u\rangle$, and $f\in\gambles(\states_v)$. Then, if $\underline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$,
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr] = \inf\bigl\{ \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]\,:\, P\in\mathcal{Z} \bigr\}\,.
\end{equation*}
\end{proposition}

Now, in our definition of the updated imprecise model, we only required that $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$. Suppose, then, that the lower probability of $(Y_u\in O_u)$ is zero, but the upper probability is strictly positive. This means that the outcome $(Y_u\in O_u)$ is impossible for \emph{some} of the precise models $P\in\mathcal{Z}$, but possible for others. As noted in the introduction of this section, \emph{conditioning} all precise models in $\mathcal{Z}$ on this observation would then lead to a vacuous model\footnote{Formally, the precise models that attribute zero probability to this event, can through coherence be extended to conditional models, where $P(X_v\vert Y_u\in O_u)$ can then be identified with any arbitrary probability mass function on $\states_v$; note that these conditional probabilities are not \emph{undefined}---in a division by zero sense---but merely \emph{undetermined}---as in under-parameterised. Computing the lower envelope over the set of all such extended models consistent with the initial set $\mathcal{Z}$, would then yield the assertion that $\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in O_u]=\min f$ (and $\overline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in O_u]=\max f$).}.

However, the generalised Bayes' rule as an \emph{updating} mechanism is more powerful than as a \emph{conditioning} mechanism. That is, when employing the GBR for regular extension---that is, precisely in the case where $\underline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u]=0$ but $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$---we can still obtain an informative, i.e. non-vacuous, model. To be exact, this corresponds to simply discarding from $\mathcal{Z}$ those precise models that assign zero probability to $(Y_u\in O_u)$, updating the remaining models, and then computing the lower envelope over these updated remaining expectations.

\begin{proposition}\label{prop:GBR_regular}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $O_u\in\langle\mathcal{O}_u\rangle$, and $f\in\gambles(\states_v)$. Then, if $\overline{\mathbb{E}}_\mathcal{Z}[Y_u\in O_u] > 0$,
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr] = \inf\bigl\{ \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]\,:\, P\in\mathcal{Z},\, P(Y_u\in O_u)>0 \bigr\}\,.
\end{equation*}
\end{proposition}

Of course, when the upper probability of $(Y_u\in O_u)$ is zero, then the event is deemed impossible by \emph{all} $P\in\mathcal{Z}$. In that case, the observation seems to be conflicting with our entire prior beliefs, and we cannot in general make informative inferences given this observation---that is, the updated model becomes vacuous, and hence $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u\in O_u\bigr]=\min f$.

\subsection{Uncountable Outcome Spaces, Point Observations, and Probability Zero}

An important special case where observations have probability zero for all precise models, but where we can still make informative inferences, is when we have an uncountable outcome space $\observs$ and the observations are points $y_u\in\observs_u$. In this case, it is common practice CITE to define the updated expectation $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$ as the limit of \emph{conditional} expectations, where each conditioning event is an increasingly smaller region $(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})$ around this point $y_u$. Under our assumption that the conditional density $\phi(y_u\vert X_u)$ is continuous, this yields the following result.

\begin{proposition}\label{prop:precise_bayes_rule_densities}
Suppose that $\observs$ is uncountable. Let $P$ be an augmented stochastic process, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, and $f\in\gambles(\states_v)$. Then, for every $y_u\in\observs_u$, if $\mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]>0$,
\begin{equation}\label{eq:updated_expectation_is_limit}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u] \coloneqq \lim_{\delta\to 0^+} \mathbb{E}_P[f(X_v)\,\vert\,Y_u\in (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})] = \frac{\mathbb{E}_P[f(X_v)\phi_u(y_u\vert X_u)]}{\mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]}\,,
\end{equation}
where $(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})$ is an open cube in $\observs_u$ of sidelength $\delta$ that is centred on $y_u$. 

On the other hand, if $\mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]=0$, then $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$ is undefined.
\end{proposition}

The right-hand side of Equation~\eqref{eq:updated_expectation_is_limit} is, of course, the well-known Bayes' conditioning(/updating) rule for mixtures of densities. Similarly, we will again update the imprecise model using regular extension, this time by means of the generalised Bayes' rule for mixtures of densities, as follows.

\begin{definition}
Suppose that $\observs$ is uncountable. Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, the updated lower expectation is given by the \emph{generalised Bayes' rule for mixtures of densities},
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] \coloneqq \max\left\{\mu\in\reals\,:\, \lexp\bigl[\phi_u(y_u\vert X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\}\,,
\end{equation*}
whenever $\overline{\mathbb{E}}_\mathcal{Z}[\phi_u(y_u\vert X_u)] >0$, and by $\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u=y_u\bigr]\coloneqq\min f$, otherwise.
\end{definition}

As was the case in Section REF, this updating rule corresponds to computing the lower envelope over all updated precise models---provided that $\lexp[\phi_u(y_u\vert X_u)]>0$. If only $\uexp[\phi_u(y_u\vert X_u)]>0$, it again corresponds to discarding the models for which $\mathbb{E}_P[\phi(y_u\vert X_u)]=0$, updating the remainder, and computing the lower envelope over those.

\begin{proposition}\label{prop:GBR_for_densities_lower_zero}
Suppose that $\observs$ is uncountable. Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\uexp[\phi_u(y_u\vert X_u)]>0$,
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] = \inf\{\mathbb{E}_P[f(X_v)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}, \mathbb{E}_P[\phi_u(y_u\,\vert\,X_u)]>0\}\,.
\end{equation*}
\end{proposition}
%
%\begin{proposition}\label{prop:GBR_for_densities}
%Suppose that $\observs$ is uncountable. Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}_{<v}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\lexp[\phi_u(y_u\vert X_u)]>0$,
%\begin{equation*}
%\underline{\mathbb{E}}_{\mathcal{Z}}\bigl[f(X_v)\,\vert\,Y_u = y_u\bigr] = \inf\{\mathbb{E}_P[f(X_v)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \phi_u(y_u\vert X_u)$ in that lemma's statement, and applying Proposition~\ref{prop:precise_bayes_rule_densities} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$.
%\end{proof}
So, we know from the above that each of the updated precise models is interpreted as a limit of updated models, and furthermore that the updated imprecise model corresponds to the lower envelope over these limits. One might then wonder, at this point, whether the updated imprecise model itself corresponds to a limit of updated imprecise models. It turns out that this is indeed the case, provided that $\lexp[\phi_u(y_u\vert X_u)]>0$.

\begin{proposition}\label{prop:GBR_for_densities_is_limit_if_continuous}
Suppose that $\observs$ is uncountable. Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $y_u\in\observs_u$, and $f\in\gambles(\states_v)$. Then, if $\lexp[\phi_u(y_u\vert X_u)]>0$,
\begin{align*}
\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u=y_u] %&= \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] \geq 0\right\} \\
 &= \lim_{\delta\to 0^+}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})]
\end{align*}
\end{proposition}

*********** I tried to generalise the above result to the case where only $\uexp[\phi_u(y_u\vert X_u)]>0$, but have so far failed to do this. The problem is essentially that you can have precise models with $\mathbb{E}_P[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})}(Y_u)\vert X_u]] > 0$ for all $\delta>0$, but still have $\mathbb{E}_P[\phi(y_u\vert X_u)]=0$. You can still construct a convergent sequence that goes to {\bf a} root of the density-GBR, but I'm failing to prove that this limit corresponds to the maximum root, and hence is independent of the exact sequence. Not that it should matter too much, since most practical densities are strictly positive anyway, but it is somewhat annoying. ******


\section{Inference Algorithms}\label{sec:inference_algos}

In the previous section, we have seen that we can use the generalised Bayes' rule for updating our ICTHMC with some given observations. From a computational point of view, this is particularly useful because, rather than having to solve the non-linear optimisation problem of computing
\begin{equation*}
\inf\bigl\{\mathbb{E}_P[f(X_v)\vert Y_u\in O_u]\,:\, P\in\mathcal{Z},P(Y_u\in O_u)>0\bigr\}\,,
\end{equation*}
we can focus on evaluating the function
\begin{equation*}
\lexp\bigl[\mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u]\bigl(f(X_v) - \mu\bigr)\bigr]\,,
\end{equation*}
or its density-analogue, for some fixed value of $\mu$. Finding the updated lower expectation is then a matter of finding the maximum value of $\mu$ for which this quantity is non-negative. Since this function is (well-known to be) continuous, monotonically decreasing, and convex in $\mu$, this latter optimisation problem is relatively straightforward to solve numerically using any number of standard optimisation methods.

Therefore, in order for this approach to be computationally tractable, we require efficient algorithms to evaluate this quantity for a given value of $\mu$. In this section, we provide such algorithms for some practically useful choices of the function $f$.

We start by generalising the problem so that these results are applicable both for observations of the form $(Y_u\in O_u)$, and for point-observations $(Y_u=y_u)$ in an uncountable outcome space. Writing $u=t_0,\ldots,t_n$, we note that the factorisation and independence properties in Definition~\ref{def:generating_process} imply that
\begin{equation*}
\mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u] = \prod_{t_i\in u}\mathbb{E}_{\observs\vert\states}[\ind{O_{t_i}}(Y_{t_i})\vert X_{t_i}]\,,\quad\quad\text{and,}\quad\quad \phi(y_u\vert X_u) = \prod_{t_i\in u}\phi(y_{t_i}\vert X_{t_i})\,.
\end{equation*}
Hence, we can in general identify with these a collection of functions $g_{t_i}\in\gambles(\states_{t_i})$, $t_i\in u$, such that $g_{t_i}\geq 0$ for all $i\in\{0,\ldots,n\}$, and the problem of interest is now to evaluate
\begin{equation*}
\lexp\left[ \left(\prod_{i=0}^ng_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr) \right]\,.
\end{equation*}
In general, the computational complexity of evaluating this quantity depends both on the function $f\in\gambles(\states_v)$, and on how the time points $v$ relate to the time points $u$---whether we are performing inference ``into the future'' or ``into the past''. We treat some special cases in the following sections.

\subsection{Functions on a Single Time Point}\label{sec:funcs_single_time}

We start with a particularly useful special case, namely to compute the updated lower expectation of a function $f\in\gambles(\states_s)$ on a single time point $s$. If $s\notin u$, then it will be notationally convenient to define $g_s\coloneqq f - \mu$, and to let $u'\coloneqq u\cup \{s\}$. We can then simply focus on computing
\begin{equation*}
\lexp\left[ \left(\prod_{i=0}^ng_{t_i}(X_{t_i})\right)\bigl(f(X_s) - \mu\bigr) \right] = \lexp\left[ \prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,.
\end{equation*}
On the other hand, if $s = t_i$ for some $t_i\in u$, we let $u'\coloneqq u$ and redefine $g_{t_i}$ as $\tilde{g}_{t_i}(x_{t_i})\coloneqq g_{t_i}(x_{t_i})\cdot (f(x_{t_i})-\mu)$---and then we immediately drop the $\tilde\,$-notation again. The point is simply to establish a uniform indexing notation over all time-points and functions. The right hand side of the above equality can now be computed using the following dynamic programming technique. 

For all $t_i\in u'$, we define auxiliary functions $g_{t_i}^+,g_{t_i}^-\in\gambles(\states_{t_i})$, as follows. Writing $u'=t_0,\ldots,t_{n+1}$, we define $g_{t_{n+1}}^+\coloneqq g_{t_{n+1}}^-\coloneqq g_{t_{n+1}}$. Then, for all $i\in\{0,\ldots,n\}$, define
\begin{equation*}
g_{t_i}^+(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
g_{t_i}(x_{t_i})\cdot\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})\geq 0$, and} \\
g_{t_i}(x_{t_i})\cdot\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})<0$,}
\end{array}\right.
\end{equation*}
and,
\begin{equation*}
g_{t_i}^-(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
g_{t_i}(x_{t_i})\cdot\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})\geq 0$, and} \\
g_{t_i}(x_{t_i})\cdot\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}] & \text{if $g_{t_i}(x_{t_i})<0$.}
\end{array}\right.
\end{equation*}
Clearly, backward recursion allows us to compute all these functions in a time-complexity order that is linear in the number of time points in $u'$. Furthermore, at each step, computing the quantities $\lexp[g_{t_{i+1}}^+(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}]$ and $\uexp[g_{t_{i+1}}^-(X_{t_{i+1}})\,\vert\, X_{t_i}=x_{t_i}]$ can be done in polynomial time, due to the results in Reference BIG PAPER. So, the total complexity of computing all these functions is clearly polynomial. We now have the following result.
\begin{proposition}\label{prop:computing_product_funcs}
For all $t_i\in u'$, let $g_{t_i}$, $g_{t_i}^+$ and $g_{t_i}^-$ be as defined above. Then,
\begin{equation*}
\lexp\left[g_{t_0}^+(X_{t_0})\right] = \lexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,,\quad\quad\text{and,}\quad\quad\uexp\left[g_{t_0}^-(X_{t_0})\right] = \uexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,.
\end{equation*}
\end{proposition}
So, in order to evaluate the function of interest, it remains to compute $\lexp\left[g_{t_0}^+(X_{t_0})\right]$. Since $g_{t_0}^+$ is a function on a single time point $t_0$, this can again be done in polynomial time\footnote{That is, under some assumptions on the set $\mathcal{M}$ of initial distributions. In particular, we require that the lower expectation with respect to this set can be computed efficiently---otherwise, this becomes the bottleneck of the procedure.} using the results in Reference BIG PAPER.


\subsection{Arbitrary Functions in the Future}

The results in the previous section provided us with a way to tractably compute updated lower expectations of arbitrary functions on any single time point. Although this may seem restrictive, it immediately grants the possibility to compute updated lower expectations of arbitrary functions $f\in\gambles(\states_v)$, provided the time points $v$ come after the time points $u$ on which we are updating. This is due to the following result.

\begin{proposition}\label{prop:arbitrary_future_functions}
Consider any $\mu\in\reals$, $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}_{<v}$, $f\in\gambles(\states_v)$ and, for all $t_i\in u$, any $g_{t_i}\in\gambles(\states_{t_i})$ such that $g_{t_i}\geq 0$. Write $u=t_0,\ldots,t_n$. Then,
\begin{equation*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\right] = \lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\left(\lexp[f(X_v)\vert X_{t_n}] - \mu\right)\right]\,.
\end{equation*}
\end{proposition}
Due to this result, it suffices to first compute the quantity $\lexp[f(X_v)\vert X_{t_n}]$, which can in general be done using the results in Reference BIG PAPER. Since this conditional lower expectation is clearly a function on a single time point $t_n$, we can then apply the results from the previous section to compute the updated lower expectation.

Hence, the computational complexity of computing this updated lower expectation depends on the complexity of computing $\lexp[f(X_v)\vert X_{t_n}]$. In general, this takes exponential time in the number of time points in $v$, since even simply specifying $f$ takes this much time.

However, there are certain classes of functions for which this can be done much more efficiently. For instance, if $f\in\gambles(\states_v)$ decomposes into a number of functions $f_{s_i}\in\gambles(\states_{s_i})$, $s_i\in v$, such that we can write
\begin{equation*}
f(x_v) = \prod_{s_i\in v}f_{s_i}(x_{s_i})\,,
\end{equation*}
then we can compute the quantity $\lexp[f(X_v)\vert X_{t_n}]$ by applying the same dynamic programming technique from Section~\ref{sec:funcs_single_time}. In particular, borrowing the notation from that section, this quantity is given by $\lexp[f_{s_0}^+(X_{s_0})\,\vert\,X_{t_n}]$, which is therefore computable in polynomial time (and in particular, in linear time w.r.t. the number of time points in $v$).

Similarly, if $f\in\gambles(\states_v)$ decomposes into functions $f_{s_i}\in\gambles(\states_{s_i})$, $s_i\in v$ such that
\begin{equation*}
f(x_v) = \sum_{s_i\in v} f_{s_i}(x_{s_i})\,,
\end{equation*}
then we can apply an even simpler backward recursive scheme. Writing $v=s_0,\ldots,s_m$, define the base case $\tilde{f}_{s_m}\coloneqq f_{s_m}$ and, for all $i\in\{0,\ldots,m-1\}$, define
\begin{equation*}
\tilde{f}_{s_i} \coloneqq f_{s_i} + \lexp[\tilde{f}_{s_{i+1}}(X_{s_{i+1}})\,\vert\,X_{s_i}]\,.
\end{equation*}
It is easily verified that due to iterated lower expectation (Proposition REF) and the imprecise Markov property of \ictmc's, we then have
\begin{equation*}
\lexp[\tilde{f}_{s_0}(X_{s_0})\,\vert\,X_{t_n}] = \lexp\left[\sum_{s_i\in v} f_{s_i}(X_{s_i})\,\vert\,X_{t_n}\right]\,,
\end{equation*}
and that, using this procedure, this quantity is therefore computable in linear time w.r.t. $m$, and in polynomial time overall.

\subsection{Arbitrary Functions at Arbitrary Time Points}

In the previous sections, we provided tractable inference algorithms for functions at an arbitrary single time point, and for certain classes of functions at multiple time points, provided that these time points are in the future with respect to our observations.

One might then wonder whether it is also possible to provide tractable algorithms for functions at time points that lie before or between the observation times. Unfortunately, it turns out that this is in general not even the case for the relatively simple function classes discussed above, i.e., those that decompose as sums or products of functions at single time points.

Nevertheless, there are some specific problems in which such inferences can be tractably computed. For instance, to find the lower probability of a given state-assignment $x_v$, given observations at time points $u$, where $u$ and $v$ are arbitrary---see JASPERS THESIS for details. 

As another example, it is possible to tractably compute the set of (Walley-Sen)-\emph{maximal state sequences}, given observations at time points $u$. These are those joint state assignments $x_u$ that are non-dominated, in the sense that $P(X_u=x_u\,\vert\,Y_u\in O_u)> P(X_u=\tilde{x}_u\,\vert\,Y_u\in O_u)$ for all $\tilde{x}_u\in\states_u$, $\tilde{x}_u\neq x_u$, and $P\in\mathcal{Z}$---see REF for details.

However, these inferences are computable using specialised algorithms that exploit problem-specific properties to achieve their tractability. For instance, that the function $f$ decomposes into \emph{indicator} functions---which vastly reduces the range of possible values that it can obtain. As such, their description lies well outside the scope of this current paper. In general, arbitrary inferences are still computable using the results in Reference BIG PAPER, although the time-complexity then becomes exponential in the number of time points in $u\cup v$. If nothing else, this makes it possible to perform inferences of arbitrary functions, provided that the number of time points in which we are interested is small enough.

\section{Related Work}

\section{Conclusions and Future Work}

\bibliographystyle{plain}
\bibliography{general.bib}

\newpage

\appendix


\section{Proofs and Lemmas for Section~\ref{sec:aug_stochastic_processes}}

\begin{proposition}\label{prop:sigma_additive_measure_is_coherent_on_sigma_algebra}
Let $(\observs,\Sigma)$ be an arbitrary measurable space, where $\observs$ is an arbitrary outcome space and $\Sigma$ is any $\sigma$-algebra on $\observs$. Then for any $\sigma$-additive probability measure $P$ on $(\observs,\Sigma)$, $P$ is a coherent probability on $\Sigma$.
\end{proposition}
\begin{proof}
*** This is well-known (see, e.g., Berti and Rigo 2002)
\end{proof}

\begin{corollary}\label{cor:product_measure_is_coherent}
Consider any $u\in\mathcal{U}_\emptyset$ and, for all $t\in u$, a $\sigma$-additive probability measure $P_t$ on $(\observs,\Sigma)$. Let $P$ denote the unique product measure on the product space $(\observs_u,\Sigma_u)$ that satisfies, for all $O_u=\prod_{t\in u} O_t$, $O_t\in\Sigma$, $t\in u$, that $P(O_u)\coloneqq \prod_{t\in u}P_t(O_t)$. Then $P$ is a coherent probability on $\Sigma_u$.
\end{corollary}
\begin{proof}
Clearly, $\Sigma_u$ is a $\sigma$-algebra on $\observs_u$, and $P$ is a $\sigma$-additive probability measure on $(\observs_u,\Sigma_u)$. This result is therefore a special case of Proposition~\ref{prop:sigma_additive_measure_is_coherent_on_sigma_algebra}.
\end{proof}


\begin{proof}{\bf of Proposition~\ref{prop:generating_process_constructable}~}
The proof works as follows. We first define a map $\tilde{P}$ on a subset of $\mathcal{C}^{\states\observs}$, for which we prove that all equalities of interest hold and that $\tilde{P}$ is a coherent conditional probability on this domain. The full augmented stochastic process is then constructed by extending from this domain to the complete domain of interest.

To this end, let
\begin{equation*}
\mathcal{C} \coloneqq \mathcal{C}^\states \cup \left\{(Y_v\in O_v,X_{u\cup v}=x_{u\cup v})\,:\,v\in\mathcal{U},u\in\mathcal{U},x_{u\cup v}\in\states_{u\cup v}, O_v\in\langle\mathcal{O}_v\rangle \right\}\,,
\end{equation*}
and it is easily verified that indeed $\mathcal{C}\subset \mathcal{C}^{\states\observs}$. Now construct a map $\tilde{P}:\mathcal{C}\to\reals$, by defining for all $(A,C)\in\mathcal{C}$,
\begin{equation*}
\tilde{P}(A\vert C) \coloneqq \left\{\begin{array}{ll}
P(A\vert C) & \text{if $(A,C)\in\mathcal{C}^\states$, and} \\
\prod_{s\in v} P_{\observs\vert\states}(O_s\vert x_s) & \text{if $(A,C)=(Y_v\in O_v, X_{u\cup v}=x_{u\cup v})$.}
\end{array}\right.
\end{equation*}
Clearly, this map $\tilde{P}$ satisfies all required equalities. It remains to prove that $\tilde{P}$ is a coherent conditional probability on $\mathcal{C}$. So, consider any $n\in\nats$ and, for all $i\in\{1,\ldots,n\}$, any $(A_i,C_i)\in\mathcal{C}$ and $\lambda_i\in\reals$. We need to show that
\begin{equation*}
\max\left\{ \sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr)\,:\,\omega\in C_0\right\} \geq 0\,,
\end{equation*}
with $C_0\coloneqq \cup_{i=1}^n C_i$. We now first split the events $(A_i,C_i)$ into those concerned only with states, and those also concerned with observations. 

So, construct the index sets $S_\states\coloneqq \bigl\{ i\in\{1,\ldots,n\}\,:\,(A_i,C_i)\in\mathcal{C}^\states \bigr\}$ and $S_\observs\coloneqq \{1,\ldots,n\}\setminus S_\states$, and start by assuming that $S_\states$ is non-empty. Then, because $\tilde{P}$ clearly coincides with $P$ on $\mathcal{C}^\states$, and because $P$ is a coherent conditional probability on $\mathcal{C}^\states$, there must exist some $\omega \in \cup_{i\in S_\states} C_i\subseteq C_0$ such that
\begin{equation*}
\sum_{i\in S_\states} \lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega) \bigr) \geq 0\,.
\end{equation*}
On the other hand, if $S_\states$ is empty, let $\omega$ be any element of $C_0$; then, the above inequality holds trivially. In summary, $\omega$ is a realisation that does not incur loss with respect to the gambles that are only concerned with states.

Let now $S_{\observs\vert\states}$ be the index set of observable-events whose conditioning event is realised by $\omega$, i.e., let $S_{\observs\vert\states}\coloneqq \bigl\{ i\in S_\observs\,:\, \ind{C_i}(\omega) = 1\bigr\}$. We now have that
\begin{align*}
 &\quad \sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) + \sum_{i\in S_\observs}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) + \sum_{i\in S_{\observs\vert\states}}\lambda_i\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr)\,.
\end{align*}
Since we know that the first summand is non-negative, and because $\omega\in C_0$, the proof is done if $S_{\observs\vert\states}$ is empty. So, we can assume without loss of generality that $S_{\observs\vert\states}$ is not empty; we now need to find a realisation of the observables so that the second summand in the above expression evaluates to something non-negative.

Now, note that for each $i\in S_{\observs\vert\states}$, the events are of the form $(A_i,C_i)=(Y_{v_i}\in O_{v_i}, X_{v_i\cup u_i}=x_{u_i\cup v_i})$, for some $v_i\in\mathcal{U}$, $u_i\in\mathcal{U}$, $x_{u_i\cup v_i}\in\states_{u_i\cup v_i}$ and $O_{v_i}\in \langle\mathcal{O}_{v_i}\rangle$. Noting that we have $\omega\vert_{u_i\cup v_i}=x_{u_i\cup v_i}$ because $\ind{C_i}(\omega)=1$, and using the definition of $\tilde{P}$, we therefore find
\begin{align*}
\sum_{i\in S_{\observs\vert\states}}\lambda_i\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) &= \sum_{i\in S_{\observs\vert\states}}\lambda_i\left(\prod_{s\in v_i}P_{\observs\vert\states}\bigl(Y_s\in O_s\vert \omega(s)\bigr) - \prod_{s\in v_i}\ind{(Y_s\in O_s)}(\omega)\right)
\end{align*}

Let now $v\coloneqq \cup_{i\in S_{\observs\vert\states}} v_i$ denote the complete set of time points on which these observable-events depend. Note that we can assume without loss of generality that $v_i=v$ for all $i\in S_{\observs\vert\states}$; if $v_i\subset v$, then we can ``pad'' $v_i$ with the remaining time points $s$ by conjunction with the trivial condition $(Y_s\in\observs,X_s=\omega(s))$. That is, using the facts that $\ind{(Y_s\in\observs)}(\omega')=1$ for all $\omega'\in\Omega$ and $P_{\observs\vert\states}(\observs\vert x)=1$ for all $x\in\states$, we have
\begin{align*}
 &\quad \sum_{i\in S_{\observs\vert\states}}\lambda_i\left(\prod_{s\in v_i}P_{\observs\vert\states}\bigl(Y_s\in O_s\vert \omega(s)\bigr) - \prod_{s\in v_i}\ind{(Y_s\in O_s)}(\omega)\right) \\
 &= \sum_{i\in S_{\observs\vert\states}}\lambda_i\left(\prod_{s\in v_i}P_{\observs\vert\states}\bigl(Y_s\in O_s\vert \omega(s)\bigr)\prod_{s\in v\setminus v_i}1 - \prod_{s\in v_i}\ind{(Y_s\in O_s)}(\omega)\prod_{s\in v\setminus v_i}1\right) \\
 &= \sum_{i\in S_{\observs\vert\states}}\lambda_i\left(\prod_{s\in v_i}P_{\observs\vert\states}\bigl(Y_s\in O_s\vert \omega(s)\bigr)\prod_{s\in v\setminus v_i}P_{\observs\vert\states}\bigl(Y_s\in \observs\vert \omega(s)\bigr) - \prod_{s\in v_i}\ind{(Y_s\in O_s)}(\omega)\prod_{s\in v\setminus v_i}\ind{(Y_s\in \observs)}(\omega)\right) \\
 &=: \sum_{i\in S_{\observs\vert\states}}\lambda_i\left( \tilde{P}(A_i'\vert C_i') - \ind{A_i'}(\omega)\right)\,,
\end{align*}
where we have defined $A_i'\coloneqq A_i\cap\bigl(\cap_{s\in v\setminus v_i}(Y_s\in\observs)\bigr)$ and $C_i'\coloneqq C_i\cap\bigl(\cap_{s\in v\setminus v_i}(X_s=\omega(s))\bigr)$.

Let now $P_{\observs}'$ be the unique product measure on $(\observs_v,\Sigma_v)$ that satisfies $P_{\observs}'(O_v)\coloneqq \prod_{s\in v}P_{\observs\vert\states}(O_s\vert\omega(s))$ for all $O_v=\prod_{s\in v}O_s$, with $O_s\in\Sigma$ for all $s\in v$. Then, clearly,
\begin{equation*}
\sum_{i\in S_{\observs\vert\states}}\lambda_i\left( \tilde{P}(A_i'\vert C_i') - \ind{A_i'}(\omega)\right) = \sum_{i\in S_{\observs\vert\states}}\lambda_i\left( P_\observs'(O_{v_i}') - \ind{A_i'}(\omega)\right)\,,
\end{equation*}
with $O_{v_i}'\in \langle\mathcal{O}_v\rangle$ defined such that $A_i'=(Y_v\in O_{v_i}')$.
Using Corollary~\ref{cor:product_measure_is_coherent}, $P_{\observs}'$ is a coherent probability on $\Sigma_v$, which implies that there is some $y_v\in\observs_v$ such that $\sum_{i\in S_{\observs\vert\states}}\lambda_i\left( P_\observs'(O_{v_i}') - \ind{O_{v_i}'}(y_v)\right) \geq 0$.

Due to Equation~\eqref{eq:paths_big_enough}, there is some $\omega'\in\Omega$ such that $\omega'$ agrees with $\omega$ with respect to all relevant state-assignments, and such that $\omega'\vert_v=y_v$. It is now trivially verified that $\omega'\in C_0$, because this only depends on the state-values, which agree with $\omega$. Furthermore, we clearly have
\begin{align*}
 &\quad \sum_{i=1}^n\lambda_i\ind{C_i}(\omega')\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega')\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega')\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega')\bigr) + \sum_{i\in S_{\observs\vert\states}}\lambda_i\ind{C_i}(\omega')\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega')\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) + \sum_{i\in S_{\observs\vert\states}}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega')\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) + \sum_{i\in S_{\observs\vert\states}}\lambda_i\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega')\bigr) \\
 &= \sum_{i\in S_\states}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i) - \ind{A_i}(\omega)\bigr) + \sum_{i\in S_{\observs\vert\states}}\lambda_i\left( P_\observs'(O_{v_i}') - \ind{O_{v_i}'}(y_v)\right) \\
 &\geq 0\,,
\end{align*}
which concludes the proof that $\tilde{P}$ is a coherent conditional probability on $\mathcal{C}$.

The remainder of the proof is now straightforward. Since $\tilde{P}$ is coherent on $\mathcal{C}$, and since $\mathcal{C}\subset\mathcal{C}^{\states\observs}$, there exists a coherent extension $P^*$ of $\tilde{P}$ to $\mathcal{C}^{\states\observs}$. Since $\tilde{P}$ satisfies all (independence) properties of interest, and since $P^*$ agrees with $\tilde{P}$ on $\mathcal{C}$, $P^*$ also satisfies these properties. It now follows from the definition that $P^*$ is an augmented stochastic process.
\end{proof}

\section{Proofs and Lemmas for the Results in Section~\ref{sec:updating_model}}

\begin{proof}{\bf of Proposition~\ref{prop:precise_conditioning_for_positive}~}
This follows from some simple manipulations:
\begin{align*}
\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u] &= \sum_{x_v\in\states_v} f(x_v)\frac{P(X_v=x_v, Y_u\in O_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(X_v=x_v, X_u=x_u, Y_u\in O_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(Y_u\in O_u\,\vert\,X_v=x_v, X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_v\in\states_v} f(x_v)\sum_{x_u\in\states_u}\frac{P(Y_u\in O_u\,\vert\,X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \sum_{x_{u\cup v}\in\states_{u\cup v}} f(x_v)\frac{P(Y_u\in O_u\,\vert\,X_u=x_u)P(X_v=x_v, X_u=x_u)}{P(Y_u\in O_u)} \\
 &= \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{P(Y_u\in O_u)} \\
 &= \frac{\mathbb{E}_P[f(X_v)P(Y_u\in O_u\vert X_u)]}{\mathbb{E}_P[P(Y_u\in O_u\,\vert\,X_u)]}\,,
\end{align*}
where the first equality is by definition, the second equality from the law of total probability, the third by the basic properties of probability, the fourth using the independence property in the definition of augmented stochastic processes, the sixth is simple rearrangement of terms, the seventh is by definition of expectation, and the final equality **** is also trivial (basic properties, total probability, definition expectation) ***.
\end{proof}

The following lemma provides some useful properties of the main function of interest in the generalised Bayes' rule, stated in slightly more general terms.

\begin{lemma}\label{lemma:general_gbr_is_monotone_and_has_root}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $f\in\gambles(\states_v)$, and $g\in\gambles(\states_u)$ such that $g\geq 0$. Let $\mu\in\reals$ be any real number. 

Then, the function $\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]$, parameterised in $\mu$, is (a) monotonically decreasing, (b) strictly monotonically decreasing if $\lexp[g(X_u)]>0$, (c) has at least one root, and (d) has a unique root if $\lexp[g(X_u)]>0$.
\end{lemma}
\begin{proof}
We first show that this function is monotonically decreasing in $\mu$. To this end, fix any $P\in\mathcal{Z}$. Then, by linearity of expectation,
\begin{align}\label{eq:gbr_linear_expansion}
\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] = \mathbb{E}_P[g(X_u)f(X_v)] - \mu\mathbb{E}_P[g(X_u)]\,.
\end{align}
Since by assumption $g\geq 0$, it must hold that $\mathbb{E}_P[g(X_u)]\geq 0$, and hence, that $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]$ is monotonically decreasing in $\mu$. Since this is true for all $P\in\mathcal{Z}$, we find that $\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]$ is a lower envelope over monotonically decreasing functions, which must therefore be monotonically decreasing itself. This proves statement (a) above.

For statement (b), assume $\lexp[g(X_u)]>0$. Clearly, this implies that $\mathbb{E}_P[g(X_u)]>0$ for all $P\in\mathcal{Z}$, which, using Equation~\ref{eq:gbr_linear_expansion}, implies that the function is a lower envelope over strictly monotonically decreasing functions that each have a constant derivative in $\mu$---the latter property is notable because this prevents the formation of accumulation points, towards some lower bound, as $\mu$ is increased. This therefore implies that the function is strictly monotonically decreasing itself.

For statement (c), i.e. that it has at least one root, we distinguish two cases. First, assume that $\uexp[g(X_u)]=0$. Clearly, this implies that, for all $P\in\mathcal{Z}$, $\mathbb{E}_P[g(X_u)]=0$. Therefore, since $g\geq 0$, we must have that $\mathbb{E}_P[g(X_u)\vert X_v=x_v]=0$ for all $x_v\in\states_v$. By the law of iterated expectation, we therefore have
\begin{equation*}
\mathbb{E}_P[f(X_v)g(X_u)] = \mathbb{E}_P\bigl[f(X_v)\mathbb{E}_P[g(X_u)\vert X_v]\bigr] = 0\,,
\end{equation*}
and hence, by combining with Equation~\ref{eq:gbr_linear_expansion}, that $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]=0$. Since this is true for all $P\in\mathcal{Z}$, we clearly have that the function of interest is identically zero for all choices of $\mu$ and hence, it trivially has at least one root.

Suppose for the other case that $\uexp[g(X_u)]>0$, and set $\mu\coloneqq \min f$. Then for every $P\in\mathcal{Z}$, using the assumption $g\geq 0$,
\begin{equation*}
\mathbb{E}_P[g(X_u)f(X_v)] \geq \mathbb{E}_P[g(X_u)(\min f)] = \mu\mathbb{E}_P[g(X_u)]\,,
\end{equation*}
and hence, using Equation~\eqref{eq:gbr_linear_expansion}, we have $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0$. Since this is true for every $P\in\mathcal{Z}$, we find that $\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]\geq 0$ for this choice of $\mu$. So, the function is non-negative, and clearly, if the function is zero, we are done.

Hence, we can assume without loss of generality that $\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] > 0$. Because we also assumed that $\uexp[g(X_u)] > 0$, there must be some $P\in\mathcal{Z}$ such that $\mathbb{E}_P[g(X_u)]>0$. Using this $P$, define
\begin{equation*}
\mu' \coloneqq \frac{\mathbb{E}_P[g(X_u)f(X_v)]}{\mathbb{E}_P[g(X_u)]}\,.
\end{equation*}
For this same choice of $P$, we then have
\begin{equation*}
\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu'\bigr)\bigr] = \mathbb{E}_P[g(X_u)f(X_v)] - \mu'\mathbb{E}_P[g(X_u)] = 0\,,
\end{equation*}
using the choice of $\mu'$ to establish the second equality. Since $P\in\mathcal{Z}$, we now have
\begin{equation*}
\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu'\bigr)\bigr] \leq \mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v) - \mu'\bigr)\bigr] = 0\,,
\end{equation*}
and since we know that the function is monotonically decreasing, that $\mu\leq \mu'$. Since the function is also clearly continuous in $\mu$, by the intermediate value theorem, there must now be some $\mu^*\in [\mu,\mu']$ such that
\begin{equation*}
\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu^*\bigr)\bigr] = 0\,.
\end{equation*}
This proves that the function has at least one root.

For statement (d), note that the above argument already established that for $\mu\coloneqq \min f$, we have $\lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr]\geq 0$. By combining with statement (b), i.e. strict monotonicity under the assumption that $\lexp[g(X_u)]>0$, the uniqueness of the root now follows under the same assumption.
\end{proof}

The following lemma states a more general version of the result that the generalised Bayes' rule computes the updated lower expectation of a model under regular extension.

\begin{lemma}\label{lemma:general_regular_extension}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $f\in\gambles(\states_v)$, and $g\in\gambles(\states_u)$ such that $g\geq 0$. Then, if $\uexp[g(X_u)]>0$, it holds that
\begin{equation*}
\max\left\{\mu\in\reals\,:\, \lexp\bigl[g(X_u)\bigl(f(X_v) - \mu\bigr)\bigr] \geq 0\right\} = \inf\left\{ \frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,:\,P\in\mathcal{Z}, \mathbb{E}_P[g(X_u)]>0 \right\}\,.
\end{equation*}
\end{lemma}
\begin{proof}
Let $\mathcal{P}\coloneqq \left\{ P\in\mathcal{Z}\,:\, \mathbb{E}_P[g(X_u)] > 0\right\}$, and note that $\mathcal{P}$ is non-empty due to the assumption that $\uexp[g(X_u)]>0$. For all $P\in\mathcal{P}$, define
\begin{equation*}
\mu_P \coloneqq \frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,,
\end{equation*}
and let $\mu_*$ be defined by
\begin{equation*}
\mu_* \coloneqq \inf\left\{\mu_P\,:\,P\in\mathcal{P} \right\}\,.
\end{equation*}
Now define the following function, parameterised in $\mu$,
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)] \coloneqq \inf\{\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]\,:\,P\in\mathcal{P} \}\,,
\end{equation*}
and consider $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$. We start by showing that this quantity is non-negative. To this end, fix any $\epsilon>0$. Then, there is some $P\in\mathcal{P}$ such that
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - \mu_*)] - \epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Using Equation~\eqref{eq:gbr_linear_expansion}, the function $\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]$ is monotonically decreasing in $\mu$. Therefore, and since $\mu_*\leq \mu_P$, we have
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)] - \epsilon \leq \mathbb{E}_P[g(X_u)(f(X_v) - \mu_*)] - \epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Due to the choice of $\mu_P$, we have $\mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)]=0$, and so we find that
\begin{equation*}
-\epsilon < \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]\,.
\end{equation*}
Since this is true for every $\epsilon>0$, we conclude that $0\leq \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$. Next, we show that this quantity is also non-positive, or in other words, that $\mu_*$ is a root of this function. 

To this end, fix any $\epsilon>0$, and define $\epsilon'\coloneqq \nicefrac{\epsilon}{\uexp[g(X_u)]}$; since by assumption $\uexp[g(X_u)]>0$, we have $\epsilon' >0$. Now consider $P\in\mathcal{P}$ such that
\begin{equation*}
\mu_P - \epsilon' < \mu_*\,.
\end{equation*}
Then, since $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)]$ is monotonically decreasing in $\mu$, we have
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] \leq \underline{\mathbb{E}}[g(X_u)(f(X_v) - (\mu_P - \epsilon'))]\leq \mathbb{E}_P[g(X_u)(f(X_v) - (\mu_P - \epsilon'))]\,.
\end{equation*}
Expanding the r.h.s. using linearity of expectation, and by the definition of $\mu_P$, we then have
\begin{equation*}
\mathbb{E}_P[g(X_u)(f(X_v) - (\mu_P - \epsilon'))] = \mathbb{E}_P[g(X_u)f(X_v)] - \mu_P\mathbb{E}_P[g(X_u)] + \epsilon'\mathbb{E}_P[g(X_u)] = \epsilon'\mathbb{E}_P[g(X_u)]\,,
\end{equation*}
and since $P\in\mathcal{P}\subseteq\mathcal{Z}$,
\begin{equation*}
\epsilon'\mathbb{E}_P[g(X_u)] \leq \epsilon'\uexp[g(X_u)]=\epsilon\,,
\end{equation*}
and so we find that
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] \leq \epsilon\,.
\end{equation*}
Since this is true for every $\epsilon>0$, and since we already know that $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)]$ is non-negative, we conclude that
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu_*)] = 0\,.
\end{equation*}

Now consider any $\mu' > \mu_*$. There must then be some $P\in\mathcal{P}$ such that $\mu_*\leq \mu_P < \mu'$, and furthermore,
\begin{equation*}
\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu')] \leq \mathbb{E}_P[g(X_u)(f(X_v) - \mu')] < \mathbb{E}_P[g(X_u)(f(X_v) - \mu_P)] = 0\,,
\end{equation*}
where the strict inequality follows from the fact that $\mathbb{E}_P[g(X_u)(f(X_v) - \mu)]$ is strictly monotonically decreasing, and $\mu_P<\mu'$. Since this is true for every $\mu'>\mu_*$, we conclude that
\begin{equation*}
\mu_* = \max\left\{ \mu\in\reals\,:\, \underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)] \geq 0 \right\}\,.
\end{equation*}

Furthermore, as was essentially already established in the proof of case (c) in Lemma~\ref{lemma:general_gbr_is_monotone_and_has_root}, the function $\mathbb{E}_P\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr]$ is identically zero for all $P\in\mathcal{Z}$ for which $\mathbb{E}_P[g(X_u)]=0$, that is, those $P\in\mathcal{Z}$ that are not in $\mathcal{P}$. Hence, we have 
\begin{equation*}
\lexp\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr] = \min\left\{\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)],\,0 \right\}\,,
\end{equation*}
from which we conclude that $\lexp\bigl[g(X_u)\bigl(f(X_v)-\mu\bigr)\bigr]$ is strictly negative whenever $\underline{\mathbb{E}}[g(X_u)(f(X_v) - \mu)]$ is. In other words, we have that
\begin{equation*}
\inf\left\{\frac{\mathbb{E}_P[f(X_v)g(X_u)]}{\mathbb{E}_P[g(X_u)]}\,:\,P\in\mathcal{P}\right\} = \mu_* = \max\left\{ \mu\in\reals\,:\, \lexp[g(X_u)(f(X_v) - \mu)] \geq 0 \right\}
\end{equation*}
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_positive_lower}~}
This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u]$ in that lemma's statement, and applying Proposition~\ref{prop:precise_conditioning_for_positive} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]$.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_regular}~}
This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \mathbb{E}_{\observs\vert\states}[\ind{O_u}(Y_u)\vert X_u]$ in that lemma's statement, and applying Proposition~\ref{prop:precise_conditioning_for_positive} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u\in O_u]$.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:precise_bayes_rule_densities}~}
**** Essentially a special case of the statement for the imprecise version. Might add a special case at some point, but the proof of Proposition~\ref{prop:GBR_for_densities_is_limit_if_continuous} also works here, exchanging lower expectations for precise ones where appropriate.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_for_densities_lower_zero}~}
This is a special case of Lemma~\ref{lemma:general_regular_extension}, obtained by setting $g(X_u)\coloneqq \phi_u(y_u\vert X_u)$ in that lemma's statement, and applying Proposition~\ref{prop:precise_bayes_rule_densities} to the quantities $\mathbb{E}_P[f(X_v)\,\vert\,Y_u=y_u]$.
\end{proof}

%*************************
%
%
%We need the following result for the proofs of Propositions~\ref{prop:GBR_for_densities} and~\ref{prop:GBR_for_densities_is_limit_if_continuous}.
%\begin{lemma}\label{lemma:unique_root}
%Suppose that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] = 0$ for some $\mu,\mu'\in\reals$. Then, if $\lexp[\phi(y_u\vert X_u)]>0$, it holds that $\mu=\mu'$.
%\end{lemma}
%\begin{proof}
%Let $\mu,\mu'$ be any two roots of the function of interest, and assume without loss of generality that $\mu\leq\mu'$. Fix any $\epsilon>0$, and define $\epsilon^*\coloneqq \epsilon\cdot \lexp\left[\phi(y_u\vert X_u) \right]$. Since $\lexp[\phi(y_u\vert X_u)] > 0$, it clearly holds that $\epsilon^*>0$. Now, since
%\begin{equation*}
%0 = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] = \inf\left\{ \mathbb{E}_P\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] \,:\, P\in\wprocesses_{\rateset,\mathcal{M}}\right\}\,,
%\end{equation*}
%there must exist some process $P_\mu\in\wprocesses_{\rateset,\mathcal{M}}$ such that $0\leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*$.
%
%By linearity of expectation, we have for any $\nu$ that
%\begin{align*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\nu \bigr)\right] %&= \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) - \phi(y_u\vert X_u)\nu \right] %\\
% &= \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) \right] - \mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u)\nu \right] \\
% = \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)f(X_s) \right] - \nu\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]\,,
%\end{align*}
%and hence, we see that the function $\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\nu \bigr)\right]$ is monotonically decreasing in $\nu$. Since by assumption $\mu\leq\mu'$, and combining with the above, we see that
%\begin{equation*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*\,.
%\end{equation*}
%
%Furthermore, since $\mu'$ is also a root, we have that
%\begin{equation*}
%0 = \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right]\,,
%\end{equation*}
%and hence, combining with the above,
%\begin{equation*}
%0 \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] \leq \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] < \epsilon^*\,,
%\end{equation*}
%which clearly implies that
%\begin{equation*}
%\mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] - \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] < \epsilon^*\,.
%\end{equation*}
%Expanding this difference using linearity of expectation, we have
%\begin{align*}
% &\quad \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu \bigr)\right] - \mathbb{E}_{P_\mu}\left[ \phi(y_u\vert X_u)\bigl(f(X_s) -\mu' \bigr)\right] 
% &= -\mu\mathbb{E}_{P_\mu}\left[\prod_{i=0}^n\phi(y_{t_i}\vert X_{t_i}) \right] + \mu'\mathbb{E}_{P_\mu}\left[\prod_{i=0}^n\phi(y_{t_i}\vert X_{t_i}) \right] \\
% = (\mu' - \mu)\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]\,,
%\end{align*}
%and hence that $(\mu' - \mu) < \nicefrac{\epsilon^*}{\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]}$. Since $\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right] \geq \lexp\left[\phi(y_u\vert X_u) \right]$, we find
%\begin{align*}
%(\mu' - \mu) &< \frac{\epsilon^*}{\mathbb{E}_{P_\mu}\left[\phi(y_u\vert X_u) \right]} \leq \frac{\epsilon^*}{\lexp\left[\phi(y_u\vert X_u) \right]} = \frac{\epsilon\cdot\lexp\left[\phi(y_u\vert X_u) \right]}{\lexp\left[\phi(y_u\vert X_u) \right]} = \epsilon\,.
%\end{align*}
%Hence, we have found that $(\mu' - \mu) = \abs{\mu'-\mu} < \epsilon$, using the assumption $\mu\leq \mu'$ to establish the equality. Since this is true for every $\epsilon>0$, we conclude that indeed $\mu=\mu'$.
%\end{proof}
%
%\begin{proof}[Proof of Proposition~\ref{prop:GBR_for_densities}]
%Let $\mu$ be the unique root of $\lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]$.
%Then, clearly,
%\begin{equation*}
%0 = \lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] \leq \mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]\,,
%\end{equation*}
%for every $P\in\wprocesses_{\rateset,\mathcal{M}}$. By linearity of expectation,
%\begin{align*}
%\mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] &= \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]-\mu\mathbb{E}_P[\phi(y_u\vert X_u)]\,,
%\end{align*}
%and hence
%\begin{align*}
%0 &\leq \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] - \mu\mathbb{E}_P[\phi(y_u\vert X_u)] \\
%\mu\mathbb{E}_P[\phi(y_u\vert X_u)] &\leq \mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] \\
%\mu &\leq \frac{\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]}{\mathbb{E}_P[\phi(y_u\vert X_u)]} = \mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,,
%\end{align*}
%which clearly implies that
%\begin{equation*}
%\mu \leq \inf\{\mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}\,.
%\end{equation*}
%
%So, $\mu$ is a lower bound on $\inf\{\mathbb{E}_P[f(X_s)\vert Y_u=y_u]\,:\,P\in\mathcal{Z}\}$. It remains to show that this bound is tight, or equivalently, that for every $\epsilon>0$, there is some $P\in\mathcal{Z}$, such that $\mathbb{E}_P[f(X_s)\vert Y_u=y_u]-\mu < \epsilon$. So, fix any $\epsilon>0$, and let $\epsilon^*\coloneqq \epsilon\cdot\lexp[\phi(y_u\vert X_u)]$. Since by assumption $\lexp[\phi(y_u\vert X_u)]>0$, we clearly have that $\epsilon^*>0$. Therefore, and since $\mu$ is a root of $\lexp[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)]$, there must exist some $P\in\wprocesses_{\rateset,\mathcal{M}}$ such that
%\begin{equation*}
%0 \leq \mathbb{E}_P[\phi(y_u\vert X_u)\bigl(f(X_s)-\mu\bigr)] < \epsilon^*\,.
%\end{equation*}
%Hence, by linearity of expectation,
%\begin{align*}
%\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]-\mu\mathbb{E}_P[\phi(y_u\vert X_u)] &< \epsilon^* \\
%\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)] &< \mu\mathbb{E}_P[\phi(y_u\vert X_u)] + \epsilon^* \\
%\frac{\mathbb{E}_P[\phi(y_u\vert X_u)f(X_s)]}{\mathbb{E}_P[\phi(y_u\vert X_u)]} &< \mu + \frac{\epsilon}{\mathbb{E}_P[\phi(y_u\vert X_u)]} \\
%\mathbb{E}_P[f(X_s)\vert Y_u=y_u] - \mu &< \frac{\epsilon^*}{\mathbb{E}_P[\phi(y_u\vert X_u)]} \leq \frac{\epsilon^*}{\lexp[\phi(y_u\vert X_u)]} = \epsilon\,.
%\end{align*}
%\end{proof}

We need the following three results for the proof of Proposition~\ref{prop:GBR_for_densities_is_limit_if_continuous}.

\begin{proposition}\label{prop:decomp}
Let $\mathcal{Z}$ be an ICTHMC, and consider any $v\in\mathcal{U}_\emptyset$, $u\in\mathcal{U}$, $f\in\gambles(\states_v)$, and $g\in\gambles(\observs_u)$. Then,
\begin{equation*}
\underline{\mathbb{E}}_\mathcal{Z}\left[ f(X_v)g(Y_u) \right] = \lexp\left[ f(X_v)\mathbb{E}_{\observs\vert\states}[g(Y_u)\vert X_u] \right] 
\end{equation*}
\end{proposition}
\begin{proof}
Fix any $P\in\mathcal{Z}$. Then,
\begin{align*}
\mathbb{E}_P\bigl[ f(X_v)g(Y_u) \bigr] &= \mathbb{E}_P\bigl[ \mathbb{E}_P\left[ f(X_v)g(Y_u) \vert X_v,X_u \right] \bigr] \\
&= \mathbb{E}_P\bigl[ f(X_v)\mathbb{E}_P[ g(Y_u) \vert X_v,X_u ] \bigr] \\
&= \mathbb{E}_P\bigl[ f(X_v)\mathbb{E}_P[ g(Y_u) \vert X_u ] \bigr] \\
&= \mathbb{E}_{P_\states}\bigl[ f(X_v)\mathbb{E}_{\observs\vert\states}[ g(Y_u) \vert X_u ] \bigr] \,,
\end{align*}
where the first and second equality follow from the basic properties of expectation, the third equality is due to the independence assumption in Definition~\ref{def:generating_process}, and the final equality uses the facts that the (outer) expectation is only concerned with states, and that the probability $P_{\observs\vert\states}$ is shared by all $P\in\mathcal{Z}$. Since this is true for every $P\in\mathcal{Z}$, the result now follows.
\end{proof}


\begin{lemma}\label{lemma:dirac_delta_gets_density_value}
Consider any sequence $\{\delta_i\}_{i\in\nats}\to 0^+$ in $\realspos$. Then, if $\phi(y_u\vert x_u)$ is continuous around $y_u$,
\begin{equation*}
\lim_{i\to\infty} \frac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u] = \phi(y_u\vert x_u)\,,
\end{equation*}
where $\lambda(\mathcal{B}_i)\coloneqq \lambda((y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2}))$ is Lebesgue measure of the region $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$.
\end{lemma}
\begin{proof}
Fix any $i\in\nats$, and note that
\begin{align*}
\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u] &= \int_{\observs_u}\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(y)\phi(y\vert x_u) dy 
= \int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\phi(y\vert x_u) dy\,.
\end{align*}
Let $\underline{\phi}_i\coloneqq \inf\{\phi(y\vert x_u):y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\}$ and $\overline{\phi}_i\coloneqq \sup\{\phi(y\vert x_u):y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\}$. Then, since $\underline{\phi}_i \leq \phi(y\vert x_u)\leq \overline{\phi}_i$ for all $y\in(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$, we clearly have that
\begin{align*}
\underline{\phi}_i = \underline{\phi}_i\cdot\frac{\lambda(\mathcal{B}_i)}{\lambda(\mathcal{B}_i)} = \underline{\phi}_i\cdot\frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}dy &= \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\underline{\phi}_idy
 \\
 &\leq \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\phi(y\vert x_u) dy \\
 &\leq \frac{1}{\lambda(\mathcal{B}_i)}\int_{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}\overline{\phi_i} dy  = \overline{\phi}_i\,.
\end{align*}
Hence, for every $i\in\nats$, we have that $\underline{\phi}_i\leq\nicefrac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u]\leq\overline{\phi}_i$, and since also clearly $\underline{\phi}_i\leq \phi(y_u\vert x_u)\leq \overline{\phi}_i$, it follows that
\begin{equation*}
\abs{\phi(y_u\vert x_u) - \frac{1}{\lambda(\mathcal{B}_i)}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u=x_u]} \leq \overline{\phi}_i - \underline{\phi}_i\,,
\end{equation*}
and so we see that it suffices to show that $\lim_{i\to\infty}\overline{\phi}_i - \underline{\phi}_i = 0$, or equivalently, that for every $\epsilon\in\realspos$, there is some $N\in\nats$ such that, for every $i>N$, $\overline{\phi}_i-\underline{\phi}_i < \epsilon$. So, fix any $\epsilon\in\realspos$. Since we assumed that $\phi(y\vert x_u)$ is continuous around $y_u$, there exists some $\delta\in\realspos$ such that, for every $\Delta\in(-\delta,\delta)$,
\begin{equation}\label{eq:dirac_bound_close_enough}
\abs{\phi(y_u\vert x_u) - \phi(y_u+\Delta\vert x_u)} < \frac{\epsilon}{4}\,.
\end{equation}
Consider this $\delta$. Then, since $\{\delta_i\}_{i\in\nats}\to 0^+$, there exists some $N\in\nats$ such that, for all $i>N$, $\delta_i < \delta$. Consider this $N$, and choose any $i>N$; it now remains to show that $\overline{\phi}_i-\underline{\phi}_i < \epsilon$.

Let $\underline{\phi}_*\coloneqq \inf\{ \phi(y\vert x_u):y\in(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2}) \}$ and $\overline{\phi}_*\coloneqq \sup\{ \phi(y\vert x_u):y\in(y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2}) \}$. Then, since $\delta_i<\delta$, we clearly have $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})\subset (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})$, and hence $\underline{\phi}_* \leq \underline{\phi}_i$ and $\overline{\phi}_i\leq \overline{\phi}_*$. Therefore, it suffices to show that $\overline{\phi}_*-\underline{\phi}_* < \epsilon$. Since it follows trivially from Equation~\eqref{eq:dirac_bound_close_enough} that $\phi(y_u\vert x_u)-\underline{\phi}_*\leq\nicefrac{\epsilon}{4}$ and $\overline{\phi}_*-\phi(y_u\vert x_u)\leq\nicefrac{\epsilon}{4}$, we have
\begin{equation*}
\overline{\phi}_* - \underline{\phi}_* = \overline{\phi}_* - \phi(y_u\vert x_u) + \phi(y_u\vert x_u) - \underline{\phi}_* \leq \frac{\epsilon}{4}+\frac{\epsilon}{4} = \frac{\epsilon}{2} < \epsilon\,,
\end{equation*}
which concludes the proof.
\end{proof}

\begin{lemma}\label{lemma:limit_lexp_is_lexp_limit}
Consider any $u\in\mathcal{U}_\emptyset$ and any uniformly convergent sequence $\{f_i\}_{i\in\nats}\to f$ in $\gambles(\states_u)$. Then, $\lim_{i\to\infty}\lexp[f_i(X_u)]=\lexp[f(X_u)]$.
\end{lemma}
\begin{proof}
We will show that, for every $\epsilon>0$, there is some $n\in\nats$ such that for all $i>n$, it holds that $\abs{\lexp[f_i(X_u)]-\lexp[f(X_u)]} < \epsilon$. So, consider any $\epsilon>0$, and define $\epsilon^*\coloneqq \nicefrac{\epsilon}{4}$. Because $\{f_i\}_{i\in\nats}\to f$, there is some $n\in\nats$ such that, for all $i>n$, it holds that $\norm{f_i - f}<\epsilon^*$. 

Consider now any $i>n$. Because $\norm{f_i - f}<\epsilon^*$, it clearly holds for every $P\in\wprocesses_{\rateset,\mathcal{M}}$ that $\abs{\mathbb{E}_P[f_i(X_u)] - \mathbb{E}_P[f(X_u)]}<\epsilon^*$, and hence
\begin{equation}\label{eq:lemma_converges_expectation_close}
\mathbb{E}_P[f_i(X_u)] - \epsilon^* < \mathbb{E}_P[f(X_u)] < \mathbb{E}_P[f_i(X_u)] + \epsilon^*\,.
\end{equation}
Furthermore, because $\lexp[\cdot]$ computes an infimum, there must be $P_i,P\in\wprocesses_{\rateset,\mathcal{M}}$ such that
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - \epsilon^* < \lexp[f_i(X_u)] \leq \mathbb{E}_{P}[f_i(X_u)]\,,
\end{equation*}
and,
\begin{equation*}
\mathbb{E}_{P}[f(X_u)] - \epsilon^* < \lexp[f(X_u)] \leq \mathbb{E}_{P_i}[f(X_u)]\,.
\end{equation*}
Applying Equation~\eqref{eq:lemma_converges_expectation_close} to the r.h.s. of these equalities, we find that
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - \epsilon^* < \mathbb{E}_{P}[f(X_u)] + \epsilon^*\,,\quad\text{and,}\quad \mathbb{E}_{P}[f(X_u)] - \epsilon^* < \mathbb{E}_{P_i}[f_i(X_u)] + \epsilon^*\,,
\end{equation*}
which when combined implies
\begin{equation*}
\mathbb{E}_{P_i}[f_i(X_u)] - 2\epsilon^* < \mathbb{E}_{P}[f(X_u)] < \mathbb{E}_{P_i}[f_i(X_u)] + 2\epsilon^*\,,
\end{equation*}
or in other words that $\abs{\mathbb{E}_{P_i}[f_i(X_u)] - \mathbb{E}_{P}[f(X_u)]} < 2\epsilon^*$.

Now, by the choice of $P_i$ and $P$, we have
\begin{align*}
 &\quad \abs{\lexp[f_i(X_u)]-\lexp[f(X_u)]} \\
 &\leq \abs{\lexp[f_i(X_u)] - \mathbb{E}_{P_i}[f_i(X_u)]} + \abs{\lexp[f(X_u)] - \mathbb{E}_{P}[f(X_u)]} + \abs{\mathbb{E}_{P_i}[f_i(X_u)] - \mathbb{E}_{P}[f(X_u)]} \\
 &< \epsilon^* + \epsilon^* + 2\epsilon^* = 4\epsilon^* = \epsilon\,.
\end{align*}
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:GBR_for_densities_is_limit_if_continuous}~}
We will show that, for any $\{\delta_i\}_{i\in\nats}\to 0^+$, it holds that
\begin{equation*}
\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\}\,.
\end{equation*}
So, consider any sequence $\{\delta_i\}_{i\in\nats}\to 0^+$. Note first of all that, because $\lexp[\phi(y_u\vert X_u)]>0$, and due to continuity of $\phi(y_u\vert X_u)$, we must also have $\lexp[\phi(y_u + \Delta \vert X_u)]>0$ for all $\Delta$ in some interval $(-\delta,\delta)$. Therefore, and due to monotonicity of measure, it follows that we must also have $\lexp[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]]>0$ for all $i\in\nats$.

Now, define an induced sequence $\{\mu_i\}_{i\in\nats}$ by
\begin{equation*}
\mu_i \coloneqq \underline{\mathbb{E}}_{\mathcal{Z}}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \max\left\{ \mu\in\reals : \underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu \bigr) \right] \geq 0\right\}\,,
\end{equation*}
and note in particular that then
\begin{equation*}
\underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu_i \bigr) \right] = 0\,,
\end{equation*}
for every $i\in\nats$. Hence, using Proposition~\ref{prop:decomp} we have that, for every $i\in\nats$,
\begin{equation*}
0 = \underline{\mathbb{E}}_{\mathcal{Z}}\left[ \ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\bigl( f(X_v) - \mu_i \bigr) \right] = \lexp\left[ \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]\bigl( f(X_v) - \mu_i \bigr) \right]\,.
\end{equation*}
For every $i\in\nats$, let $\lambda(\mathcal{B}_i)\coloneqq \lambda((y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2}))$ denote Lebesgue measure of the region $(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})$.
Then, by non-negative homogeneity, we have
\begin{equation}\label{eq:all_steps_zero}
0 = \lexp\left[\frac{1}{\lambda(\mathcal{B}_i)} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})}(Y_u)\vert X_u]\bigl( f(X_v) - \mu_i \bigr) \right]\,.
\end{equation}

Now, since $\mu_i = \underline{\mathbb{E}}_{\mathcal{Z}}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})]$, it follows that $\min f\leq \mu_i\leq \max f$ and therefore, that the sequence $\{\mu_i\}_{i\in\nats}$ exists in the (compact) interval $[\min f, \max f]$. Let now $\{\mu_{i_j}\}_{j\in\nats}$ be any convergent subsequence of $\{\mu_i\}_{i\in\nats}$, for which $\lim_{j\to\infty}\mu_{i_j}=:\mu_{j_*}\in[\min f,\max f]$---the existence of such a sequence is guaranteed by the Bolzano-Weierstrass theorem.

Since the sequence $\{\mu_{i_j}\}_{j\in\nats}$ is convergent, we clearly also have that the sequence $\{f(X_v)-\mu_{i_j}\}_{j\in\nats}$ in $\gambles(\states_v)$ is convergent. Furthermore, as we know from Lemma~\ref{lemma:dirac_delta_gets_density_value}, the sequence 
\begin{equation*}
\left\{\frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right\}_{j\in\nats}
\end{equation*}
in $\gambles(\states_u)$ is convergent as well. Therefore in particular, we see that
\begin{equation*}
\lim_{j\to\infty} \frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_j}) = \phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})\,.
\end{equation*}
Using Lemma~\ref{lemma:limit_lexp_is_lexp_limit}, we therefore find
\begin{equation*}
\lim_{j\to\infty} \lexp\left[\frac{1}{\lambda(\mathcal{B}_{i_j})} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_j})\right] = \lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})]\,,
\end{equation*}
and, using Equation~\eqref{eq:all_steps_zero}, that $\lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{j_*})] = 0$.

Since we know from Lemma~\ref{lemma:general_gbr_is_monotone_and_has_root} that the function $\lexp[\phi(y_u\vert X_u)(f(X_v) - \mu)]$ has a unique root (because by assumption $\lexp[\phi(y_u\vert X_u)]>0$), say $\mu_*$, we conclude from this that $\mu_{j_*}=\mu_*$. Furthermore, since the convergent subsequence $\{\mu_{i_j}\}_{j\in\nats}$ was arbitrary, we find that $\mu_*$ is the limit of \emph{every} convergent subsequence of $\{\mu_i\}_{i\in\nats}$.

We now first show that the original sequence $\{\mu_i\}_{i\in\nats}$ also converges, and that $\lim_{i\to\infty}\mu_i = \mu_{*}$. To this end, assume \emph{ex absurdo} that this is false. Then, there exists some $\epsilon\in\realspos$ such that, for every $N\in\nats$, there is some $k>N$ for which $\abs{\mu_k - \mu_{*}} \geq \epsilon$. Therefore, we can construct a subsequence $\{\mu_{i_k}\}_{k\in\nats}$ such that $\abs{\mu_{i_k}-\mu_{*}}\geq \epsilon$, for all $k\in\nats$. Using a similar argument to the above, this sequence is in the (compact) interval $[\min f, \max f]$ and therefore has a convergent subsequence $\{\mu_{i_{k_\ell}}\}_{\ell\in\nats}$, with $\lim_{\ell\to\infty}\mu_{i_{k_\ell}} =: \mu_{\ell_*}$ satisfying $\abs{\mu_{\ell_*} - \mu_{*}}\geq\epsilon$. However, the sequence $\{\mu_{i_{k_\ell}}\}_{\ell\in\nats}$ is clearly a convergent subsequence of $\{\mu_i\}_{i\in\nats}$ and hence, as we have just seen, we must have $\lim_{\ell\to\infty}\mu_{i_{k_\ell}} = \mu_{\ell_*} = \mu_{*}$. This contradicts the fact that $\abs{\mu_{\ell_*} - \mu_{*}}\geq\epsilon$ and hence, we can conclude that $\{\mu_i\}_{i\in\nats}$ converges to a $\mu_*$.

In summary, we have shown that $\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})]$ exists and is equal to $\mu_*$. The remainder of the proof is now straightforward. Since we know from Lemma~\ref{lemma:general_gbr_is_monotone_and_has_root} that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right]$ is strictly monotonically decreasing in $\mu$, and that this function has a unique root---which we know is given by $\mu_*$---we must have that $\lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] < 0$ for every $\mu>\mu_*$, 
or in other words, that
\begin{equation*}
\lim_{i\to \infty}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta_i}{2},y_u+\nicefrac{\delta_i}{2})] = \mu_* = \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\}\,.
\end{equation*}
Since this holds for every sequence $\{\delta_i\}_{i\in\nats}\to 0^+$, we conclude that indeed, as claimed,
\begin{align*}
 \underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u=y_u] %\\
&= \max\left\{ \mu\in\reals : \lexp\left[ \phi(y_u\vert X_u)\bigl(f(X_v) -\mu \bigr)\right] \geq 0\right\} \\
 &= \lim_{\delta\to 0^+}\underline{\mathbb{E}}_\mathcal{Z}[f(X_v)\vert Y_u\in (y_u-\nicefrac{\delta}{2},y_u+\nicefrac{\delta}{2})] \,.
\end{align*}
\end{proof}

%\begin{remark}
%The below contains some notes / failed proof attempts to generalise the above result to hold under regular extension.
%
%********************
%
%We next establish that this limit $\mu_{i_*}$ is independent of the exact subsequence $\{\mu_{i_j}\}_{j\in\nats}$. To this end, consider any sequence $\{\epsilon_{j}\}_{j\in\nats}\to 0^+$. Then, for all $j\in\nats$, due to the definition of $\mu_{i_j}$, it follows from Proposition~\ref{prop:GBR_regular} that there is some $P_j\in\mathcal{Z}$ such that $\mathbb{E}_{P_j}[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]]>0$, and for which
%\begin{equation*}
%\mu_{i_j}\leq \nu_j\coloneqq \frac{\mathbb{E}_{P_j}\bigl[f(X_v)\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\bigr]}{\mathbb{E}_{P_j}[\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]]} < \mu_{i_j} + \epsilon_j\,.
%\end{equation*}
%Since $\{\epsilon_j\}_{j\in\nats}\to 0^+$, and because $\{\mu_{i_j}\}_{j\in\nats}\to \mu_{i_*}$, this clearly implies that also $\{\nu_j\}_{j\in\nats}\to \mu_{i_*}$.
%
%Therefore, we see that also
%\begin{equation}\label{}
%\lim_{j\to\infty} \lexp\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = \lexp[\phi(y_u\vert X_u)(f(X_v) - \mu_{i_*})]
%\end{equation}
%Furthermore, for all $j\in\nats$, we clearly have
%\begin{align*}
% &\quad \lexp\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] \\
% &\leq
% &\quad \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] \\
% &= \frac{1}{\delta_{i_j}}\mathbb{E}_{P_j}\left[ f(X_v) \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right] - \frac{\nu_j}{\delta_{i_j}}\mathbb{E}_{P_j}\left[ \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u]\right] \\
% &= 0\,,
%\end{align*}
%from which it follows that
%\begin{equation*}
%\lim_{j\to\infty} \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = 0\,.
%\end{equation*}
%Invoking Lemma~\ref{lemma:dirac_delta_gets_density_value} once more, and taking limits separately, we find
%\begin{equation}\label{eq:precise_limit_also_approaches}
% \lim_{j\to\infty} \mathbb{E}_{P_j}\left[\frac{1}{\delta_{i_j}} \mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \nu_j)\right] = \lim_{j\to\infty} \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right] = 0\,.
%\end{equation}
%
%*** 
%
%okay, let's see if I can set the below $\epsilon$ to something useful.
%
%possible options: 
%\begin{itemize}
%\item Construct a subsequence such that precise func is non-positive, then set $\epsilon=0$.
%\item Construct a subsequence such that $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]$ are all greater than a given value, set $\epsilon$ to that value (times $\Delta$).
%\item All smaller than some value? Not sure if that helps.
%\end{itemize}
%
%Assume $\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right]>0$, which implies $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]>0$, but now furthermore assume $\lim_{j\to\infty}\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]=0$ (or at least in every convergent subsequence, which exists). This is the worst case scenario.
%
%** Show that $\abs{\tilde{\nu}_j - \nu_j}\to 0$, which implies $\tilde{\nu}_j\to\mu_{i_*}$ from the right, which means that we can get strictly in between $\mu_{i_*}$ and $\mu'$, which gives us the desired slope since we know we are exactly zero at $\tilde{\nu}_j$ and are strictly monotonically decreasing in $j$'s precise function.
%
%Maybe force $j$ such that
%\begin{align*}
%\uexp\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*}) - \frac{1}{\delta_{i_j}}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{i_*})\right] < \epsilon\,, \\
%\text{and}, \\
%\uexp\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{*}) - \frac{1}{\delta_{i_j}}\mathbb{E}_{\observs\vert\states}[\ind{(y_u-\nicefrac{\delta_{i_j}}{2},y_u+\nicefrac{\delta_{i_j}}{2})}(Y_u)\vert X_u](f(X_v) - \mu_{*})\right] < \epsilon
%\end{align*}
%This is definitely possible. Then take $\nu_j\to\mu_{i_*}$ as before. Write $\psi_j(y_u\vert X_u)$ for the delta, for convenience. We clearly have $\tilde{\nu}_j > \mu_*$.
%
%\begin{align*}
%0 &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\tilde{\nu}_j)\right] - \mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)(f(X_v)-\nu_j)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)f(X_v)-\psi_j(y_u\vert X_u)f(X_v)\right] - \tilde{\nu}_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)f(X_v)-\psi_j(y_u\vert X_u)f(X_v)\right] + \mu_{i_*}\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu_{i_*}\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &\quad\quad - \tilde{\nu}_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*})-\psi_j(y_u\vert X_u)f(X_v)\right] + (\mu_{i_*} - \tilde{\nu}_j)\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right]  \\
% &\quad\quad + \nu_j\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
% &= \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v)-\mu_{i_*})-\psi_j(y_u\vert X_u)(f(X_v)-\mu_{i_*})\right] \\
% &\quad\quad + (\mu_{i_*} - \tilde{\nu_j})\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] + (\nu_j-\mu_{i_*})\mathbb{E}_{P_j}\left[\psi_j(y_u\vert X_u)\right] \\
%\end{align*}
%
%Actually maybe go the other way. Choose $P_j$ so that $\phi$ is satisfied: $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] >0$, and
%\begin{equation*}
%\mu_* \leq \tilde{\nu}_j < \mu_* + \epsilon_j\,.
%\end{equation*}
%This also has the advantage that due to continuity, $\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] >0\Rightarrow \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)]>0$.
%
%\begin{align*}
%0 &= \mathbb{E}_{P_j}[\phi(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \mathbb{E}_{P_j}[f(X_v)\psi_j(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \mathbb{E}_{P_j}[f(X_v)\psi_j(y_u\vert X_u)] \\
% &\quad\quad - \tilde{\nu}_j\mathbb{E}_{P_j}[\phi(y_u\vert X_u)] + \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)] - \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)] \\
% &= \mathbb{E}_{P_j}[f(X_v)\phi(y_u\vert X_u) - f(X_v)\psi_j(y_u\vert X_u)] + \tilde{\nu}_j\mathbb{E}_{P_j}[\psi_j(y_u\vert X_u) - \phi(y_u\vert X_u)] \\
% &\quad\quad + \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)]
%\end{align*}
%Afschatbaar naar twee kanten, dus
%\begin{equation*}
%-\epsilon_j < \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \tilde{\nu}_j)] < \epsilon_j\,.
%\end{equation*}
%We also know that
%\begin{equation*}
%0 = \lexp[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})] \leq \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})]
%\end{equation*}
%and
%\begin{align*}
% &\quad \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})] \\
% &= \mathbb{E}_{P_j}[\psi_j(y_u\vert X_u)(f(X_v) - \mu_{i_j})]
%\end{align*}
%
%*******************
%
%New plan:
%\begin{itemize}
%\item Assume ex absurdo that $\mu_*>\mu_{i_*}$.
%\item Then we can approach the $\phi$ GBR strictly to the right of $\mu_{i_j}$, using some $\tilde{\nu}<\mu_*$, once the sequence is close enough to $\mu_{i_*}$;
%\item Far enough in the sequence, $\phi$ and $\psi_j$ become so close that we can cap the wiggle room of all precise processes;
%\item This yields a point $\tilde{\nu}>\mu_{i_j}$ for which the $\psi_j$ GBR is still non-negative, which contradicts the definition of $\mu_{i_j}$.
%\end{itemize}
%Assuming we're approaching $\mu_{i_*}$ from the left, we have
%\begin{equation*}
%\left\{\lexp[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)]\right\}_{j\in\nats} \to 0^-
%\end{equation*}
%
%Choose $P_j$ and $\nu_j$ as before. Then,
%\begin{align*}
%\lexp[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)] &\leq \mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)(f(X_v)-\mu_*)] \\
% &= \mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)(f(X_v)-\nu_j)] - (\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)] \\
% &= -(\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)] \\
% &= -(\mu_* - \nu_j)(\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)-\phi(y_u\vert X_u)] + \mathbb{E}_{P_j}[\phi(y_u\vert X_u)]) \\
% &= -(\mu_* - \nu_j)\mathbb{E}_{P_j}[\psi_{j}(y_u\vert X_u)-\phi(y_u\vert X_u)] - (\mu_* - \nu_j)\mathbb{E}_{P_j}[\phi(y_u\vert X_u)]
%\end{align*}
%
%
%*******************
%
%
%***
%
%Now, consider any $\mu'>\mu_{i_*}$, and define $\Delta\coloneqq \nicefrac{(\mu'-\mu_{i_*})}{2}$. Because $\{\nu_j\}_{j\in\nats}\to\mu_{i_*}$, there is then some $N\in\nats$ such that, for all $j>N$, it holds that $\nu_j<\mu'-\Delta$. Next, define $\epsilon\coloneqq TODO$. Due to Equation~\eqref{eq:precise_limit_also_approaches}, there is then some $N'\in\nats$ such that, for all $j>N'$, it holds that
%\begin{equation*}
%\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \nu_j)\right] < \epsilon\,.
%\end{equation*}
%Consider now any $j>\max\{N,N'\}$. Because $P_j\in\mathcal{Z}$, we then find that
%\begin{align*}
%\lexp\left[\phi(y_u\vert X_u)(f(X_v) - \mu')\right] &\leq \mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)(f(X_v) - \mu')\right] \\
% &= \mathbb{E}_{P_j}\left[f(X_v)\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% = \mathbb{E}_{P_j}\left[f(X_v)\phi(y_u\vert X_u)\right] - \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] &+ \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &< \epsilon + \nu_j\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] - \mu'\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &= \epsilon - (\mu' - \nu_j)\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
% &< \epsilon - \Delta\mathbb{E}_{P_j}\left[\phi(y_u\vert X_u)\right] \\
%\end{align*}
%
%********************
%\end{remark}


\section{Proofs and Lemmas for the Results in Section~\ref{sec:inference_algos}}

We need the following lemma for the proof of Proposition~\ref{prop:computing_product_funcs}.
\begin{lemma}\label{lemma:product_func_induction}
For all $t_i\in u'$, let $g_{t_i}$, $g_{t_i}^+$ and $g_{t_i}^-$ be as defined in Section~\ref{sec:funcs_single_time}. Then, for all $t_i\in u'$,
\begin{equation*}
g_{t_i}^+ = \lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,, \quad\quad\text{and,} \quad\quad g_{t_i}^- = \uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,.
\end{equation*}
\end{lemma}
\begin{proof}
We provide a proof by induction. Clearly, the result is trivial for $t_i=t_{n+1}$. So, assume that it is true for $i$. We show that it is then also true for $i-1$ (with $i>0$).

We focus on $g_{t_{i-1}}^+$, and consider the two cases in its definition separately. So, consider any $x_{t_{i-1}}\in\states_{t_{i-1}}$. Then, if $g_{t_{i-1}}(x_{t_{i-1}})\geq 0$, we have
\begin{align*}
g_{t_{i-1}}^+(x_{t_{i-1}}) &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[g_{t_{i}}^+(X_{t_{i}})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
 &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[\lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
 &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\ 
 &= \lexp\left[g_{t_{i-1}}(x_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right]\,,
\end{align*}
where the first equality is by definition, the second is by the induction hypothesis, the third by iterated lower expectation (Proposition REF), and the final by non-negative homogeneity of lower expectation and the assumption that $g_{t_{i-1}}(x_{t_{i-1}})\geq 0$.

For the other case, assume that $g_{t_{i-1}}(x_{t_{i-1}})< 0$. Then,
\begin{align*}
g_{t_{i-1}}^+(x_{t_{i-1}}) &= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[g_{t_{i}}^-(X_{t_{i}})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[\uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_i}\right]\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= g_{t_{i-1}}(x_{t_{i-1}})\cdot \uexp\left[\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= -g_{t_{i-1}}(x_{t_{i-1}})\cdot \lexp\left[-\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right] \\
&= \lexp\left[g_{t_{i-1}}(x_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}=x_{t_{i-1}}\right]\,,
\end{align*}
where the first equality is by definition, the second equality by the induction hypothesis, the third by iterated upper expectation (Proposition REF), the fourth by conjugacy of upper- and lower expectation, and the final by non-negative homogeneity of lower expectation and the assumption that $g_{t_{i-1}}(x_{t_{i-1}})<0$.

Since this covers both cases in the definition of $g_{t_{i-1}}^+(x_{t_{i-1}})$, we find that
\begin{equation*}
g_{t_{i-1}}^+(X_{t_{i-1}}) = \lexp\left[g_{t_{i-1}}(X_{t_{i-1}})\cdot\prod_{j=i}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}\right] = \lexp\left[\prod_{j={i-1}}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_{i-1}}\right]\,,
\end{equation*}
which concludes the proof for $g_{t_{i-1}}^+$. The proof for $g_{t_{i-1}}^-$ is completely analogous.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:computing_product_funcs}~}
By combining Lemma~\ref{lemma:product_func_induction} with iterated lower expectation (Proposition REF), we have
\begin{equation*}
\lexp\left[g_{t_0}^+(X_{t_0})\right] = \lexp\left[\lexp\left[\prod_{j=0}^{n+1}g_{t_j}(X_{t_j})\,\vert\,X_{t_0}\right]\right] = \lexp\left[\prod_{j=0}^{n+1}g_{t_j}(X_{t_j})\right] = \lexp\left[\prod_{t_i\in u'}g_{t_i}(X_{t_i})\right]\,,
\end{equation*}
and similarly for the upper expectation.
\end{proof}

\begin{proof}{\bf of Proposition~\ref{prop:arbitrary_future_functions}~}
Due to iterated lower expectation (Proposition REF), we have
\begin{equation*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\right] = \lexp\left[\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u\right]\right]\,.
\end{equation*}
Now consider any $x_u\in\states_u$. Then,
\begin{align*}
\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] &= \lexp\left[\left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\lexp\left[\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u=x_u\right] \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_u=x_u\right] - \mu\right) \\
&= \left(\prod_{i=0}^n g_{t_i}(x_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_{t_n}=x_{t_n}\right] - \mu\right)\,,
\end{align*}
where the first equality is due to the basic properties of (lower) expectation, the second by non-negative homogeneity of lower expectation and the assumption that $g_{t_i}\geq 0$, the third by basic properties of lower expectation, and the fourth by the imprecise Markov property of ICTMC's (Proposition REF), and the assumption that $u<v$.

Since this is true for all $x_u\in\states_u$, we therefore have
\begin{align*}
 &\lexp\left[\lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\bigl(f(X_v) - \mu\bigr)\,\bigl\vert\,X_u\right]\right] \\
 &\quad\quad= \lexp\left[\left(\prod_{i=0}^n g_{t_i}(X_{t_i})\right)\cdot\left(\lexp\left[f(X_v)\,\vert\,X_{t_n}\right] - \mu\right)\right]\,.
\end{align*}
\end{proof}

%\section{Computing Functions that are Products}
%
%
%
%We here adopt a small change of notation compared to the above, to prevent having to deal with special cases. Consider any $u'\in\mathcal{U}_{\emptyset}$ such that $u'=t_0,t_1,\ldots,t_n$ with $n\geq 1$, define $u\coloneqq u'\setminus t_0$ and, for all $i\in\{1,\ldots,n\}$, consider any $g_i\in\gambles(\states_{t_i})$. Let $f\in\gambles(\states_u)$ be defined as $f(x_u)\coloneqq \prod_{i=1}^n g_i(x_{t_i})$, for all $x_u\in\states_u$, with $x_{t_i}\in x_u$ for all $i\in\{1,\ldots,n\}$. We now seek to compute
%\begin{align*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[f(X_u)\vert X_{t_0}\right] &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[f(X_{t_1},\ldots,X_{t_n})\vert X_{t_0}\right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[\prod_{i=1}^ng_i(X_{t_i})\vert X_{t_0}\right]\,.
%\end{align*}
%If all the $g_i$, $i\in\{1,\ldots,n\}$, satisfy $g_i\geq 0$, we can apply the same procedure as described for functions that are sums, exchanging sums for products where appropriate. However, the general case is slightly more involved since we cannot simply factorise out the non-negative functions (i.e. lower expectations only satisfy non-negative homogeneity). However, the below dynamic programming procedure does the trick.
%
%Define $\tilde{g}_n^+\coloneqq\tilde{g}_n^-\coloneqq g_n$ and, for all $i\in\{1,\ldots,n-1\}$, define
%\begin{equation*}
%\tilde{g}_i^+(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
%g_i(x_{t_i})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^+(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})\geq 0$, and} \\
%g_i(x_{t_i})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^-(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})<0$\,,} \\
%\end{array}\right.
%\end{equation*}
%and,
%\begin{equation*}
%\tilde{g}_i^-(x_{t_i}) \coloneqq \left\{\begin{array}{ll}
%g_i(x_{t_i})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^-(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})\geq 0$, and} \\
%g_i(x_{t_i})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i+1}^+(X_{t_{i+1}}) \vert X_{t_i}=x_{t_i} \right] & \text{if $g_i(x_{t_i})<0$\,,} \\
%\end{array}\right.
%\end{equation*}
%for all $x_{t_i}\in\states_{t_i}$. Clearly, backward recursion (dynamic programming) allows us to compute all these functions in linear time w.r.t. $n$. We now have the following result.
%\begin{proposition}
%For any $i\in\{1,\ldots,n\}$, it holds that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_i^+(X_{t_i})\,\vert\, X_{t_{i-1}}] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right]\,,
%\quad\text{and,}\quad
%\overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_i^-(X_{t_i})\,\vert\, X_{t_{i-1}}] = \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right]\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%We provide a proof by (backward) induction. Clearly, the result is trivial for $i=n$. Now, assume that it is true for $i$ (with $i\geq 2$). We show that it is also true for $i-1$. Hence, we will show that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}[\tilde{g}_{i-1}^+(X_{t_{i-1}})\,\vert\, X_{t_{i-2}}] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j={i-1}}^n g_j(X_{t_j}) \vert X_{t_{i-2}} \right]\,,
%\end{equation*}
%and similarly for the second statement. We start from the definition of $\tilde{g}_{i-1}^+$, and consider the two cases in that definition separately. So, consider any $x_{t_{i-1}}\in\states_{t_{i-1}}$. Then, if $g_{i-1}(x_{t_{i-1}}) \geq 0$, we find
%\begin{align*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) &= g_{i-1}(x_{t_{i-1}})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i}^+(X_{t_{i}}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% = g_{i-1}(x_{t_{i-1}})\cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ g_{i-1}(x_{t_{i-1}})\cdot\prod_{j=i}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] 
% = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i-1}^ng_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,,
%\end{align*}
%where the first equality is by definition, the second equality follows from the induction hypothesis, the third equality follows from non-negative homogeneity of lower expectation, and the last equality follows from the basic rules of (lower) expectation (i.e., $\underline{\mathbb{E}}[f(X,Y)\vert X=x]=\underline{\mathbb{E}}[f(x,Y)\vert X=x]$).
%
%If, on the other hand, $g_{i-1}(x_{t_{i-1}}) < 0$, we find
%\begin{align*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) = g_{i-1}(x_{t_{i-1}})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i}^-(X_{t_{i}}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% &= g_{i-1}(x_{t_{i-1}})\cdot \overline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% = g_{i-1}(x_{t_{i-1}})\cdot -\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ - \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]
% &= \lvert g_{i-1}(x_{t_{i-1}})\rvert \cdot \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ - \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ -\lvert g_{i-1}(x_{t_{i-1}})\rvert\cdot \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] 
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[  g_{i-1}(x_{t_{i-1}})\cdot \prod_{j=i}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right] \\
% &= \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,,
%\end{align*}
%where the first equality is by definition, the second equality follows from the induction hypothesis, the third equality follows from conjugacy of lower- and upper expectation, the fourth equality follows from the assumption that $g_{i-1}(x_{t_{i-1}}) < 0$, the fifth equality follows from non-negative homogeneity of upper expectation, and the last equality follows from the basic rules of (lower) expectation, as above.
%
%So, in both cases, we find that
%\begin{equation*}
%\tilde{g}_{i-1}^+(x_{t_{i-1}}) = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}=x_{t_{i-1}} \right]\,.
%\end{equation*}
%Since this is true for every $x_{t_{i-1}}\in\states_{t_{i-1}}$, we now find by substitution that
%\begin{align*}
%&\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_{i-1}^+(X_{t_{i-1}}) \vert X_{t_{i-2}} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}} \right] \vert X_{t_{i-2}} \right] \\
%=&~ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-1}}, X_{t_{i-2}} \right] \vert X_{t_{i-2}} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[   \prod_{j=i-1}^n g_j(X_{t_j}) \vert X_{t_{i-2}} \right]\,,
%\end{align*}
%where the second equality follows from the imprecise Markov property of $\wprocesses_{\rateset,\mathcal{M}}$, and the third equality follows from the rule of iterated lower expectation. This concludes the proof for the first statement. The proof for the second statement is the same, \emph{mutatis mutandis}.
%\end{proof}
%In particular, the above result implies that
%\begin{equation*}
%\underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \tilde{g}_1^+(X_{t_1})\vert X_{t_0} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ \prod_{i=1}^ng(X_{t_i})\vert X_{t_0} \right] = \underline{\mathbb{E}}_{\rateset,\mathcal{M}}^\mathrm{W}\left[ f(X_u) \vert X_{t_0} \right]\,,
%\end{equation*}
%and immediately suggest an algorithm with total runtime complexity $O(n\lvert\states\rvert C)$, where $C$ is again the time complexity of evaluating $L_{t_{i-1}}^{t_i}g_i$.


\end{document}
