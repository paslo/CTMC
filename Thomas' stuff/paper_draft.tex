\documentclass[10pt]{paper}
%\documentclass[a4paper,reqno]{amsart}
\usepackage[british]{babel}
%\usepackage[garamond]{mathdesign}
\usepackage{mathptmx}
\usepackage{amsmath}
\usepackage{courier}
\usepackage{amssymb}
%\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{nicefrac}
%\usepackage{pdfsync}
%\usepackage{authblk}

\theoremstyle{definition}
\newtheorem{exmp}{Example}%[section]

\renewcommand{\ttdefault}{cmtt}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem*{remark*}{Remark}

% - macros

\newcommand{\nats}{\mathbb{N}}
\newcommand{\natswith}{\nats_{0}}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\realspos}{\reals_{>0}}
\newcommand{\realsnonneg}{\reals_{\geq 0}}

\newcommand{\states}{\mathcal{X}}

\newcommand{\paths}{\Omega}
\newcommand{\path}{\omega}

\newcommand{\power}{\mathcal{P}(\paths)}
\newcommand{\nonemptypower}{\power_{\emptyset}}
\newcommand{\events}{\mathcal{E}}
%\newcommand{\nonemptyevents}{\events^{\emptyset}}
\newcommand{\filter}[1][t]{\mathcal{F}_{#1}}
\newcommand{\eventst}[1][t]{\events_{#1}}

\newcommand{\processes}{\mathbb{P}}
\newcommand{\mprocesses}{\processes^{\mathrm{M}}}


\newcommand{\lt}{\underline{T}}
\newcommand{\lbound}{L}

\newcommand{\gambles}{\mathcal{L}}
\newcommand{\gamblesX}{\gambles(\states)} 

\newcommand{\ind}[1]{\mathbb{I}_{#1}}

\newcommand{\rateset}{\mathcal{Q}}
\newcommand{\lrate}{\underline{Q}}

\newcommand{\asa}{\Leftrightarrow}
\newcommand{\then}{\Rightarrow}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\abs}[1]{\left\vert #1 \right\vert}

\newcommand{\coloneqq}{:\!=}

\newcommand{\opinset}{\,\,\widetilde{\in}\,\,}

\newcommand{\argmin}{\arg\min}


\title{Imprecise Continuous-Time Discrete-Space Stochastic Processes}

%\author[1]{Thomas E. Krak\thanks{t.e.krak@uu.nl}}
%\author[2]{Jasper de Bock\thanks{jasper.debock@ugent.be}}
%\affil[1]{Universiteit Utrecht}
%\affil[2]{Ghent University}

\author{Thomas Krak \and Jasper de Bock}

\begin{document}

%\author{{\bf Thomas E. Krak} \\ Utrecht}
%\address{Utrecht University}
%\curraddr{}
%\email{t.e.krak@uu.nl}
%\thanks{}

%\author{{\bf Jasper de Bock} \\ Ghent}
%\address{Ghent University}

%\author{
	%{\bf Thomas E. Krak} \quad\quad {\bf Jasper de Bock} \\
%	Utrecht University \quad Ghent University \\
	%Department of Information and Computing Sciences \\
	%Princetonplein 5, De Uithof \\
	%3584 CC Utrecht \\
	%The Netherlands \\
%	\texttt{\quad\quad t.e.krak@uu.nl} \quad\quad \texttt{jasper.debock@ugent.be}
%\and
	%{\bf Jasper de Bock} \\
%	Ghent University \\
	%SYSTeMS Research Group \\
	%Technologiepark -- Zwijnaarde 914 \\
	%9052 Zwijnaarde \\ 
	%Belgium \\
%	\texttt{jasper.debock@ugent.be}
%}
\date{}
\maketitle

\begin{abstract}
Lorem ipsum.
\end{abstract}

\section{Introduction}\label{sec:introduction}

This paper is organized as follows. In Section~\ref{sec:prelim} we introduce notation and basic definitions used throughout this work. Section~\ref{sec:lower_operator} contains our definition for the lower transition operator, along with existence proofs and the connection to previous work from the literature. 

In Sections~\ref{sec:imp_markov} and~\ref{sec:imp_non_markov} we show that this lower transition operator correctly gives the lower envelope of expectation functionals with respect to sets of Markov and non-Markov processes, respectively. In Section~\ref{sec:decomp}, we extend these results to expectation functionals on multiple time points, and show that certain decomposition properties hold when the lower envelope is taken with respect to sets of non-Markov models. 

Section~\ref{sec:tractability} contains some notes on tractability aspects of  computing such lower expectations, and we describe different function classes with varying degrees of tractability. We finally close with some conclusions and an outlook to further work in Section~\ref{sec:conclusions}.

\section{Preliminaries}\label{sec:prelim}

*** introduce state space, notation for naturals, reals, ... ***

\subsection{Probability Distributions and Stochastic Processes}
Consider some finite \emph{state space} $\states=\{1,\dots,m\}$. A cadlag function from $\realsnonneg$ to $\states$ is called a \emph{path}, where cadlag means that it is right continuous for all $t\in\realsnonneg$ and that the left limit exists for all $t\in\realspos$. Let $\paths$ be the set of all paths. For any path $\path\in\paths$ and any time point $t\in\realsnonneg$, the value of $\path$ in $t$ is denoted by $\path(t)$.

A subset $E$ of $\paths$ is called an \emph{event}. The set of all events is denoted by $\power$ and we let $\nonemptypower\coloneqq\power\setminus\{\emptyset\}$. For any $t\in\realsnonneg$ and $x\in\states$, we define the elementary event
\begin{equation*}
(X_t=x)\coloneqq\{\path\in\paths\colon\path(t)=x\}.
\end{equation*}
Consider now any $t\in\realsnonneg$. We then let $\events_{\geq t}$ be the algebra that is generated by all the elementary events $X_s=x$, for $s\geq t$ and $x\in\states$.\footnote{This is the smallest subset of $\power$ that contains all these elementary events and that is furthermore closed under complements, finite unions and hence also finite intersections.} Similarly, we let $\events_{\leq t}$ be the algebra that is generated by all the elementary events $X_s=x$, for $s\leq t$ and $x\in\states$. We also define $\filter\coloneqq\events_{\leq t}\setminus\{\emptyset\}$.

\begin{definition}[Conditional Probability]\label{def:cond_prob}
A full conditional finitely additive probability measure $P$ is a real-valued map from $\power\times\nonemptypower$ to $\reals$ that satisfies the following axioms. For all $A,B\in\power$ and all \mbox{$C,D\in\nonemptypower$}:
\vspace{5pt}

\begin{enumerate}[label=F\arabic*:]
\item
$P(C\vert C)=1$;
\item
$0\leq P(A\vert C)\leq 1$;
\item
$P(A\cup B\vert C)=P(A\vert C)+P(B\vert C)$ if $A\cap B=\emptyset$;
\item
$P(A\vert D)=P(A\vert C\cap D)P(C\vert D)$ if $A\subseteq C$.
\end{enumerate}
\vspace{5pt}

\noindent
For any $A\in\power$ and $C\in\nonemptypower$, we call $P(A\vert C)$ the probability of $A$ conditional on $C$. Also, for any $A\in\power$, we use the shorthand notation $P(A)\coloneqq P(A\vert\paths)$ and then call $P(A)$ the probability of $A$.
\end{definition}

\begin{definition}[Stochastic Process]\label{def:stoch_process}
A \emph{stochastic process} is the restriction of a full conditional finitely additive probability measure $P$ to some subset $\mathcal{C}$ of $\power\times\nonemptypower$ that includes at least
\begin{equation*}
\mathcal{C^*}\coloneqq\big\{
(A,C)
\colon
C\in\filter, A\in\events_{\geq t}, t\in\realsnonneg
\big\}.
\end{equation*}
We denote the set of all such stochastic processes by $\processes$.
\end{definition}

Throughout this work, we will make extensive use of the notion of sequences of time points. For any $t,s\in\realsnonneg$ such that $t<s$, let $u$ denote any finite sequence of time points $t_0,t_1,\ldots,t_n$ such that $t=t_0 < t_1 <\ldots < t_n = s$. We use $\mathcal{U}_{[t,s]}$ to denote the set of all such sequences. Given any $u\in\mathcal{U}_{[t,s]}$, we define for all $i\in\{1,\ldots,n\}$ the terms $\Delta_i\coloneqq t_i-t_{i-1}$.  Finally, define a function $\sigma(u)$, as
\begin{equation*}
\sigma(u) \coloneqq \max\bigl\{\Delta_i\,:\,i\in\{1,\ldots,n\}\bigr\}\,.
\end{equation*}

\begin{definition}[Markov Property]\label{def:markov_property}
We say that a stochastic process $P\in\processes$ satisfies the \emph{Markov property} when, for any time sequence $0\leq t_0<t_1,\dots,t_{n}<t<s$ and set of states $x_{t_0},x_{t_1},\dots,x_{t_n},x_t,x_s\in\states$:
\begin{equation*}
P(X_s=x_s\vert X_t=x_t)=P(X_s=x_s\vert X_t=x_t,X_{t_0}=x_{t_0},X_{t_1}=x_{t_1}, \dots, X_{t_n}=x_{t_n}).
\end{equation*}
We denote the set of all stochastic processes that satisfy this Markov property by $\mprocesses$.
\end{definition}

\subsection{Functions, Operators, and Norms}
Let $\gamblesX$ denote the set of all real-valued functions on $\states$. Because $\states$ is finite, we can also interpret any function $f\in\gamblesX$ as a vector in $\reals^m$. Hence, we will in the sequel use the terms `function' and `vector' interchangeably when referring to elements of $\gamblesX$.

For any vector $f\in\gamblesX$, we let
\begin{equation*}
\norm{f}\coloneqq\norm{f}_{\infty}\coloneqq\max\{\abs {f(x)}\colon x\in\states\}
\end{equation*}
be the maximum norm. For any operator $A$ from $\gamblesX$ to $\gamblesX$ that is non-negatively homogeneous, meaning that
\begin{equation*}
A(\lambda f)=\lambda A(f)\text{ for all $f\in\gamblesX$ and all $\lambda\geq0$,}
\end{equation*}
we consider the induced operator norm
\begin{equation*}
\norm{A}\coloneqq\sup\left\{\norm{Af}\colon f\in\gamblesX,\norm{f}=1\right\}.
\end{equation*}
If $A$ is an $m\times m$ matrix, we have that
\begin{equation*}
\norm{A}
=
\max\left\{\sum_{y\in\states}\abs{A(x,y)}\colon x\in\states\right\}.
\end{equation*}

\noindent
These norms satisfy the following properties. 

\begin{proposition}
For all $f,g\in\gamblesX$, all $A,B$ from $\gamblesX$ to $\gamblesX$ that are non-negatively homogeneous, all $\lambda\in\reals$ and all $x\in\states$, we have that
\vspace{5pt}

\begin{enumerate}[label=N\arabic*:,ref=N\arabic*]
\item
$\abs{f(x)}\leq\norm{f}$
\item
$\norm{f}\geq0$
\item
$\norm{f}=0\asa f=0$
\item
$\norm{f+g}\leq\norm{f}+\norm{g}$
\item
$\norm{\lambda f}=\abs{\lambda}\norm{f}$
\item
$\norm{A}\geq0$
\item
$\norm{A}=0\asa A=0$
\item
$\norm{A+B}\leq\norm{A}+\norm{B}$
\item
$\norm{AB}\leq\norm{A}\norm{B}$
\item
$\norm{\lambda A}=\abs{\lambda}\norm{A}$
\item\label{N:normAf}
$\norm{Af}\leq\norm{A}\norm{f}$
\item
$\norm{A}=1$ if $A$ is a stochastic matrix.
\end{enumerate}
\vspace{5pt}
\end{proposition}

\noindent
Finally, for any set $\mathcal{A}$ of square matrices, we define

\begin{equation*}
\norm{\mathcal{A}}\coloneqq\sup\{\norm{A}\colon A\in\mathcal{A}\}.
\end{equation*}

\subsubsection{wat notatie voor meerdere variabelen}

*** dit kan opzich wel korter denk ik, maar kunnen we bij oppoetsen straks nog wel even checken ***

We will also find it convenient to have notation for functions defined on the state space at multiple time points.
To this end, consider any $t,s\in\realsnonneg$ such that $t<s$, and any $u\in\mathcal{U}_{[t,s]}$. We will now define
\begin{equation*}
\states^u\coloneqq \prod_{i=0}^n\states
\end{equation*}
to be the joint state space at times $t_0,\ldots,t_n$. Let $\gambles(\states^u)$ denote the set of functions on $(X_{t_0},\ldots,X_{t_n})$.

For any $t,t',s\in\realsnonneg$ such that $t<t'<s$ and any $u\in\mathcal{U}_{[t,t']}$, let $\states^{\{s\}}$ denote the state space at time $s$, and let
\begin{equation*}
\states^{u\cup\{s\}} \coloneqq \states^u\times\states^{\{s\}}
\end{equation*}
denote the joint state space at times $t_0,\ldots,t_n,s$. Similarly, for any $t,t',s,s'\in\realsnonneg$ such that $t<t'<s<s'$, any $u\in\mathcal{U}_{[t,t']}$ and $v\in\mathcal{U}_{[s,s']}$, let
\begin{equation*}
\states^{u\cup v}\coloneqq\states^u\times\states^v\,.
\end{equation*}
Let the sets of functions $\gambles(\states^{u\cup\{s\}})$ and $\gambles(\states^{u\cup v})$ be defined in the obvious manner.

For any function $f\in\gambles(\states^{\{t_0\}}\times\cdots\times\states^{\{t_n\}})$, let the norm $\norm{f}$ be defined as
\begin{equation*}
\norm{f} \coloneqq \max\left\{ f(x_{t_0},\ldots,x_{t_n})\,:\,(x_{t_0},\ldots,x_{t_n})\in \states^{\{t_0\}}\times\cdots\times\states^{\{t_n\}}\right\}\,.
\end{equation*}

For the sake of brevity, we will also write a joint state assignment as
\begin{equation*}
\left(X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\right)\equiv (X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})\,.
\end{equation*}

%In order to re-use the lower transition operator $L_t^s$ from Definition~\ref{def:low_trans}, we will finally have to introduce some conventions. Note that $L_t^s$ is a map from $\gamblesX$ to $\gamblesX$, so it is straightforward to apply to functions $g\in\gambles(\states^{\{s\}})$. This is because these functions only depend on a single variable. However, $L_t^s$ is not yet properly defined for, e.g., functions $f\in\gambles(\states^{u\cup\{s\}})$. To this end, let first 
%\begin{equation*}
%f(x_{t_0},\ldots,x_{t_n},X_{s})\in\gambles(\states^{\{s\}})
%\end{equation*}
%denote the restriction of any $f\in\gambles(\states^{u\cup\{s\}})$ to $\gambles(\states^{\{s\}})$, for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$. Similarly, for all $(x_{t_0},\ldots,x_{t_{n-1}})\in\states^{\{t_0,\ldots,t_{n-1}\}}$, let
%\begin{equation*} f(x_{t_0},\ldots,x_{t_{n-1}},X_{t_n},X_s)\in\gambles(\states^{\{t_n,s\}})\,,
%\end{equation*}
%and so forth.

\section{Precise Continuous-Time Markov Chains}

*** tralala ***

\subsection{Rate Matrices, Stochasticity, and Transition Matrices}

\begin{definition}[Rate Matrix]\label{def:rate_matrix}
A real-valued $m\times m$ matrix $Q$ is said to be a \emph{rate matrix} if

\vspace{5pt}
\begin{enumerate}[label=R\arabic*:]
\item
$\sum_{y\in\states}Q(x,y)=0$ for all $x\in\states$;
\item
$Q(x,y)\geq0$ for all $x,y\in\states$ such that $x\neq y$.
\end{enumerate}
\vspace{5pt}
\noindent
We use $\mathcal{R}$ to denote the set of all rate matrices. 
\end{definition}

Clearly, $\mathcal{R}$ is closed under finite sums and multiplication with non-negative scalars. 

\begin{definition}[Stochastic Matrix]\label{def:stoch_matrix}
A real-valued $m\times m$ matrix $A$ is said to be \emph{stochastic} if
\vspace{5pt}
\begin{enumerate}[label=S\arabic*:]
\item
$\sum_{y\in\states}A(x,y)=1$ for all $x\in\states$;
\item
$A(x,y)\geq0$ for all $x,y\in\states$.
\end{enumerate}
\vspace{5pt}
\noindent
\end{definition}

\begin{proposition}\label{prop:stochastic_from_rate_matrix}
Consider any $m\times m$ rate matrix $Q\in\mathcal{R}$, and any $0\leq \Delta \leq \nicefrac{1}{\norm{Q}}$. Let $I$ denote the $m\times m$ identity matrix. Then, the matrix $[I+\Delta Q]$ is stochastic.
\end{proposition}
\begin{proof}
Let $A=[I+\Delta Q]$. We will verify the properties from Definition~\ref{def:stoch_matrix}.

We start with property S1. Consider any $x\in\states$. Then
\begin{equation*}
\sum_{y\in\states} A(x,y) = \sum_{y\in\states} [I + \Delta Q](x,y) = \sum_{y\in\states}I(x,y) + \Delta \sum_{y\in\states}Q(x,y) = 1\,,
\end{equation*}
where we used property R1 from Definition~\ref{def:rate_matrix}.

For property S2, note that $0\leq \Delta \leq \nicefrac{1}{\norm{Q}}$. Whence, for all $x\in\states$, we have $-1\leq \Delta Q(x,x) \leq 0$, so that $[I+\Delta Q](x,x) \geq 0$. Furthermore, for all $x,y\in\states$ s.t. $x\neq y$, we have $0\leq \Delta Q(x,y) \leq 1$, so that $[I+\Delta Q](x,y)\geq 0$.
\end{proof}

\begin{proposition}\label{prop:rate_from_stochastic_matrix}
Consider any stochastic $m\times m$ matrix $A$, and any $\Delta\in\realspos$. Let $I$ denote the $m\times m$ identity matrix. Then, $[\nicefrac{1}{\Delta}\cdot(A-I)]$ is a rate matrix.
\end{proposition}
\begin{proof}
This follows from a similar argument as the proof of Proposition~\ref{prop:stochastic_from_rate_matrix}; simply verify the properties from Definition~\ref{def:rate_matrix}.
\end{proof}

\begin{definition}[Transition Matrix]\label{def:trans_matrix}
Consider any stochastic process $P\in\processes$ and any $t,s\in\realsnonneg$ such that $t<s$. Then, the \emph{transition matrix} $T_t^s$ \emph{corresponding to} $P$ is a stochastic $m\times m$ matrix that is defined by
\begin{equation*}
T_t^s(x_t, x_s) \coloneqq P(X_s=x_s\,\vert X_t=x_t)\quad\text{for all $x_s,x_t\in\states$}\,.
\end{equation*}
\end{definition}
Obviously, this transition matrix $T_t^s$ can also be regarded as a map from $\gamblesX$ to $\gamblesX$, defined for all $f\in\gamblesX$ by $T_t^s(f)\coloneqq T_t^sf$. Note that for all $x_t\in\states$ we have that
\begin{align*}
\left[T_t^sf\right](x_t) &= \sum_{x_s\in\states}f(x_s)P(X_s=x_s\,\vert\,X_t=x_t)\\
 &= \mathbb{E}_{X_s}\left[f(X_s)\,\vert\,X_t=x_t\right]\,.
\end{align*}

%\begin{proposition}\label{prop:transitionmatrixhasprocess}
%Consider any $t,s\in\realsnonneg$ such that $t<s$, and any stochastic $m\times m$ matrix $A$. Then, there is at least one stochastic process $P\in\mprocesses$ that satisfies the Markov property, and that has a corresponding transition matrix $T_t^s$ such that
%\begin{equation*}
%T_t^s = A\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%This is immediate from Definition~\ref{def:trans_matrix} and the fact that $\mprocesses$ contains all Markov processes, according to Definition~\ref{def:markov_property}.\newline
%{\bf ATTN:} Not sure how to give an in-depth argument for this, but I don't see how it could be false.
%\end{proof}

\begin{lemma}\label{lemma:transitionmatrixfactorises}
Consider any $P\in\mprocesses$. Then
\begin{equation*}
T_t^s=\prod_{k=1}^n T_{t_{k-1}}^{t_k} \coloneqq T_{t_0}^{t_1}T_{t_1}^{t_2}\cdots T_{t_{n-1}}^{t_n}
\end{equation*}
for every sequence $0\leq t=t_0<t_1<t_2,\dots,t_{n}=s$.
\end{lemma}
\begin{proof}
This property is well known and therefore stated without proof. {\bf TODO:} Ref.
\end{proof}

%\begin{proposition}\label{prop:transitionmatrix_factorized_has_process}
%Consider any $t,s\in\realsnonneg$ such that $t<s$, any sequence of time points $u\in\mathcal{U}_{[t,s]}$, and any sequence of stochastic matrices $A_1,\ldots,A_n$. Then, there is at least one stochastic process $P\in\mprocesses$ such that, for all $i\in\{1,\ldots,n\}$, $P$ has corresponding transition matrix $T_{t_{i-1}}^{t_i}$ on the interval $[t_{i-1},t_i]$, and
%\begin{equation*}
%T_{t_{i-1}}^{t_i} = A_i\,.
%\end{equation*}
%Furthermore, $P$ has a corresponding transition matrix $T_t^s$ on the interval $[t,s]$ such that
%\begin{equation*}
%T_t^s = \prod_{i=1}^n A_i\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%Should be true. Final statement is trivial assuming the first is true. First statement should be true, given that $\mprocesses$ contains \emph{all} Markov processes, and a finite sequence of well-defined stochastic matrices should be non-degenerate.
%
%{\bf ATTN:} Does need a proof though.
%\end{proof}

%\begin{lemma}\label{lemma:linear_factorization_has_process}
%Consider any $t,s\in\realsnonneg$ such that $t<s$, any bounded set of rate matrices $\mathcal{Q}\subset\mathcal{R}$, any sequence of time points $u\in\mathcal{U}_{[t,s]}$ such that $\sigma(u)<\nicefrac{1}{\norm{\mathcal{Q}}}$, and any sequence of rate matrices $Q_1,\ldots,Q_n$ such that $Q_i\in\mathcal{Q}$ for all $i\in\{1,\ldots,n\}$. 
%
%Consider the induced sequence of matrices $[I + \Delta_1 Q_1],\ldots,[I+\Delta_n Q_n]$. Then,
%\begin{enumerate}
%\item The matrix $[I+\Delta_i Q_i]$ is stochastic for all $i\in\{1,\ldots,n\}$.
%\item There is at least one stochastic process $P\in\mprocesses$ such that $T_{t_{i-1}}^{t_i}=[I+\Delta_i Q_i]$ for all $i\in\{1,\ldots,n\}$, and $T_t^s = \prod_{i=1}^n[I+\Delta_i Q_i]$.
%\end{enumerate}
%\end{lemma}
%\begin{proof}
%The first claim is immediate from Proposition~\ref{prop:stochastic_from_rate_matrix}. The second claim is immediate from Proposition~\ref{prop:transitionmatrix_factorized_has_process}.
%\end{proof}
%
%\begin{lemma}\label{lemma:exponential_matrix_has_process}
%Consider any rate matrix $Q$, any $t,s\in\realsnonneg$ such that $t<s$, and any sequence of sequences of time points $u_1,u_2,\ldots,u_n,\ldots$ such that $u_i\in\mathcal{U}_{[t,s]}$ and $\lim_{n\rightarrow\infty}\sigma(u_n)= 0$. For each $u_i$, define the stochastic matrix
%\begin{equation*}
%\Phi_i \coloneqq \prod_{k=1}^{n_i} [I+\Delta^i_k Q]\,.
%\end{equation*}
%Then, the corresponding sequence $\Phi_1,\Phi_2,\ldots,\Phi_n,\ldots$ converges, with solution
%\begin{equation*}
%\lim_{n\rightarrow\infty}\Phi_n = \exp\{(s-t)Q\}\,,
%\end{equation*}
%where the right hand side denotes the matrix exponential.
%
%Furthermore, there is at least one stochastic process $P\in\mprocesses$ such that, for all $\tau,\tau'\in[t,s]$ such that $\tau<\tau'$, this process has corresponding transition matrix
%\begin{equation*}
%T_\tau^{\tau'} = \exp\{(\tau'-\tau)Q\}\,.
%\end{equation*}
%\end{lemma}
%\begin{proof}
%The claim of convergence is well-known. The last claim is then immediate from Lemma~\ref{lemma:linear_factorization_has_process}.
%\end{proof}
%
%\begin{corollary}\label{corollary:exponential_process_approximates_everywhere_and_has_derivative}
%Consider any rate matrix $Q$ and any $t,s\in\realsnonneg$ such that $t<s$. Then, there is at least one stochastic process $P\in\mprocesses$ such that, for all $\tau\in[t,s]$, this process has corresponding transition matrix $T_t^\tau$, and
%\begin{equation*}
%(\forall \epsilon\in\realspos)(\exists \delta\in\realspos)(\forall u\in\mathcal{U}_{[t,\tau]}\,:\,\sigma(u)<\delta) \norm{T_t^\tau - \prod_{k=1}^n[I+\Delta_i Q]} < \epsilon\,.
%\end{equation*}
%Furthermore, this process' transition matrix satisfies
%\begin{equation*}
%(\forall \epsilon>0)(\exists \delta>0)(\forall \Delta\in(0,\delta))(\forall \tau\in[t,s))\norm{\frac{T_\tau^{\tau+\Delta} - I}{\Delta} - Q} < \epsilon\,.
%\end{equation*}
%\end{corollary}
%\begin{proof}
%This is immediate from Lemma~\ref{lemma:exponential_matrix_has_process}.
%\end{proof}

\subsection{Precise Continuous-Time Markov Chains}

\subsubsection{*** homogeneous version ***}
TODO

\subsubsection{*** non-homogeneous version ***}

\begin{definition}[Markov Process]\label{def:markov_process}
A stochastic process $P\in\mprocesses$ is said to be a \emph{continuous-time Markov process} if the transition matrix corresponding to $P$ satisfies
\begin{equation*}
(\forall \epsilon\in\realspos)(\exists \delta\in\realspos)(\forall \Delta\in(0,\delta))(\forall t\in\realsnonneg)(\exists Q\in\mathcal{R}) \norm{\frac{T_t^{t+\Delta} - I}{\Delta} - Q} < \epsilon\,.
\end{equation*}
\end{definition}

\begin{definition}[Characterizing Rate Matrix]\label{def:markov_process_char_matrix}
Consider any continuous-time Markov process $P$, and let $Q_t$ be a function that gives for each time point $t\in\realsnonneg$ a rate matrix $Q_t\in\mathcal{R}$. We say that $Q_t$ \emph{characterizes} $P$ if it satisfies
\begin{equation*}
(\forall \epsilon\in\realspos)(\exists \delta\in\realspos)(\forall \Delta\in(0,\delta))(\forall t\in\realsnonneg)\norm{\frac{T_t^{t+\Delta} - I}{\Delta} - Q_t} < \epsilon\,.
\end{equation*}
\end{definition}

\begin{theorem}\label{theorem:continuous_rate_matrix_has_process}
Consider any right-continuous function $Q_t$ that gives for each time point $t\in\realsnonneg$ a rate matrix $Q_t\in\mathcal{R}$, where by right-continuity we mean that for all $t\in\realsnonneg$,
\begin{equation*}
\lim_{s\downarrow t} Q_s = Q_t\,.
\end{equation*}
Then, there exists a stochastic process $P\in\mprocesses$ such that $Q_t$ characterizes $P$.
\end{theorem}
\begin{proof}
{\bf TODO.}
\end{proof}

\subsubsection{*** non-markov version (?) ***}
TODO

%\subsection{*** Ik denk dat dat brol is ***}
%
%\begin{lemma}\label{lemma:differenceproductoftransition}
%Consider two sequences $A_1,\dots,A_n$ and $B_1,\dots,B_n$ of stochastic matrixes such that, for all $i\in\{1,\dots,n\}$, $\norm{A_i-B_i}\leq c$. Then
%\begin{equation*}
%\norm{\prod_{i=1}^nA_i-\prod_{i=1}^nB_i}\leq nc
%\end{equation*}
%\end{lemma}
%\begin{proof}
%We provide a proof by induction. For $n=1$, the result is trivially true. Assume that the result holds for $n=k-1$. The following derivation then shows that it also holds for $n=k$: 
%\begin{align*}
%\norm{\prod_{i=1}^nA_i-\prod_{i=1}^nB_i}
%&=
%\norm{\prod_{i=1}^{n}A_i-\left(\prod_{i=1}^{n-1}A_i\right)B_n+\left(\prod_{i=1}^{n-1}A_i\right)B_n-\prod_{i=1}^{n}B_i}\\
%&\leq
%\left(\prod_{i=1}^{n-1}\norm{A_i}\right)\norm{A_n-B_n}+\norm{\prod_{i=1}^{n-1}A_i-\prod_{i=1}^{n-1}B_i}\norm{B_n}\\
%&\leq c + \norm{\prod_{i=1}^{n-1}A_i-\prod_{i=1}^{n-1}B_i}\leq c+(n-1)c= nc.
%\end{align*}
%\end{proof}

%\section{The Lower Transition Operator}\label{sec:lower_operator}

\section{Imprecise Continuous-Time Markov chains}
\label{sec:iCTMC}

*** starten van een set van Q's (bounded), en dan drie manieren beschouwen om imprecies te maken:

Consider any set $\rateset\subseteq\mathcal{R}$ of rate matrices. Then $\rateset$ is said to be \emph{non-empty} if $\rateset\neq\emptyset$ and $\rateset$ is said to be \emph{bounded} if $\norm{\rateset}<+\infty$. The following proposition provides a simple alternative characterisation of boundedness.

\begin{proposition}\label{prop:alternativedefforbounded}
A set of rate matrices $\rateset\subseteq\mathcal{R}$ is bounded if and only if
\begin{equation*}
\inf\left\{Q(x,x)\colon Q\in\rateset\right\}>-\infty\text{~~for all $x\in\states$.}
\end{equation*}
\end{proposition}
\begin{proof}
*** moet dit nog invullen ***
\end{proof}

\subsection{*** onder van homogene ***}

uitleggen dat het dan NIET is

\subsection{*** onder van inhomogene Markov ***}


\begin{definition}[Set of Markov Processes]\label{def:markov_process_set_new}
For any bounded set of rate matrices $\rateset$, we define the set $\mprocesses_{\rateset}$ of all continuous-time Markov processes \emph{consistent} with $\rateset$. Formally, we let $\mprocesses_{\rateset}$ be the set of all $P\in\mprocesses$ such that
\begin{align*}\label{eq:conditionforMarkov_new}
(\forall\epsilon\in\realspos)&\,
(\exists\delta\in\realspos)\,
(\forall t\in\realsnonneg)\,
(\forall\Delta\in(0,\delta))\,
(\exists Q\in\rateset)\,:\\
 &\,(\forall f\in\gamblesX)(\forall x\in\states)~
\left\lvert\frac{\mathbb{E}_{X_{t+\Delta}}[f(X_{t+\Delta})\,\vert\,X_t=x]-f(x)}{\Delta}-\left[Qf\right](x)\right\rvert<\epsilon\cdot\norm{f}\,.
\end{align*}
\end{definition}

\begin{definition}[Lower Expectation for Set of Markov Processes]\label{def:lower_markov} Consider any $t,s\in\realsnonneg$ such that $t<s$, any bounded set of rate matrices $\rateset$, and the set of corresponding continuous-time Markov processes $\mprocesses_\rateset$. Then, the \emph{lower expectation with respect to $\mprocesses_\rateset$} is defined for all $f\in\gamblesX$ and $x_t\in\states$, as
\begin{equation*}
\underline{\mathbb{E}}^\mathrm{M}[f(X_s)\,\vert\,X_t=x_t] \coloneqq \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_t=x_t]\,:\,P\in\mprocesses_\rateset\right\}\,.
\end{equation*}
\end{definition}

\subsection{*** onder van niet-Markov}

\begin{definition}[Set of Non-Markov Processes]\label{def:set_non_markov_process}
For any bounded set of rate matrices $\rateset$, we consider the set $\processes_\rateset$ of all stochastic processes \emph{consistent} with $\rateset$. Formally, we let $\processes_\rateset$ be the set of all $P\in\processes$ such that
\begin{align*}
&(\forall\epsilon\in\realspos)\,(\exists\delta\in\realspos)\,: \\
 &(\forall t\in\realsnonneg)\,(\forall\Delta\in(0,\delta))\,(\forall u\in\mathcal{U}_{[0,t]})\,(\forall(x_{t_0},\ldots,x_{t_{n-1}})\in\states^{\{t_0,\ldots,t_{n-1}\}})\,(\exists Q\in\rateset)\,: \\
 &(\forall f\in\gambles(\states^{u\cup\{t+\Delta\}}))\,(\forall x_{t_n}\in\states^{\{t_n\}}): \\
 &\abs{\frac{\mathbb{E}_{X_{t+\Delta}}[f(x_{t_0},\ldots,x_{t_n},X_{t+\Delta})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] - f(x_{t_0},\ldots,x_{t_n},x_{t_n})}{\Delta} - \left[Q f(x_{t_0},\ldots,x_{t_{n}},X_{t+\Delta})\right](x_{t_n})} \\ 
 &\quad\quad < \epsilon\cdot\norm{f}\,.
\end{align*}
\end{definition}

\begin{definition}[Lower Expectation for Set of Non-Markov Processes]\label{def:lower_non_markov} Consider any $t,s\in\realsnonneg$ such that $t<s$, any bounded set of rate matrices $\rateset$, and the set of corresponding continuous-time non-Markov processes $\processes_\rateset$. Then, the \emph{lower expectation with respect to $\processes_\rateset$} is defined for all $f\in\gamblesX$ and $x_t\in\states$, as
\begin{equation*}
\underline{\mathbb{E}}[f(X_s)\,\vert\,X_t=x_t] \coloneqq \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_t=x_t]\,:\,P\in\processes_\rateset\right\}\,.
\end{equation*}
\end{definition}

\begin{proposition}\label{prop:markov_set_subset_of_nonmarkov_set}
Consider any bounded set of rate matrices $\rateset$, and the corresponding sets $\mprocesses_\rateset$ and $\processes_\rateset$ of continuous-time Markov processes and non-Markov processes, respectively. Then,
\begin{equation*}
\mprocesses_\rateset \subseteq \processes_\rateset\,.
\end{equation*}
\end{proposition}
\begin{proof}
This is immediate from Definitions \ref{def:markov_process_set_new} and \ref{def:set_non_markov_process}.
\end{proof}

\begin{proposition}\label{prop:lower_exp_markov_bounded_by_nonmarkov}
Consider any $t,s\in\realsnonneg$ such that $t<s$, any bounded set of rate matrices $\rateset$, any $f\in\gamblesX$, and any $x_t\in\states$. Then,
\begin{equation*}
\underline{\mathbb{E}}^\mathrm{M}[f(X_s)\,\vert\,X_t=x_t] \geq \underline{\mathbb{E}}[f(X_s)\,\vert\,X_t=x_t]\,.
\end{equation*}
\end{proposition}
\begin{proof}
This is immediate from Definitions \ref{def:lower_markov} and \ref{def:lower_non_markov}, and Proposition \ref{prop:markov_set_subset_of_nonmarkov_set}.
\end{proof}

\section{An important lower transition operator}
\label{sec:lowertrans}




*** het doel van deze sectie is om $\lbound_t^s$ te defini\"eren, te bewijzen dat die aan de differentiaalvergelijkingen van Damjan voldoet, en uit te leggen dat deze operator `makkelijk' uit te rekenen is (via de methodes van Damjan of die van Stavros) ***

*** the subsections I introduce here are not final, I'm just trying to organise things a bit ***


\subsection{Lower Transition (Rate) Operators}

\begin{definition}[Lower Transition Rate Operator]\label{def:coh_low_trans_rate}
We will call a map $\lrate$ from $\gamblesX$ to $\gamblesX$ a lower transition rate operator if, for all $f,g\in\gamblesX$, $\lambda\geq0$ and $\mu\in\reals$:

\vspace{5pt}
\begin{enumerate}[label=LR\arabic*:,ref=LR\arabic*]
\item\label{LR:constantzero}
$\lrate(\mu)=0$;
\item\label{LR:subadditive}
$\lrate(f+g)\geq\lrate(f)+\lrate(g)$;
\item\label{LR:homo}
$\lrate(\lambda f)=\lambda\lrate(f)$;
\item\label{LR:nondiagpos}
$\lrate(\ind{y})(x)\geq0$ for all $x,y\in\states$ such that $x\neq y$.
\end{enumerate}
\vspace{5pt}
\end{definition}


\begin{definition}[Lower Transition Operator]\label{def:coh_low_trans}
We will call a map $\lt$ from $\gamblesX$ to $\gamblesX$ a lower transition operator if, for all $f,g\in\gamblesX$ and $\lambda\geq0$:

\vspace{5pt}
\begin{enumerate}[label=C\arabic*:]
\item
$\lt f\geq\min f$
\item
$\lt(f+g)\geq\lt(f)+\lt(g)$;
\item
$\lt(\lambda f)=\lambda\lt(f)$.
\end{enumerate}
\vspace{5pt}
\end{definition}

\begin{lemma}\label{lemma:completemetricspace}
The set of all lower transition operators is a complete metric space.
\end{lemma}
\begin{proof}
Since a coherent lower transition operator is just a finite vector of coherent lower previsions, this result should follow fairly easily for the (known) fact that the set of all coherent lower previsions (on a given fixed space) is a complete metric space.
\end{proof}

\begin{lemma}\label{lem:normlratefinite}
Let $\lrate$ be a lower transition rate operator. Then $0\leq\norm{\lrate}<+\infty$.
\end{lemma}
\begin{proof}
*** TO BE COMPLETED ***
\end{proof}

We now first establish the connection between coherent lower transition rate operators and coherent lower transition operators. We will assume that we are given some coherent lower transition rate operator $\lrate$.

\begin{lemma}\label{lemma:normQsmallenough}
If $0\leq\Delta\norm{\lrate}\leq1$, then $(I+\Delta\lrate)$ is a lower transition operator.
\end{lemma}
\begin{proof}
Just check each of the three defining properties. C2 and C3 are trivial. C1 requires a bit more work.
\end{proof}

\begin{lemma}\label{lemma:compositioncoherence}
If $\lt_1,\lt_2,\dots,\lt_n$ are lower transition operators, then  $\lt_1\lt_2\cdots\lt_n$ is also a lower transition operator.
\end{lemma}
\begin{proof}
Simply check each of the properties.
\end{proof}

\begin{lemma}\label{lemma:productiscoherent}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$. Then
\begin{equation*}
\prod_{k=i}^n(I+\Delta_i\lrate)
\end{equation*}
is a lower transition operator.
\end{lemma}
\begin{proof}
Trivial consequence of Lemma~\ref{lemma:normQsmallenough} and~\ref{lemma:compositioncoherence}.
\end{proof}

\subsection{*** The operator of interest ***}

\begin{definition}[Lower Transition Operator]\label{def:low_trans}

Consider any $t,s\in\realsnonneg$ such that $t<s$ and let $\lrate$ be an arbitrary coherent lower transition rate operator . The corresponding \emph{lower transition operator} $\lbound_t^s$ is then a map from $\gamblesX$ to $\gamblesX$, defined by
\begin{equation}\label{eq:lowerbound}
\lbound_t^s\coloneqq\lim_{\sigma(u)\to0}\prod_{k=1}^n(I+\Delta_k\lrate),
\end{equation}
where the limit is taken with respect to the set $\mathcal{U}_{[t,s]}$ of all finite sequences of time points that partition the interval $[t,s]$.
\end{definition}

\noindent The remainder of this section establishes that the limit in Equation~\eqref{eq:lowerbound} exists, and that it is a coherent lower transition operator.

The proof basically works as follows. In Lemmas~\ref{lemma:normofcoherenttrans}-\ref{lemma:differencebetweennested}, we first establish bounds on the norm of the difference between various coherent lower transition operators.

For any $u\in\mathcal{U}_{[t,s]}$, we then define the operator
\begin{equation*}
\Phi_u\coloneqq\prod_{k=1}^n(I+\Delta_k\lrate)\,,
\end{equation*}
so that for any sequence $u_1,u_2,\ldots,u_n,\ldots$, we can obtain a corresponding sequence $\Phi_{u_1},\Phi_{u_2},\ldots,\Phi_{u_n},\ldots$ of operators. Using the previously established bounds, Corollary~\ref{corol:limitexistsandiscoherent} establishes that if we choose $u_1,u_2,\ldots,u_n,\ldots$ such that $\lim_{n\rightarrow\infty}\sigma(u_n)=0$, the corresponding sequence $\Phi_{u_1},\Phi_{u_2},\ldots,\Phi_{u_n},\ldots$ converges, and that its limit point is a coherent lower transition operator. Theorem~\ref{theo:convergencelowerbound} finally establishes that this limit is furthermore unique. Thus, we show that the limit in Equation~\eqref{eq:lowerbound} exists, and that $L_t^s$ is a coherent lower transition operator. 

We begin with some bounds on norms.

\begin{lemma}\label{lemma:normofcoherenttrans}
For any coherent lower transition operator $\lt$, we have that $\norm{\lt}\leq 1$.
\end{lemma}
\begin{proof}
This can be shown to follow from coherence.
\end{proof}

\begin{lemma}\label{lemma:differencenormofcoherenttrans}
For any coherent lower transition operator $\lt$ and any two non-negatively homogeneous operators $A$, $B$, we have that $\norm{\lt A-\lt B}\leq \norm{A-B}$.
\end{lemma}
\begin{proof}
This can be shown to follow from coherence.
\end{proof}

\begin{lemma}\label{lemma:differencenormofcoherenttransrate}
Consider any two non-negatively homogeneous operators $A$, $B$. It then holds that $\norm{\lrate A-\lrate B}\leq 2\norm{\lrate}\norm{A-B}$.
\end{lemma}
\begin{proof}
This can be shown to follow from the definition of the norm and the properties of $\lrate$.
\end{proof}


\begin{lemma}\label{lemma:justtheindicator}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}\leq\Delta\norm{\lrate}.
\end{equation*}
\end{lemma}
\begin{proof}
See Lemma~\ref{lemma:justtheindicator_appendix} in the appendix.
\end{proof}

\begin{lemma}\label{lemma:justthelinearpart}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\leq\Delta^2\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
See Lemma~\ref{lemma:justthelinearpart_appendix} in the appendix.
\end{proof}

\begin{lemma}\label{lemma:differencebetweennested}
For any $k\in\{1,\dots,n\}$, consider a sequence of $\Delta_{k,i}>0$, $i=1,\dots,n_k$ and let $\Delta_k\coloneqq\sum_{i=1}^{n_k}\Delta_{n,k}$. Let $\Delta\coloneqq\sum_{k=1}^n\Delta_k$ and let $\alpha\coloneqq\max\{\Delta_k\colon k\in\{1,\dots,n\}\}$. If $\alpha\leq\nicefrac{1}{\norm{\lrate}}$, then
\begin{equation*}
\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}
\leq\alpha\Delta\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
See Lemma~\ref{lemma:differencebetweennested_appendix} in the appendix.
\end{proof}

\noindent For any $u\in\mathcal{U}_{[t,s]}$, we now let
\begin{equation*}
\Phi_u\coloneqq\prod_{k=1}^n(I+\Delta_k\lrate)\,.
\end{equation*}

\begin{proposition}\label{prop:differencebetweenu}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and any $u,u^*\in\mathcal{U}_{[t,s]}$ such that $\sigma(u)<\alpha$ and $\sigma(u^*)<\alpha$, with $0<\alpha\leq\nicefrac{1}{\norm{\lrate}}$. Let $\Delta\coloneqq s-t$. Then,
\begin{equation*}
\norm{\Phi_u-\Phi_{u^*}}\leq 2\alpha\Delta\norm{\lrate}^2
\end{equation*}
\end{proposition}
\begin{proof}
Consider any $u'\in\mathcal{U}_{[t,s]}$ that is finer than $u$ and $u^*$, meaning that the timepoints it consists of contain the timepoints in $u$ and the timepoints in $u^*$. For example, let $u'$ be the ordered union of the timepoints in $u$ and $u^*$.

This implies that, for all $k\in\{1,\dots,n\}$, there is some sequence $\Delta_{k,i}>0$, $i\in\{1,\dots,n_k\}$, such that $\Delta_k=\sum_{i=1}^{n_k}\Delta_{k,i}$ and
\begin{equation*}
\Phi_{u'}\coloneqq\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right).
\end{equation*}
It then follows from Lemma~\ref{lemma:differencebetweennested} that $\norm{\Phi_{u'}-\Phi_u}\leq\alpha\Delta\norm{\lrate}^2$. 

Similarly, for all $k\in\{1,\dots,n^*\}$, there is some sequence $\Delta^*_{k,i}>0$, $i\in\{1,\dots,n^*_k\}$, such that $\Delta^*_k=\sum_{i=1}^{n^*_k}\Delta^*_{k,i}$ and
\begin{equation*}
\Phi_{u'}\coloneqq\prod_{k=1}^{n^*}\left(\prod_{i=1}^{n^*_k}(I+\Delta^*_{k,i}\lrate)\right).
\end{equation*}
It then follows from Lemma~\ref{lemma:differencebetweennested} that $\norm{\Phi_{u'}-\Phi_{u^*}}\leq\alpha\Delta\norm{\lrate}^2$.

Hence, we find that
\begin{equation*}
\norm{\Phi_{u}-\Phi_{u^*}}
=
\norm{\Phi_{u}-\Phi_{u'}+\Phi_{u'}-\Phi_{u^*}}
\leq
\norm{\Phi_{u}-\Phi_{u'}}
+
\norm{\Phi_{u'}-\Phi_{u^*}}
\leq2\alpha\Delta\norm{\lrate}^2.
\end{equation*}
\end{proof}

\begin{corollary}\label{corol:cauchy}
For every sequence $u_1,u_2,\dots,u_n,\dots$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{n\to\infty}\sigma(u_n)=0$, the corresponding sequence $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ is a \emph{cauchy sequence}, meaning that
\begin{equation*}
(\forall \epsilon>0)(\exists N\in\nats)(\forall n,m\geq N)
\norm{\Phi_{u_n}-\Phi_{u_m}}<\epsilon.
\end{equation*}
\end{corollary}
\begin{proof}
This follows almost directly from Proposition~\ref{prop:differencebetweenu}.
\end{proof}

\begin{corollary}\label{corol:limitexistsandiscoherent}
For every sequence $u_1,u_2,\dots,u_n,\dots$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{n\to\infty}\sigma(u_n)=0$, the corresponding sequence $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ converges to a coherent lower transition operator.
\end{corollary}
\begin{proof}
Since $\lim_{n\to\infty}\sigma(u_n)=0$, and because of Lemma~\ref{lemma:productiscoherent}, there is some index $i$ such that the sequence $\Phi_{u_i},\Phi_{u_{i+1}},\dots,\Phi_{u_n},\dots$ consists of coherent lower transition operators. Due to Corollary~\ref{corol:cauchy}, this sequence is cauchy and therefore, because of Lemma~\ref{lemma:completemetricspace}, this sequence has a limit that is also a coherent lower transition operator. Since the limit starting from $i$ and the limit starting from $1$ are identical (initial elements do not influence the limit), we find that the sequence $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ has a limit, and that this limit is a coherent lower transition operator.
\end{proof}

\begin{theorem}\label{theo:convergencelowerbound}
For any $t,s\in\realsnonneg$ such that $t<s$ and any coherent lower transition rate operator $\lrate$, there is a coherent lower transition operator $\lbound_t^s$ such that 
\begin{equation*}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall u\in\mathcal{U}_{[t,s]}\colon\sigma(u)<\delta)~\norm{\lbound_t^s - \prod_{k=1}^n(I+\Delta_k\lrate)}<\epsilon.
\end{equation*}
\end{theorem}
\begin{proof}
Consider any sequence $u_1,u_2,\dots,u_n,\dots$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{n\to\infty}\sigma(u_n)=0$. Due to Corollary~\ref{corol:limitexistsandiscoherent}, the sequence $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ converges to a coherent lower transition operator, which we denote by $\lbound_t^s$. 

Consider now any $\epsilon>0$ and let $\Delta\coloneqq s-t$ and
\begin{equation*}
\delta\coloneqq\min\left\{\frac{\epsilon}{4\Delta\norm{\lrate}^2},\frac{1}{\norm{\lrate}}\right\}.
\end{equation*}

\noindent Since $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ converges to $\lbound_t^s$, there is some $N\in\nats$ such that
\begin{equation*}
(\forall n\geq N)~\norm{\lbound_t^s - \Phi_{u_n}}<\frac{\epsilon}{2}.
\end{equation*}
Therefore, since $\lim_{n\to\infty}\sigma(u_n)=0$, there is some $N^*\geq N$ such that
\begin{equation*}
\sigma(u_{N^*})<\delta\text{ and }\norm{\lbound_t^s - \Phi_{u_{N^*}}}<\frac{\epsilon}{2}
\end{equation*}

\noindent Consider now any $u\in\mathcal{U}_{[t,s]}$ such that $\sigma(u)<\delta$. Then

\begin{equation*}
\norm{\lbound_t^s - \Phi_u}\leq\norm{\lbound_t^s-\Phi_{u_{N^*}}}
+\norm{\Phi_{u_{N^*}}-\Phi_u}
<\frac{\epsilon}{2}+2\delta\Delta\norm{\lrate}^2\leq\epsilon,
\end{equation*}
where the strict inequality follows from Proposition~\ref{prop:differencebetweenu}.
In summary, we have shown that there is some coherent lower transition operator $\lbound_t^s$ such that
\begin{equation*}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall u\in\mathcal{U}_{[t,s]}\colon\sigma(u)<\delta)~\norm{\lbound_t^s - \Phi_u}<\epsilon\,.
\end{equation*}
\end{proof}

\subsection{Derivatives, Relation to previous work, computations}

The derivative of $\lbound_t^s$ with respect to $t$ satisfies differential equations in the style of Damjan.

\begin{proposition}\label{prop:lower_transition_has_deriv}
Consider any $t,s\in\realsnonneg$ such that $t<s$, let $\lrate$ be an arbitrary coherent lower transition rate operator and let $\lbound_t^s$ be the corresponding lower transition operator. Then $\frac{d}{dt}\lbound_t^s=-\lrate\lbound_t^s$ and $\frac{d}{ds}\lbound_t^s=\lbound_t^s\lrate$, meaning that
\begin{equation}\label{eq:lower_deriv_backward}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall\Delta\,:\,0<\lvert\Delta\rvert <\delta)~
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert<\epsilon
\end{equation}
and
\begin{equation}\label{eq:lower_deriv_forward}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall\Delta\,:\,0<\lvert\Delta\rvert<\delta)~
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert<\epsilon.
\end{equation}
\end{proposition}
\noindent The proof for the above proposition can be found in Appendix~\ref{sec:proof_appendix}.

\section{*** Simple functions ***}

\subsection{Onderenveloppe dualiteit Q Qonder}

One of the objectives of this paper is to establish a connection between the operator $\lbound_t^s$ that we have just introduced, and the different types of imprecise continous-time Markov chains that were discussed in Section~\ref{sec:iCTMC}. Since the former is derived from a lower transition rate operator $\lrate$ and the latter are derived from a non-empty bounded set of rate matrices $\rateset$, the obvious first step is to investigate the connection between lower transition rate operators and non-empty bounded sets of rate matrices.
% $\rateset$ and $\lrate$. 
%In order to do that, we start by discussing some properties of sets of rate matrices.

We start by considering a non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices. For any $f\in\gamblesX$,
\begin{equation}\label{eq:correspondinglowertrans}
\lrate f\coloneqq\inf\{Qf\colon Q\in\rateset\}\\[2mm]
\end{equation}
is then again an element of $\gamblesX$.\footnote{%Since $\rateset$ is non-empty, the components of $\lrate f$ cannot be $+\infty$.
Since $\rateset$ is bounded,~\ref{N:normAf} implies that $\norm{Qf}\leq\norm{Q}\norm{f}<+\infty$ for all $Q\in\rateset$. Therefore, and since $\rateset$ is non-empty, the components of $\lrate f$ cannot be infinite. Hence, $\lrate f$ is a real-valued function on $\states$.}
Therefore, $\lrate$ is a map from $\gamblesX$ to $\gamblesX$. We call this operator $\lrate$, as defined by Equation~\eqref{eq:correspondinglowertrans}, the \emph{lower envelope} of $\rateset$. It is a matter of straightforward verification to see that $\lrate$ is a lower transition operator.

\begin{proposition}\label{prop:lowerenvelopeislowertrans}
For any non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices, the corresponding operator $\lrate\colon\gamblesX\to\gamblesX$, as defined by Equation~\eqref{eq:correspondinglowertrans}, is a lower transition rate operator.
\end{proposition}
\begin{proof}
Consider any $Q\in\rateset$. It then follows from Definition~\ref{def:rate_matrix} that the matrix $Q$, when regarded as a map from $\gamblesX$ to $\gamblesX$, satisfies \ref{LR:constantzero}--\ref{LR:nondiagpos}. Since each of these properties is preserved under taking lower envelopes, it follows that $\lrate$ satisfies \ref{LR:constantzero}--\ref{LR:nondiagpos}, which means that $\lrate$ is a lower transition rate operator.
\end{proof}

\noindent
Inspired by this result, we will also refer to the lower envelope of $\rateset$ as the \emph{lower transition rate operator that corresponds to $\rateset$}. %As we have just seen, every non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices has such a corresponding lower transition rate operator $\lrate$. 
However, this correspondence is not one-to-one. As the following example establishes, different non-empty bounded sets of rate matrices may have the same corresponding lower transition rate operator.

\begin{exmp}
*** TO BE COMPLETED ***
\end{exmp}

Next, we consider some fixed lower transition rate operator $\lrate$.
All the non-empty bounded sets $\rateset$ of rate matrices that have $\lrate$ as their lower envelope then share a common property: they consist of rate matrices $Q$ that dominate $\lrate$, in the sense that $Qf\geq\lrate f$ for all $f\in\gamblesX$. Therefore, each of these sets $\rateset$ is contained in the following set of dominating rate matrices:
\begin{equation}\label{eq:dominatingratematrices}
\rateset_{\lrate}\coloneqq
\left\{
Q\in\mathcal{R}
\colon
Qf\geq\lrate f\text{ for all $f\in\gamblesX$}
\right\}.
\end{equation}
As our next result shows, this set $\rateset_{\lrate}$ is non-empty and bounded, and has $\lrate$ as its lower envelope. Even stronger, the infimum in Equation~\eqref{eq:correspondinglowertrans} is reached---can be replaced by a minimum.

\begin{proposition}
Consider a lower transition rate operator $\lrate$ and let $\rateset_{\lrate}$ be the corresponding set of dominating rate matrices, as defined by Equation~\eqref{eq:dominatingratematrices}. Then $\rateset_{\lrate}$ is non-empty and bounded and, for all $f\in\gamblesX$, there is some $Q\in\rateset_{\lrate}$ such that $\lrate f=Qf$.
\end{proposition}
\begin{proof}
Fix any $f\in\gamblesX$. Choose $\Delta>0$ small enough such that $0\leq\Delta\norm{\lrate}\leq 1$ (this always possible because of Lemma~\ref{lem:normlratefinite}). Define $\lt\coloneqq I+\Delta\lrate$. Since $\lrate$ is a lower transition rate operator, it follows from Lemma~\ref{lemma:normQsmallenough} that $\lt$ is a lower transition operator. For any $x\in\states$, we now let
\begin{equation*}
\lt_xg\coloneqq(\lt g)(x)
\text{~~for all $g\in\gamblesX$.}
\end{equation*}
Since $\lt$ is a lower transition operator, it follows that $\lt_x\colon \gamblesX\to\reals$ is subadditive, positively homogeneous and bounded below by the minimum operator. Hence, by definition~\cite[Definition~2.3.3]{Walley:1991vk}, $\lt_x$ is a coherent lower prevision on $\gamblesX$. Because of \cite[Theorem~3.3.3(b)]{Walley:1991vk}, this implies the existence of an expectation operator $E_x$ on $\gamblesX$---Reference~\cite{Walley:1991vk} calls this a linear prevision on $\gamblesX$---such that $E_xg\geq\lt_xg$ for all $g\in\gamblesX$ and $E_xf=\lt_xf$. Let $P_x$ be the unique probability mass function that corresponds to $E_x$. For all $x,y\in\states$, we now let $T(x,y)\coloneqq P_x(y)\coloneqq E_x(\ind{x})$. Then $T$ is clearly a stochastic matrix. Furthermore, for every $x\in\states$ and $g\in\gamblesX$, we have that $(Tg)(x)=E_xg$. Hence, it follows that $Tg\geq\lt g$ for all $g\in\gamblesX$ and that $Tf=\lt f$. Now let $Q\coloneqq\nicefrac{1}{\Delta}(T-I)$, which, because of Proposition~\ref{prop:rate_from_stochastic_matrix}, is a rate matrix. Since $Tf=\lt f$, it then follows that
\begin{equation*}
Qf=\frac{1}{\Delta}(Tf-f)\geq\frac{1}{\Delta}{\lt f-f}=\lrate f.
\end{equation*}
Similarly, since $Tg\geq\lt g$ for all $g\in\gamblesX$, it follows that $Qg\geq\lrate g$, or equivalently, since $Q$ is a rate matrix, that $Q\in\rateset_{\lrate}$. Since $f$ was arbitrary, this proofs that, for all $f\in\gamblesX$, there is some $Q\in\rateset_{\lrate}$ such that $Qf=\lrate f$. Since $\gamblesX$ is non-empty, this clearly implies that $\rateset_{\lrate}$ is non-empty.

We end this proof by showing that $\rateset_{\lrate}$ is bounded. Consider any $x\in\states$. Then for all $Q\in\rateset_{\lrate}$, we have that $Q(x,x)=(Q\ind{x})(x)\geq(\lrate\ind{x})(x)$, which implies that
\begin{equation*}
\inf\left\{Q(x,x)\colon Q\in\rateset_{\lrate}\right\}\geq(\lrate\ind{x})(x)>-\infty.
\end{equation*}
Since $x\in\states$ is arbitary, Proposition~\ref{prop:alternativedefforbounded} now guarantees that $\rateset_{\lrate}$ is bounded. 
\end{proof}

\noindent
Because of this result, and since---as discussed above---every non-empty bounded set of rate matrices that has $\lrate$ as its lower envelope is a subset of $\rateset_{\lrate}$, it follows that $\rateset_{\lrate}$ is the largest non-empty bounded set of rate matrices that has $\lrate$ as its lower envelope.
Furthermore, as we will show in proposition~\ref{prop:dominatingproperties} below, this set $\rateset_{\lrate}$ is also closed and convex, and has \emph{separately specified rows}.

\begin{definition}
A set of rate matrices $\rateset\subseteq\mathcal{R}$ has separately specified rows if
\begin{equation*}
\rateset=\left\{
Q\in\mathcal{R}
\colon
(\forall x\in\states)~Q(x,\cdot)\in\rateset_x\right\},
\end{equation*}
where, for every $x\in\states$, $\rateset_x\coloneqq\{Q(x,\cdot)\colon Q\in\rateset\}$ is some set of rows from which the $x$-th row of the rate matrices in $\rateset$ are taken.
\end{definition}
Thus, a set of rate matrices has separately specified rows if it is closed under taking arbitrary combinations of rows from its elements.

\begin{proposition}\label{prop:dominatingproperties}
Consider a lower transition rate operator $\lrate$ and let $\rateset_{\lrate}$ be the corresponding set of dominating rate matrices, as defined by Equation~\eqref{eq:dominatingratematrices}. Then $\rateset_{\lrate}$ is closed and convex, and has separately specified rows.
\end{proposition}
\begin{proof}
*** TO BE COMPLETED ***
\end{proof}


\begin{exmp}
*** TO BE COMPLETED ***
\end{exmp}

\noindent
These additional properties characterise $\rateset_{\lrate}$ completely, in the sense that no other set satisfies them.

\begin{proposition}
Consider any non-empty, bounded, closed and convex set of rate matrices $\rateset\subseteq\mathcal{R}$ with separately specified rows that has $\lrate$ as its lower envelope. Then $\rateset=\rateset_{\lrate}$.
\end{proposition}
\begin{proof}
*** TO BE COMPLETED ***
\end{proof}

We conclude from all of this that non-empty bounded sets of rate matrices are more informative than lower transition rate matrices. Different non-empty bounded sets of rate matrices $\rateset$ may have the same lower transition rate operator $\lrate$ and therefore, in general, knowledge of $\lrate$ does not suffice to reconstruct $\rateset$; we can only reconstruct an outer approximation $\rateset_{\lrate}$, which is guaranteed to include $\rateset$. This changes if, besides non-empty and bounded, $\rateset$ is also closed and convex and has separately specified rows. In that case, $\lrate$ serves as an alternative representation for $\rateset$ because, since $\rateset=\rateset_{\lrate}$, we can use $\lrate$ to reconstruct $\rateset$. In other words: there is a one-to-one correspondence between lower transition rate operators and non-empty, bounded, closed and convex sets of rate matrices that have separately specified rows.

%\section{Imprecise Continuous-Time Markov Chains}\label{sec:imp_markov}

%\subsection{New Version}

%This section contains the new, simplified proofs.

\subsection{*** Inequality ***}

%\begin{theorem}\label{theorem:markov_single_var_lower_bounded_new}
%*** gaat weg want speciaal geval van *** Consider any $t,s\in\realsnonneg$ such that $t<s$ and let $\rateset$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then for any $P\in\mprocesses_\rateset$ and $f\in\gamblesX$:
%\begin{equation*}
%\left[\lbound_t^sf\right](x)\leq \left[T_t^sf\right](x).
%\end{equation*}
%\end{theorem}
%\begin{proof}
%Consider any $P\in\mprocesses_\rateset$, any $t,s\in\realsnonneg$ such that $t<s$, and any $f\in\gamblesX$. We will show that for all $\epsilon\in\realspos$,
%\begin{equation*}
%\left[L_t^sf\right](x) < \left[T_t^sf\right](x)+\epsilon\,,
%\end{equation*}
%which then implies $\left[\lbound_t^sf\right](x)\leq \left[T_t^sf\right](x)$. Start by choosing any $\epsilon\in\realspos$.
%
%Let $C\coloneqq (s-t)$. Because $P\in\mprocesses_\rateset$, it follows from Definition~\ref{def:markov_process_set_new} that there is some $\delta\in\realspos$ such that
%\begin{align}
%&(\forall \tau\in\realsnonneg)\,
%(\forall\Delta\in(0,\delta))\,
%(\exists Q\in\rateset)\,:\\
% &\,(\forall g\in\gamblesX)(\forall x\in\states)~
%\left\lvert\frac{\mathbb{E}_{X_{\tau+\Delta}}[g(X_{\tau+\Delta})\,\vert\,X_\tau=x]-g(x)}{\Delta}-\left[Qg\right](x)\right\rvert<\frac{\epsilon}{2C\norm{f}}\cdot\norm{g}.\label{eq:markov_single_var_precise_approx}
%\end{align}
%Furthermore, it follows from Theorem~\ref{theo:convergencelowerbound} that there is some $\delta'\in\realspos$ such that
%\begin{equation}\label{eq:markov_single_var_lower_trans_approx}
%(\forall u\in\mathcal{U}_{[s,t]}\,:\,\sigma(u)<\delta')\,(\forall x\in\states)\,\left\lvert \left[L_t^sf\right](x) - \left[\prod_{k=1}^n(I+\Delta_i\lrate)f\right](x)\right\rvert < \frac{\epsilon}{2}\,.
%\end{equation}
%Let $\delta^*\coloneqq\min\{\delta,\delta'\}$, and choose any $n>\nicefrac{C}{\delta^*}$. Then, for $\Delta\coloneqq\nicefrac{C}{n}$, we have $\Delta<\delta$ and $\Delta<\delta'$.
%
%Equation~\eqref{eq:markov_single_var_precise_approx} now implies that for all $\tau\in\realspos$, there is a $Q_\tau\in\rateset$ such that
%\begin{equation}\label{eq:markov_single_var_precise_bound}
%\left[(I + \Delta Q_\tau)f\right](x) - \frac{\Delta\epsilon}{2C} < \mathbb{E}_{X_{\tau+\Delta}}[f(X_{\tau+\Delta})\,\vert\,X_\tau=x]\,,\quad\text{for all $x\in\states$}\,.
%\end{equation}
%Furthermore, Equation~\eqref{eq:markov_single_var_lower_trans_approx} implies that
%\begin{equation}\label{eq:markov_single_var_lower_bound}
%\left[L_t^sf\right](x) - \frac{\epsilon}{2} < \left[(I+\Delta\lrate)^nf\right](x)\,,\quad\text{for all $x\in\states$}\,.
%\end{equation}
%
%Now, we have
%\begin{align*}
%\left[T_t^sf\right](x) &= \mathbb{E}_{X_{s}}[f(X_{s})\,\vert\,X_t=x] \\
% &= \mathbb{E}_{X_{s-\Delta}}\left[\mathbb{E}_{X_s}[f(X_s)\,\vert\,X_{s-\Delta},X_t=x]\,\vert\,X_t=x\right] \\
% &= \mathbb{E}_{X_{s-\Delta}}\left[\mathbb{E}_{X_s}[f(X_s)\,\vert\,X_{s-\Delta}]\,\vert\,X_t=x\right]\,,
%\end{align*}
%where the last step made use of the Markov property. From Equation~\ref{eq:markov_single_var_precise_bound}, we now find that there is some $Q_{s-\Delta}\in\rateset$ such that for all $x_{s-\Delta}\in\states$,
%\begin{equation*}
%\left[(I+\Delta Q_{s-\Delta})f\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} < \mathbb{E}_{X_s}[f(X_s)\,\vert\,X_{s-\Delta}=x_{s-\Delta}]\,.
%\end{equation*}
%Using Definition~\ref{def:low_trans_rate}, we then have that
%\begin{align*}
%\mathbb{E}_{X_s}[f(X_s)\,\vert\,X_{s-\Delta}=x_{s-\Delta}] &> \left[(I+\Delta Q_{s-\Delta})f\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} \\
% &\geq \left[(I+\Delta \lrate)f\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C}\,.
%\end{align*}
%Because the expectation operator in the equality below takes a convex combination of values, we find by substitution that
%\begin{align*}
%\left[T_t^sf\right](x) &= \mathbb{E}_{X_{s-\Delta}}\left[\mathbb{E}_{X_s}[f(X_s)\,\vert\,X_{s-\Delta}]\,\vert\,X_t=x\right] \\
% &> \mathbb{E}_{X_{s-\Delta}}\left[\left[(I+\Delta\lrate)f\right](X_{s-\Delta})\,\vert\,X_t=x\right] - \frac{\Delta\epsilon}{2C}\,.
%\end{align*}
%Repeatedly applying this argument, i.e. factoring the expectation at time points $(s-2\Delta),\ldots,(s-(n-1)\Delta)$, then reveals
%\begin{align*}
%\left[T_t^sf\right](x) &> \left[(I+\Delta\lrate)^nf\right](x) - n\cdot\frac{\Delta\epsilon}{2C} \\
% &= \left[(I+\Delta\lrate)^nf\right](x) - \frac{C\epsilon}{2C} \\
% &= \left[(I+\Delta\lrate)^nf\right](x) - \frac{\epsilon}{2}\,.
%\end{align*}
%We then find using Equation~\ref{eq:markov_single_var_lower_bound} that
%\begin{align*}
%\left[T_t^sf\right](x) &> \left[(I+\Delta\lrate)^nf\right](x) - \frac{\epsilon}{2} \\
% &> \left[L_t^sf\right](x) - \frac{\epsilon}{2} - \frac{\epsilon}{2}\,,
%\end{align*}
%so that we finally obtain
%\begin{equation*}
%\left[L_t^sf\right](x) < \left[T_t^sf\right](x) + \epsilon\,.
%\end{equation*}
%Because the $\epsilon\in\realspos$ was arbitrary, this concludes the proof.
%\end{proof}

*** dit is de correcte algemenere versie ***
\begin{theorem}\label{theorem:nonmarkov_single_var_lower_bounded}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then, for any $P\in\processes_\rateset$, any $u\in\mathcal{U}_{[0,t]}$, any $(x_{t_0},\ldots,x_{t_n})\in\states^u$, and any $g\in\gambles(\states^{\{s\}})$,
\begin{equation*}
[L_t^s g](x_{t_n}) \leq \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
\end{theorem}
\begin{proof}
Consider any $P\in\processes_\rateset$, any $t,s\in\realsnonneg$ such that $t<s$, any $u\in\mathcal{U}_{[0,t]}$, and any $g\in\gambles(\states^{\{s\}})$. We will show that for all $\epsilon\in\realspos$,
\begin{equation*}
[L_t^s g](x_{t_n}) < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] + \epsilon\,,
\end{equation*}
which then implies $[L_t^s g](x_{t_n}) \leq \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]$. Start by choosing any $\epsilon\in\realspos$, and let $C\coloneqq (s-t)$.

Because $P\in\processes_\rateset$, it follows from Definition~\ref{def:set_non_markov_process} that there is some $\delta\in\realspos$ such that
\begin{align*}
 &(\forall \tau\in\realsnonneg)\,(\forall\Delta\in(0,\delta))\,(\forall v\in\mathcal{U}_{[0,\tau]})\,(\forall(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}})\,(\exists Q\in\rateset)\,: \\
 &(\forall f\in\gambles(\states^{v\cup\{\tau+\Delta\}}))\,(\forall x_{\tau_m}\in\states^{\{\tau_m\}}): \\
 &\abs{\frac{\mathbb{E}[f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\,\vert\,X_{\tau_0,\ldots,\tau_m}=x_{\tau_0,\ldots,\tau_m}] - f(x_{\tau_0},\ldots,x_{\tau_m},x_{\tau_m})}{\Delta} - \left[Q f(x_{\tau_0},\ldots,x_{\tau_{m}},X_{\tau+\Delta})\right](x_{\tau_m})} \\ 
 &\quad\quad < \frac{\epsilon}{2C\norm{g}}\cdot\norm{f}\,.
\end{align*}
Furthermore, it follows from Theorem~\ref{theo:convergencelowerbound} that there is some $\delta'\in\realspos$ such that
\begin{equation}
(\forall v\in\mathcal{U}_{[t,s]}\,:\,\sigma(v)<\delta')\,(\forall x_t\in\states)\abs{\left[L_t^s g\right](x_t) - \left[\prod_{k=1}^n(I+\Delta_i\lrate)g\right](x_t)} < \frac{\epsilon}{2}\,.
\end{equation}

Let $\delta^*\coloneqq\min\{\delta,\delta'\}$, and choose any $n>\nicefrac{C}{\delta^*}$. Then, for $\Delta\coloneqq\nicefrac{C}{n}$, we have $\Delta<\delta$ and $\Delta<\delta'$.

Equation {\bf EQREF} now implies that for all $\tau\in\realspos$, all $v\in\mathcal{U}_{[0,\tau]}$, and all $(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}}$, there is some $Q^v_{x_{\tau_0},\ldots,x_{\tau_{m-1}}}\in\rateset$ such that, for all $f\in\gambles(\states^{v\cup\{\tau+\Delta\}})$ and all $x_{\tau_m}\in\states^{\{\tau_m\}}$,
\begin{align}
 &\left[(I + \Delta Q^v_{x_{\tau_0},\ldots,x_{\tau_{m-1}}})f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\right](x_{\tau_m}) - \frac{\Delta\epsilon\norm{f}}{2C\norm{g}} \\
 &\quad< \mathbb{E}[f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\,\vert\,X_{\tau_0,\ldots,\tau_m}=x_{\tau_0,\ldots,\tau_m}]\,.
\end{align}
Now, note that by the basic rules of probability,
\begin{align*}
\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &= \mathbb{E}\bigl[\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}]\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr]\,.
\end{align*}
By choosing $\tau=(s-\Delta)$, setting $v=t_0,\ldots,t_n,(s-\Delta)$, and noting that $g\in\gambles(\states^{\{s\}})=\gambles(\states^{\{\tau+\Delta\}})\subset\gambles(\states^{v\cup\{\tau+\Delta\}})$, we find from Equation {\bf EQREF} that for all $(x_{t_0},\ldots,x_{t_n})\in\states^{u}$ there is some $Q^v_{x_{t_0},\ldots,x_{t_n}}\in\rateset$ such that, for all $x_{s-\Delta}\in\states^{\{s-\Delta\}}$,
\begin{equation*}
\left[(I + \Delta Q^v_{x_{t_0},\ldots,x_{t_n}})g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}=x_{s-\Delta}]\,.
\end{equation*}
Furthermore, we find using Definition~\ref{def:low_trans_rate} and the fact that $Q^v_{x_{t_0},\ldots,x_{t_n}}\in\rateset$, that
\begin{equation*}
\left[(I + \Delta \lrate)g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} \leq \left[(I + \Delta Q^v_{x_{t_0},\ldots,x_{t_n}})g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C}\,.
\end{equation*}
Noting that an expectation takes a convex combination of values, we find by substitution that
\begin{align*}
\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &= \mathbb{E}\bigl[\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}]\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr] \\
&> \mathbb{E}\bigl[[(I+\Delta\lrate)g](X_{s-\Delta})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr] - \frac{\Delta\epsilon}{2C}\,.
\end{align*}

Note also that
\begin{equation*}
[(I+\Delta\lrate)g](X_{s-\Delta})\in\gambles(\states^{\{s-\Delta\}})\subset\gambles(\states^{u\cup\{s-\Delta\}})\,.
\end{equation*}
Hence, we can repeat this argument, factoring the expectation at time points $(s-2\Delta),\ldots,(s-(n-1)\Delta)$, to obtain
\begin{align*}
\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &> \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - n\cdot\frac{\Delta\epsilon}{2C} \\
 &= \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - \frac{\epsilon}{2}\,.
\end{align*}

It follows from Equation {\bf EQREF} and the fact that $\Delta<\delta'$, that
\begin{equation*}
\left[L_t^s g\right](x_{t_n}) - \frac{\epsilon}{2} < \left[(I+\Delta\lrate)^n g\right](x_{t_n})\,,
\end{equation*}
so that
\begin{align*}
\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &> \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - \frac{\epsilon}{2} \\
 &> [L_t^s g](x_{t_n}) - \frac{\epsilon}{2} - \frac{\epsilon}{2} \\
 &= [L_t^s g](x_{t_n}) - \epsilon\,.
\end{align*}
Thus, we have found that
\begin{equation*}
[L_t^s g](x_{t_n}) < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] + \epsilon\,.
\end{equation*}
Because the $\epsilon\in\realspos$ was arbitrary, this concludes the proof.
\end{proof}

%\subsection{Old Version}

%This section contains the old, more complicated proofs.

%\begin{definition}[Set of Markov Processes]\label{def:markov_process_set}
%For any bounded set of rate matrices $\rateset$, we define the set $\mprocesses_{\rateset}$ of all continuous-time Markov processes \emph{consistent} with $\rateset$. Formally, we let $\mprocesses_{\rateset}$ be the set of all $P\in\mprocesses$ such that
%\begin{equation}\label{eq:conditionforMarkov}
%(\forall\epsilon>0)\,
%(\exists\delta>0)\,
%(\forall t\in[0,+\infty))\,
%(\forall\Delta\in(0,\delta))\,
%(\exists Q\in\rateset)~
%\Big\lVert\frac{T_t^{t+\Delta}-I}{\Delta}-Q\Big\rVert<\epsilon.
%\end{equation}
%\end{definition}
%\vspace{5pt}

%\begin{theorem}\label{theorem:markov_single_var_lower_bounded}
%Consider any $t,s\in[0,+\infty)$ such that $t<s$ and let $\rateset$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then for any $P\in\mprocesses_\rateset$ and $f\in\gamblesX$:
%\begin{equation*}
%\lbound_t^sf(x)\leq T_t^sf(x).
%\end{equation*}
%\end{theorem}
%\begin{proof}
%Consider any $P\in\mprocesses_\rateset$ and any $f\in\gamblesX$ and $x\in\states$. Assume \emph{ex absurdo} that $\lbound_t^sf(x)>T_t^sf(x)$. We prove that this leads to a contradiction.  Let $C\coloneqq s-t$ and choose $\epsilon>0$ small enough such that
%\begin{equation}\label{eq:chooseepsilon}
%\epsilon(1+C\norm{f})<\lbound_t^sf(x)-T_t^sf(x).
%\end{equation}
%Since $P\in\mprocesses_\rateset$, it follows from Equation~\eqref{eq:conditionforMarkov} that there is some $\delta>0$ such that
%\begin{equation}\label{eq:1conditionforMarkov}
%(\forall \tau\in[0,+\infty))\,
%(\forall\Delta\in(0,\delta))\,
%(\exists Q\in\rateset)~
%\Big\lVert\frac{T_\tau^{\tau+\Delta}-I}{\Delta}-Q\Big\rVert<\epsilon.
%\end{equation}
%Furthermore, because of Equation~\eqref{eq:deflowerbound} and Theorem~\ref{theo:convergencelowerbound}, there is some $\delta'>0$ such that
%\begin{equation}\label{eq:deltaprimeformula}
%(\forall u\in\mathcal{U}_{[t,s]}\colon\sigma(u)<\delta')~\abs{\lbound_t^sf(x) - \left(\left(\prod_{k=1}^n(I+\Delta_k\lrate)\right)(f)\right)(x)}<\epsilon.
%\end{equation}
%Now choose $n>\max\{\nicefrac{C}{\delta},\nicefrac{C}{\delta'},C\norm{\rateset}\}$. Then for $\Delta\coloneqq\nicefrac{C}{n}$, we find that $\Delta<\delta$, $\Delta<\delta'$ and $\Delta\norm{\rateset}<1$. 

%For all $k\in\{0,1,\dots,n\}$, define $t_k\coloneqq t+k\Delta$. Since $\Delta<\delta$, it follows from Equation~\eqref{eq:1conditionforMarkov} that, for all $i\in\{1,\dots,n\}$, there is some $Q_i\in\rateset$ such that 
%\begin{equation*}
%\norm{T_{t_{i-1}}^{t_i}-(I+\Delta Q_i)}
%=\norm{\frac{T_{t_{i-1}}^{t_i}-I}{\Delta}-Q_i}\Delta
%<\epsilon\Delta.
%\end{equation*}
%Furthermore, for all $i\in\{1,\dots,n\}$, since $\abs{\Delta Q_i(x,y)}\leq\norm{\Delta Q_i}=\Delta\norm{Q_i}\leq\Delta\norm{\rateset}<1$ for all $x,y\in\states$, we have that $I+\Delta Q_i$ is a stochastic matrix.
%Therefore, due to Lemmas~\ref{lemma:transitionmatrixfactorises} and~\ref{lemma:differenceproductoftransition}, we find that
%\begin{equation*}
%\norm{T_t^s-\prod_{i=1}^n(I+\Delta Q_i)}
%=\norm{\prod_{i=1}^n T_{t_{i-1}}^{t_i}-\prod_{i=1}^n(I+\Delta Q_i)}
%\leq\epsilon\Delta n=\epsilon C,
%\end{equation*}
%which implies that
%\begin{align}
%\abs{T_t^sf(x)-\left(\left(\prod_{i=1}^n(I+\Delta Q_i)\right)(f)\right)(x)}
%&\leq
%\norm{T_t^sf-\left(\prod_{i=1}^n(I+\Delta Q_i)\right)(f)}\notag\\
%&\leq
%\norm{T_t^s-\prod_{i=1}^n(I+\Delta Q_i)}\norm{f}
%\leq\epsilon C\norm{f}.\label{eq:firstpartofbound}
%\end{align}
%\noindent
%Equation~\eqref{eq:deflowerbound} implies that
%\begin{equation}
%\left(\left(\prod_{i=1}^n(I+\Delta Q_i)\right)(f)\right)(x)
%\geq
%\left((I+\Delta\lrate)^n(f)\right)(x)\label{eq:middlepartofbound}
%\end{equation}
%and, since $\Delta<\delta'$, it follows from Equation~\eqref{eq:deltaprimeformula} that
%\begin{equation}\label{eq:lastpartofbound}
%\abs{\lbound_t^sf(x) - \left((I+\Delta\lrate)^n(f)\right)(x)}<\epsilon.
%\end{equation}
%\noindent
%By combining Equations~\eqref{eq:firstpartofbound}, \eqref{eq:middlepartofbound} and~\eqref{eq:lastpartofbound}, we find that
%\begin{align*}
%T_t^sf(x)
%&\geq
%\left(\left(\prod_{i=1}^n(I+\Delta Q_i)\right)(f)\right)(x)-\epsilon C\norm{f}\\
%&\geq
%\left((I+\Delta\lrate)^n(f)\right)(x)-\epsilon C\norm{f}
%>\lbound_t^sf(x)-\epsilon-\epsilon C\norm{f},
%\end{align*}
%which provides the required contradiction; see Equation~\eqref{eq:chooseepsilon}.
%\end{proof}

\subsection{*** Bereikbaarheid ***}

*** heb hem even hier neergezet, kan misschien beter in sectie over relatie tussen $\rateset$ en $\lrate$. ***
\begin{lemma}\label{lemma:rateset_has_arginf}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then for all $f\in\gamblesX$ and $\epsilon\in\realspos$, there exists a $Q\in\rateset$ such that
\begin{equation*}
\norm{\lrate f - Qf} < \epsilon\,.
\end{equation*}
\end{lemma}
\begin{proof}
This is immediate from the definition of the corresponding lower transition rate operator for $\rateset$, as given by Equation~\eqref{eq:correspondinglowertrans}.
\end{proof}

*** deze moeten we ook nog ergens uitwerken en neerzetten ***
\begin{lemma}\label{lemma:bound_precise_linear_approx}
Let $Q_\tau$ be any piecewise-constant function that gives for each time point $\tau\in\realsnonneg$ a rate matrix in some non-empty bounded set of rate matrices $\rateset$. By Theorem~\ref{theorem:continuous_rate_matrix_has_process}, there is then some Markov process $P\in\mprocesses_\rateset$ that is characterized by $Q_\tau$. Consider any $t\in\realsnonneg$ and any $\Delta\in\realsnonneg$ such that $Q_\tau$ is constant on the interval $[t,t+\Delta]$. Then, the transition matrix $T_t^{t+\Delta}$ corresponding to $P$ satisfies
\begin{equation*}
\norm{\left[I + \Delta Q_t\right] - T_t^{t+\Delta}} \leq \Delta^2\norm{\rateset}^2\,.
\end{equation*}
\end{lemma}
\begin{proof}
{\bf TODO}
\end{proof}

\begin{theorem}\label{theorem:lower_markov_bound_is_tight}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then for all $f\in\gamblesX$ and $\epsilon\in\realspos$, there exists a $P\in\mprocesses_{\rateset}$ such that
\begin{equation*}
\norm{\lbound_t^sf-T_t^sf} < \epsilon\,.
\end{equation*}
\end{theorem}
\begin{proof}
Choose any $f\in\gamblesX$ and any $\epsilon\in\realspos$, and let $C\coloneqq (s-t)$.

By Lemma~\ref{lemma:rateset_has_arginf}, for all $\tau\in[t,s]$ there is some rate matrix $Q_\tau\in\rateset$ such that
\begin{equation}\label{eq:lower_char_rate_matrix}
\norm{\lrate \lbound_\tau^sf - Q_\tau \lbound_\tau^sf} < \frac{\epsilon}{2C}\,.
\end{equation}
To fix $Q_\tau$'s values outside of the interval $[t,s]$, let $Q_\tau \coloneqq Q_t$ for all $\tau\in[0,t]$, and let $Q_\tau\coloneqq Q_s$ for all $\tau>s$.
%Define a \emph{lower-characterizing rate matrix} $Q_\tau$ as
%\begin{equation}\label{eq:lower_char_rate_matrix}
%Q_\tau(x_\tau,\cdot)\coloneqq \argmin\left\{ Q(x_\tau,\cdot)\bigl[\lbound_\tau^sf\bigr]\,:\,Q(x_\tau,\cdot)\in\mathcal{Q}_{x_\tau}\right\}\quad\text{for all $x_\tau\in\states$ and $\tau\in[t,s]$}\,.
%\end{equation}
%Note that the $\argmin\{\cdot\}$ may be set-valued, in which case take an arbitrary element.
%Furthermore, let $Q_\tau \coloneqq Q_t$ for all $\tau\in[0,t]$, and let $Q_\tau\coloneqq Q_s$ for all $\tau>s$.

Next, define
\begin{equation}\label{eq:delta_required_for_tight_bound}
\delta \coloneqq \min\left\{\frac{\epsilon}{4C\norm{\mathcal{Q}}^2\norm{f}},\frac{1}{\norm{\lrate}}\right\}\,,
\end{equation}
and choose any $n>\nicefrac{C}{\delta}$. Then, for $\Delta\coloneqq \nicefrac{C}{n}$, we have $\Delta<\delta$.

For all $k\in\{0,\ldots,n\}$, define $t_k=t+k\Delta$. Let $u\coloneqq t_0,t_1,\ldots,t_n$. Finally, define a piecewise-constant approximation $Q_\tau^u$ to $Q_\tau$ such that, for all $k\in\{1,\ldots,n\}$,
\begin{equation}\label{eq:lower_char_matrix_linear_approx}
Q_\tau^u \coloneqq Q_{t_k},\quad\text{for all $\tau\in (t_{k-1},t_k]$}\,.
\end{equation}
Let $Q_\tau^u\coloneqq Q_{t_0}$ for all $\tau\leq t_0$ and let $Q_\tau^u\coloneqq Q_{t_n}$ for all $\tau>t_n$.

{\bf ATTN:} *** $Q_\tau^u$ is left-continuous, so the statement below may need some work. ***

Then, by Theorem~\ref{theorem:continuous_rate_matrix_has_process}, there is some $P\in\mathbb{P}_\mathcal{Q}^M$ that is characterized by $Q_\tau^u$, with corresponding transition matrix $T_t^s$. Furthermore,
\begin{align*}
\norm{L_t^sf - T_t^sf} &= \norm{L_{t_0}^{t_n}f - T_{t_0}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_n}f - T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f} + \norm{T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f - T_{t_0}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f - T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f} + \norm{{T_{t_0}^{t_{n-1}}}}\cdot\norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \,.
\end{align*}
Recursion on the first summand yields
\begin{align*}
\norm{L_t^sf - T_t^sf} &\leq \norm{L_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-2}}\left[L_{t_{n-2}}^{t_n}f\right] - T_{t_0}^{t_{n-2}}\left[L_{t_{n-2}}^{t_n}f\right]} \\
 &\quad\quad\quad+ \norm{L_{t_{n-2}}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_{n-2}}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
&\vdots \\
 &\leq \sum_{i=1}^{n} \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]}\,.
\end{align*}
For all $i\in\{1,\ldots,n\}$, we have
\begin{align*}
&\quad \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - \left[I+\Delta\lrate\right]L_{t_i}^{t_n}f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \norm{L_{t_{i-1}}^{t_i} - \left[I+\Delta\lrate\right]}\cdot\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \Delta^2\norm{\lrate}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]}\,.
\end{align*}
By Equation~\eqref{eq:lower_char_rate_matrix}, we have $\norm{Q_{t_i}L_{t_i}^{t_n}f - \lrate L_{t_i}^{t_n}f} < \nicefrac{\epsilon}{2C}$. Furthermore, by Equation~\eqref{eq:lower_char_matrix_linear_approx}, we have $Q_{t_i}^u=Q_{t_i}$, so that
\begin{align*}
 &\quad \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \norm{\left[I+\Delta \lrate\right]L_{t_i}^{t_n}f - \left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f} \\
 &= \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \Delta\norm{\lrate L_{t_i}^{t_n}f - Q_{t_i}L_{t_i}^{t_n}f} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \frac{\Delta\epsilon}{2C} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right] - T_{t_{i-1}}^{t_i}}\cdot\norm{f} + \frac{\Delta\epsilon}{2C} \\
 &\leq 2\Delta^2\norm{\mathcal{Q}}^2\norm{f} + \frac{\Delta\epsilon}{2C}\,,
\end{align*}
where the last step used Lemma~\ref{lemma:bound_precise_linear_approx}.

Thus, using the fact that $n\Delta=C$, we find
\begin{align*}
\norm{L_t^sf - T_t^sf} &\leq \sum_{i=1}^n \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \sum_{i=1}^n 2\Delta^2\norm{\mathcal{Q}}^2\norm{f} + \frac{\Delta\epsilon}{2C} \\
 &= 2n\Delta^2\norm{\mathcal{Q}}^2\norm{f} + n\frac{\Delta\epsilon}{2C}\\
 &= 2C\Delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2}\,,
\end{align*}
so that by Equation~\eqref{eq:delta_required_for_tight_bound} and the fact that $\Delta<\delta$, we have
\begin{equation*}
\norm{L_t^sf - T_t^sf} \leq 2C\Delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2} < 2C\delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2} \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\,.
\end{equation*}
\end{proof}

\begin{corollary}\label{cor:lower_operator_is_infimum}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then, for all $g\in\gambles(\states^{\{s\}})$ and $x\in\states$,
\begin{equation*}
\left[L_t^sg\right](x) = \underline{\mathbb{E}}^\mathrm{M}[g(X_s)\,\vert\,X_t=x]\,,%\inf\Bigl\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\Bigr\}\,.
\end{equation*}
and furthermore,
\begin{equation*}
\left[L_t^sg\right](x) = \underline{\mathbb{E}}[g(X_s)\,\vert\,X_t=x]\,.%\inf\Bigl\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\Bigr\}\,.
\end{equation*}
\end{corollary}
\begin{proof}
We start by proving the first statement. By Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded} and Proposition~\ref{prop:lower_exp_markov_bounded_by_nonmarkov}, we have that, for all $P\in\mprocesses_\rateset$ with expectation operator $\mathbb{E}$,
\begin{equation*}
\left[L_t^sg\right](x) \leq \mathbb{E}[g(X_s)\,\vert\,X_t=x]\,.
\end{equation*}
Furthermore, by Theorem~\ref{theorem:lower_markov_bound_is_tight}, we have that for all $\epsilon\in\realspos$, there is some $P\in\mprocesses_\rateset$ such that
\begin{equation*}
\norm{L_t^sg - T_t^sg} < \epsilon\,.
\end{equation*}
Together this implies, using Definition~\ref{def:lower_markov}, that
\begin{equation*}
\left[L_t^sg\right](x) = \inf\left\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\right\} = \underline{\mathbb{E}}^{\mathrm{M}}\left[g(X_s)\,\vert\,X_t=x\right]\,.
\end{equation*}

We now move on to the second statement. By Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded} we have that for all $P\in\processes_\rateset$ with expectation operator $\mathbb{E}$,
\begin{equation*}
\left[L_t^sg\right](x) \leq \mathbb{E}[g(X_s)\,\vert\,X_t=x]\,.
\end{equation*}
Furthermore, using Theorem~\ref{theorem:lower_markov_bound_is_tight} and Proposition~\ref{prop:markov_set_subset_of_nonmarkov_set}, we have that for all $\epsilon\in\realsnonneg$ there is some $P\in\processes_\rateset$ such that
\begin{equation*}
\norm{L_t^sg - T_t^sg} < \epsilon\,.
\end{equation*}
Together this implies, using Definition~\ref{def:lower_non_markov}, that
\begin{equation*}
\left[L_t^sg\right](x) = \inf\left\{\left[T_t^sf\right](x)\,:\,P\in\processes_\rateset\right\} = \underline{\mathbb{E}}\left[g(X_s)\,\vert\,X_t=x\right]\,.
\end{equation*}
\end{proof}

%\begin{definition}\label{def:lower_expectation}
%Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\mathcal{Q}$ be an arbitrary closed and bounded set of rate matrices with separately specified rows, with corresponding lower transition rate operator $\lrate$. Then, for all $f\in\gamblesX$, we define the \emph{lower expectation of $f$ at time $s$, given the state at time $t$, with respect to $\mprocesses_\rateset$}, as
%\begin{equation*}
%\underline{\mathbb{E}}_{X_s}\left[f(X_s)\,\vert\,X_t\right]\coloneqq L_t^sf\,.
%\end{equation*}
%\end{definition}


\section{*** More complex functions *** }

%\subsection{wat notatie voor meerdere variabelen}\label{sec:imp_non_markov}

We will now move on to consider non-Markovian stochastic processes. Due to the need to consider multiple time points in such a process' history, we will find it convenient to switch from a transition-matrix notation to using (conditional) expectation operators. 
%We will start by introducing some notation for functions which makes explicit the time points that we are considering.

\begin{definition}
Consider any stochastic process $P\in\processes$, any $t,t',s\in\realsnonneg$ such that $t<t'<s$, any $u\in\mathcal{U}_{[t,t']}$, and any $f\in\gambles(\states^{u\cup\{s\}})$. Then, the \emph{expectation of $f$ at time $s$ given the states at times $u$}, with respect to $P$, is a map $\mathbb{E}$ from $\gambles(\states^{u\cup\{s\}})$ to $\gambles(\states^u)$, defined for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$, as
\begin{equation*}
\mathbb{E}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \coloneqq \sum_{x_s\in\states^{\{s\}}} f(x_{t_0},\ldots,x_{t_n},x_s)P(X_s=x_s\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n})\,.
\end{equation*}
\end{definition}
\noindent Note that $\gambles(\states^{\{s\}})\subset\gambles(\states^{u\cup\{s\}})$, so that for any $g\in\gambles(\states^{\{s\}})$,
\begin{equation*}
\mathbb{E}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] = \sum_{x_s\in\states^{\{s\}}} g(x_s)P(X_s=x_s\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n})\,.
\end{equation*}

% \begin{definition}
% Consider any $t,t',s\in\realsnonneg$ such that $t<t'<s$, any $u\in\mathcal{U}_{[t,t']}$, any $g\in\gambles(\states^{\{s\}})$ and any $f\in\gambles(\states^{u\cup\{s\}})$. Let $\rateset$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. We will define the \emph{lower expectation operator} $\underline{\mathbb{E}}$, for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$, as
% \begin{equation*}
% \underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \coloneqq \left[L_{t_n}^sg\right](x_{t_n})\,,
% \end{equation*}
% and,
% \begin{equation*}
% \underline{\mathbb{E}}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \coloneqq \left[L_{t_n}^sf(x_{t_0},\ldots,x_{t_n},X_s)\right](x_{t_n})\,.
% \end{equation*}
% \end{definition}


\subsection{*** functies met in tijdstip in de toekomst en de rest in het verleden ***}

*** dit is triviaal en moet wat in de tekst komen, volgt uit eigenschappen van verwachtingswaarden ***

\begin{theorem}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then, for any $P\in\processes_\rateset$, any $u\in\mathcal{U}_{[0,t]}$, any $(x_{t_0},\ldots,x_{t_n})\in\states^u$, and any $f\in\gambles(\states^{u\cup\{s\}})$,
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \leq \mathbb{E}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
\end{theorem}
\begin{proof}
Consider any $P\in\processes_\rateset$, any $t,s\in\realsnonneg$ such that $t<s$, any $u\in\mathcal{U}_{[0,t]}$, any $f\in\gambles(\states^{u\cup\{s\}})$, and any $(x_{t_0},\ldots,x_{t_n})\in\states^u$.

Note that
\begin{equation*}
f(x_{t_0},\ldots,x_{t_n},X_s)\in\gambles(\states^{\{s\}})
\end{equation*}
is the restriction of $f\in\gambles(\states^{u\cup\{s\}})$ to $\gambles(\states^{\{s\}})$. Hence, we can define a function $g\in\gambles(\states^{\{s\}})$ as
\begin{equation*}
g(x_s) \coloneqq f(x_{t_0},\ldots,x_{t_n},x_s)\,,\quad\quad\text{for all $x_s\in\states^{\{s\}}$}\,.
\end{equation*}
Then,
\begin{equation*}
\mathbb{E}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] = \mathbb{E}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,,
\end{equation*}
and
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] = \underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
Thus, it remains to show that
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \leq \mathbb{E}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
Because $g\in\gambles(\states^{\{s\}})$, this was shown to hold by Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded}.
\end{proof}

\begin{theorem}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary closed and bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then for any $u\in\mathcal{U}_{[0,t]}$, any $g\in\gambles(\states^{\{s\}})$, and any $\epsilon\in\realspos$, there is some $P\in\processes_\rateset$ such that $P$ is Markovian, i.e. also $P\in\mprocesses_\rateset$, and furthermore,
\begin{equation*}
\norm{\underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}]} < \epsilon\,.
\end{equation*}
\end{theorem}
\begin{proof}
Because $g\in\gambles(\states^{\{s\}})$, we have by Definition~{\bf REF} that
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}] = \underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_n}] = L_{t_n}^s g\,.
\end{equation*}
Furthermore, by Theorem~{\bf REF} there is some $P\in\mprocesses_\rateset$ with
\begin{equation*}
\mathbb{E}_{X_{s}}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}] =  \mathbb{E}_{X_{s}}[g(X_s)\,\vert\,X_{t_n}] = T_{t_n}^sf
\end{equation*}
by virtue of the Markov property, and
\begin{equation*}
\norm{\underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_{s}}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}]} = \norm{L_{t_n}^sg - T_{t_n}^sg}< \epsilon\,.
\end{equation*}
Because $P\in\mprocesses_\rateset$ and $\mprocesses_\rateset\subseteq\processes_\rateset$, we have $P\in\processes_\rateset$, which concludes the proof.
\end{proof}

\subsection{Decompositie}

*** dit bewijs mag weg, de essentie ervan zal terugkeren ergens in de decompositie denk ik ***

\begin{theorem}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary closed and bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then for any $u\in\mathcal{U}_{[0,t]}$, any $f\in\gambles(\states^{u\cup\{s\}})$, and any $\epsilon\in\realspos$, there is some $P\in\processes_\rateset$ such that
\begin{equation*}
\norm{\underline{\mathbb{E}}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} < \epsilon\,.
\end{equation*}
\end{theorem}
\begin{proof}
Choose any $u\in\mathcal{U}_{[0,t]}$, any $f\in\gambles(\states^{u\cup\{s\}})$, and any $\epsilon\in\realspos$.

Define a \emph{lower-characterizing rate matrix} $Q_{x_{t_0},\ldots,x_{t_n},\tau}$ as
\begin{equation*}
Q_{x_{t_0},\ldots,x_{t_n},\tau}(x_\tau,\cdot) \coloneqq \argmin\bigl\{Q(x_\tau,\cdot)\left[\underline{\mathbb{E}}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{\tau}]\right]\,:\,Q(x_\tau,\cdot)\in\rateset_{x_\tau}\bigr\}\,,
\end{equation*}
for all $x_\tau\in\states^{\{\tau\}}$, all $\tau\in[t,s]$, and all $(x_{t_0},\ldots,x_{t_n})\in\states^u$. Note that the $\argmin\{\cdot\}$ may be set-valued, in which case take an arbitrary element. Furthermore, for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$, let $Q_{x_{t_0},\ldots,x_{t_n},\tau}\coloneqq Q_{x_{t_0},\ldots,x_{t_n},t}$ for all $\tau\in[0,t]$, and let $Q_{x_{t_0},\ldots,x_{t_n},\tau}\coloneqq Q_{x_{t_0},\ldots,x_{t_n},s}$ for all $\tau>s$.

Let $C\coloneqq (s-t)$, define
\begin{equation*}
\delta\coloneqq \min\left\{\frac{\epsilon}{2C\norm{\rateset}^2\norm{f}}, \frac{1}{\norm{\lrate}}\right\}\,,
\end{equation*}
and choose any $m>\nicefrac{C}{\delta}$. Then, for $\Delta\coloneqq\nicefrac{C}{m}$, we have $\Delta<\delta$.

For all $k\in\{0,\ldots,m\}$, define $\tau_k\coloneqq t+k\Delta$. Let $v\coloneqq \tau_0,\tau_1,\ldots,\tau_m$. Finally, define for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$ a piecewise-constant approximation $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v$ to $Q_{x_{t_0},\ldots,x_{t_n},\tau}$ such that, for all $k\in\{1,\ldots,m\}$,
\begin{equation*}
Q_{x_{t_0},\ldots,x_{t_n},\tau}^v\coloneqq Q_{x_{t_0},\ldots,x_{t_n},\tau_k}\,,\quad\text{for all $\tau\in(\tau_{k-1},\tau_k]$}\,.
\end{equation*}
Let $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v\coloneqq Q_{x_{t_0},\ldots,x_{t_n},\tau_0}$ for all $\tau\leq\tau_0$ and let $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v\coloneqq Q_{x_{t_0},\ldots,x_{t_n},\tau_m}$ for all $\tau>\tau_m$.

Then, for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$, $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v$ is a piecewise-constant matrix which takes values $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v\in\rateset$ for all $\tau\in\realsnonneg$. Hence, by Proposition {\bf REF}, there is some $P\in\processes_\rateset$ that is characterized by the collection $Q_{X_{t_0},\ldots,X_{t_n},\tau}^v$ of all $Q_{x_{t_0},\ldots,x_{t_n},\tau}^v$. 

Let $\mathbb{E}$ be the expectation operator associated with this $P$. Then,
\begin{align*}
&\quad \norm{\underline{\mathbb{E}}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} \\
&= \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n}]} \\
&= \norm{\underline{\mathbb{E}}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-1}}}\bigl[\mathbb{E}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
&\quad + \norm{\mathbb{E}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-1}}}\bigl[\mathbb{E}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
&\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]}\,, \end{align*}
where the last step used convexity of the expectation operator and the definition of the norm. Recursion on the first summand yields
\begin{align*}
&\quad \norm{\underline{\mathbb{E}}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} \\
&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-1}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
%&= \norm{\underline{\mathbb{E}}_{X_{\tau_{m-2}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-2}}}\bigl[\mathbb{E}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
%&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
%&= \norm{\underline{\mathbb{E}}_{X_{\tau_{m-2}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-2}}}\bigl[\mathbb{E}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
%&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
%&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_{m-2}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-2}}}[ \underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}] \,\vert\,X_{t_0,\ldots,t_n}]} \\
%&\quad\quad\quad + \norm{\mathbb{E}_{X_{\tau_{m-2}}}[ \underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}] \,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_{\tau_{m-2}}}\bigl[\mathbb{E}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr]} \\
%&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
%&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_{m-2}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-2}}}[ \underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}] \,\vert\,X_{t_0,\ldots,t_n}]} \\
%&\quad\quad\quad + \norm{ \underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}] - \mathbb{E}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}]} \\
%&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
%&= \norm{\underline{\mathbb{E}}_{X_{\tau_{m-2}}}\bigl[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}]\,\big\vert\,X_{t_0,\ldots,t_n}\bigr] - \mathbb{E}_{X_{\tau_{m-2}}}[ \underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-2}}] \,\vert\,X_{t_0,\ldots,t_n}]} \\
%&\quad\quad\quad + \norm{ \underline{\mathbb{E}}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}] - \mathbb{E}_{X_{\tau_{m-1}}}[\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}]\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-2}}]} \\
%&\quad\quad\quad + \norm{\underline{\mathbb{E}}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}] - \mathbb{E}_{X_{\tau_m}}[g(X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_{m-1}}]} \\
&\vdots \\
&\leq \sum_{i=1}^m \norm{\underline{\mathbb{E}}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr] - \mathbb{E}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr]}\,.
\end{align*}
For all $i\in\{1,\ldots,m\}$, we have
\begin{align*}
&\quad \norm{\underline{\mathbb{E}}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr] - \mathbb{E}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr]} \\
&\leq \norm{\underline{\mathbb{E}}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr] - [I+\Delta \lrate]\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}]} \\
&\quad\quad + \norm{[I+\Delta \lrate]\underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] - \mathbb{E}_{X_{\tau_i}}\bigl[ \underline{\mathbb{E}}_{X_{\tau_m}}[f(X_{t_0},\ldots,X_{t_n},X_{\tau_m})\,\vert\,X_{t_0,\ldots,t_n,\tau_i}] \,\big\vert\,X_{t_0,\ldots,t_n,\tau_{i-1}}\bigr]} \\
&\leq 2\Delta^2\norm{\rateset}^2\norm{f}\,,
\end{align*}
where the last step needs a bit more detail. Thus, we find
\begin{align*}
&\quad \norm{\underline{\mathbb{E}}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} \\
&\leq \sum_{i=1}^m 2\Delta^2\norm{\rateset}^2\norm{f} \\
&= 2n\Delta^2\norm{\rateset}^2\norm{f} \\
&= 2C\Delta\norm{\rateset}^2\norm{f}\,,
\end{align*}
so that by Equation {\bf REF} and the fact that $\Delta<\delta$, we have
\begin{align*}
&\quad \norm{\underline{\mathbb{E}}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}] - \mathbb{E}_{X_s}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} \\
&\leq 2C\Delta\norm{\rateset}^2\norm{f} \\
&< 2C\delta\norm{\rateset}^2\norm{f} \\
&\leq \epsilon\,.
\end{align*}
\end{proof}

*** kan dit weg? ***
\begin{corollary}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary closed and bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then for all $u\in\mathcal{U}_{[0,t]}$, all $g\in\gambles(\states^{\{s\}})$, and all $(x_{t_0},\ldots,x_{t_n})\in\states^u$,
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] = \inf\Bigl\{ \mathbb{E}_{X_s}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,:\, P\in\processes_\rateset \Bigr\}\,.
\end{equation*}
\end{corollary}
\begin{proof}
This is immediate.
\end{proof}


*** kan dit weg? ****

\begin{corollary}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and let $\rateset$ be an arbitrary closed and bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then for all $u\in\mathcal{U}_{[0,t]}$, all $f\in\gambles(\states^{u\cup\{s\}})$, and all $(x_{t_0},\ldots,x_{t_n})\in\states^u$,
\begin{equation*}
\underline{\mathbb{E}}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] = \inf\Bigl\{ \mathbb{E}_{X_s}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,:\, P\in\processes_\rateset \Bigr\}\,.
\end{equation*}
\end{corollary}
\begin{proof}
This is immediate.
\end{proof}

\subsection{Algoritmes}\label{sec:tractability}

In the sequel, for a given $f\in\gambles(\states^{u\cup v})$, we will refer to the transition operator corresponding to the distribution $P\in\mathbb{P}_\mathcal{Q}$ that satisfies Theorem~\ref{theorem:nonmarkov_multi_variable_lower_envelope} 
as $\lt_u^v$.

\begin{proposition}
For any $f\in\gambles(\states^{u\cup v})$ and given the corresponding $\lt_u^v$, computing $\left[\lt_u^v f\right](x_{t_0},\ldots,x_{t_n})$ is not more difficult than computing $\left[T_u^v f\right](x_{t_0},\ldots,x_{t_n})$ for an arbitrary $P\in\mathbb{P}_{\mathcal{Q}}$. Specifically, this takes a number of operations that is exponential in $m$.
\end{proposition}
\begin{proof}
The first claim is immediate from the fact that $\lt_u^v$ corresponds to a $P\in\mathbb{P}_\mathcal{Q}$. The difficulty of the computation follows from the fact that it is an expectation on $m$ variables, which requires summing over all values $(x_{\tau_0},\ldots,x_{\tau_m})\in\states^v$.
\end{proof}

\begin{proposition}
Identifying the $\lt_u^v$ corresponding to a given $f\in\gambles(\states^{u\cup v})$ is intractable.
\end{proposition}
\begin{proof}
The problem is essentially that for all combinations $(x_{\tau_0},\ldots,x_{\tau_m})\in\states^v$, we need to perform an optimization to find the corresponding $\lrate$. Clearly, the number of optimizations required is exponential in $m$.
\end{proof}

\begin{proposition}
There is a subclass of gambles $\mathcal{C}(\states^{u\cup v})\subset\gambles(\states^{u\cup v})$, so that for $f\in\mathcal{C}(\states^{u\cup v})$, identifying the corresponding $\lt_u^v$ is tractable, i.e., the required number of times that $\lrate$ needs to be computed is linear in $m$.
\end{proposition}
\begin{proof}
As a trivial example, take $\mathcal{C}(\states^{u\cup v}) = \gambles(\states^{\{s'\}})$. {\bf Claim: } This class can be made a lot bigger.
\end{proof}




\section{Conclusions \& Future Work}\label{sec:conclusions}

*** I would discuss sigma-additivity things here: explain that this is possible with our approach by using Kolmogorovs extension theorem, say that this would allow us to consider for example the lower and upper expected time till absorbtion. ***


\section{*** Dit mag volgens mij volledig weg ***}\label{sec:decomp}

We now generalize the results from the previous sections to the lower bound of expectations on functions $f\in\gambles(\states^{u\cup v})$, where $v\in\mathcal{U}_{[s,s']}$.

We again start with some notation. For any $t,s,s'\in\realsnonneg$ such that $t<s<s'$, any $u\in\mathcal{U}_{[0,t]}$ and any $v\in\mathcal{U}_{[s,s']}$, let $A_u^v$ be a non-negatively homogeneous operator from $\gambles(\states^{u\cup v})$ to $\gambles(\states^u)$. Define the norm as before, i.e.,
\begin{equation*}
\norm{A_u^v} \coloneqq \sup\left\{\norm{A_u^v}\,:\,f\in\gambles(\states^{u\cup v}), \norm{f}=1\right\}\,.
\end{equation*}
This norm satisfies all properties N6-N12 from the previous section. The default notation for sequences of time points will be $u=t_0,\ldots,t_n$ and $v=\tau_0,\ldots,\tau_m$, where we will assume that $t_n\leq \tau_0$.

As a special case of such an operator, define for all $f\in\gambles(\states^{u\cup v})$ the operator
\begin{equation*}
T_u^vf \coloneqq \mathbb{E}_{X_{\tau_0},\ldots,X_{\tau_m}}\left[f(X_{t_0},\ldots,X_{t_n},X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X_{t_0},\ldots,X_{t_n}\right]\,.
\end{equation*}
This also satisfies for all $g\in\gambles(\states^v)$ the equality
\begin{equation*}
T_u^vg = \mathbb{E}_{X_{\tau_0},\ldots,X_{\tau_m}}\left[g(X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X_{t_0},\ldots,X_{t_n}\right]\,.
\end{equation*}

\begin{proposition}\label{proposition:nonmarkov_multi_variable_decompose}
Consider any $t,s,s'\in\realsnonneg$ such that $t<s<s'$, any $u\in\mathcal{U}_{[0,t]}$ and $v\in\mathcal{U}_{[s,s']}$, and any $P\in\mathbb{P}$ that has, for all $i\in\{1,\ldots,m\}$, transition operators
\begin{equation*}
T_{u\cup\{\tau_0,\ldots,\tau_{i-1}\}}^{\{\tau_i\}}\,.
\end{equation*}
Then, the expectation operator $T_u^v$ corresponding to $P$ satisfies, for all $f\in\gambles(\states^{u\cup v})$,
\begin{equation*}
T_u^v f = T_u^{\{\tau_0\}}T_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f\,.
\end{equation*}
\end{proposition}
\begin{proof}
%We will use backward induction on $m$. Note that
%\begin{equation*}
%T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} g = \mathbb{E}_{X_{\tau_m}}\left[g(X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X_{t_0},\ldots,X_{t_n},X_{\tau_0},\ldots,X_{\tau_{m-1}}\right]
%\end{equation*}
This is immediate from the decomposition properties of expectation, i.e.,
\begin{align*}
&\quad T_u^{\{\tau_0\}}T_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f \\
 &= \mathbb{E}_{X_{\tau_0}}\left[\cdots\mathbb{E}_{X_{\tau_m}}\left[f(X_{t_0},\ldots,X_{t_n},X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X_{t_0},\ldots,X_{t_n},X_{\tau_0},\ldots,X_{\tau_{m-1}}\right]\cdots\,\vert\,X_{t_0},\ldots,X_{t_n}\right] \\
 &= \mathbb{E}_{X_{\tau_0},\ldots,X_{\tau_m}}\left[f(X_{t_0},\ldots,X_{t_n},X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X_{t_0},\ldots,X_{t_n}\right] \\
 &= T_u^v f\,.
\end{align*}
\end{proof}

\begin{definition}[Lower Joint Expectation Operator]\label{def:low_joint_exp_op}
Recall the extended operator $L_u^{\{s\}}$ from Definition~\ref{def:low_full_cond_exp_op}, and define a new operator $L_u^v$ from $\gambles(\states^{u\cup v})$ to $\gambles(\states^u)$, as
\begin{equation*}
L_u^v \coloneqq L_u^{\{\tau_0\}}L_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots L_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}}.
\end{equation*}
\end{definition}

\begin{theorem}\label{theorem:nonmarkov_multi_variable_lower_bounded}
Consider any $t,s,s'\in\realsnonneg$ such that $t<s<s'$, and let $\mathcal{Q}$ be an arbitrary bounded set of rate matrices with corresponding lower transition rate operator $\lrate$. Then, for any $P\in\mathbb{P}_\mathcal{Q}$, any $u\in\mathcal{U}_{[0,t]}$ and $v\in\mathcal{U}_{[s,s']}$, any $f\in\gambles(\states^{u\cup v})$ and any $(x_{t_0},\ldots,x_{t_n})\in\states^u$, it holds that
\begin{equation*}
\left[L_u^v f\right](x_{t_0},\ldots,x_{t_n}) \leq \left[T_u^v f\right](x_{t_0},\ldots,x_{t_n})\,.
\end{equation*}
\end{theorem}
\begin{proof}
Consider any $(x_{t_0},\ldots,x_{t_n})\in\states^u$. Using the decomposition from Proposition~\ref{proposition:nonmarkov_multi_variable_decompose}, we find that
\begin{align*}
&\quad \left[T_u^vf\right](x_{t_0},\ldots,x_{t_n}) \\
&= \left[T_u^{\{\tau_0\}}T_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f\right](x_{t_0},\ldots,x_{t_n}) \\
&= \mathbb{E}_{X_{\tau_0}}\left[\cdots\mathbb{E}_{X_{\tau_m}}\left[f(x_{t_0},\ldots,x_{t_n},X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n}),X_{\tau_0},\ldots,X_{\tau_{m-1}}\right]\cdots\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right] \\
&= \mathbb{E}_{X_{\tau_0},\ldots,X_{\tau_{m-1}}}\left[\mathbb{E}_{X_{\tau_m}}\left[f(x_{t_0},\ldots,x_{t_n},X_{\tau_0},\ldots,X_{\tau_m})\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n}),X_{\tau_0},\ldots,X_{\tau_{m-1}}\right]\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right] \\
&= \sum_{x_{\tau_0}}\cdots\sum_{x_{\tau_{m-1}}} P\left(X_{\tau_0}=x_{\tau_0},\ldots,X_{\tau_{m-1}}=x_{\tau_{m-1}}\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right)g(x_{\tau_0},\ldots,x_{\tau_{m-1}})\,,
\end{align*}
where
\begin{equation*}
g(x_{\tau_0},\ldots,x_{\tau_{m-1}}) \coloneqq \left[T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}}f\right](x_{t_0},\ldots,x_{t_n},x_{\tau_0},\ldots,x_{\tau_{m-1}})\,.
\end{equation*}
Define a new function $g'(\cdot)$ as
\begin{equation*}
g'(x_{\tau_0},\ldots,x_{\tau_{m-1}}) \coloneqq \left[L_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}}f\right](x_{t_0},\ldots,x_{t_n},x_{\tau_0},\ldots,x_{\tau_{m-1}})\,,
\end{equation*}
and note that by Theorem~\ref{theorem:nonmarkov_historic_variable_lower_bounded} we have for all $(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}}$ that
\begin{equation}\label{equation:nonmarkov_multiple_variable_theorem_eq}
g'(x_{\tau_0},\ldots,x_{\tau_{m-1}}) \leq g(x_{\tau_0},\ldots,x_{\tau_{m-1}})\,.
\end{equation}
Now, because
\begin{equation*}
\sum_{x_{\tau_0}}\cdots\sum_{x_{\tau_{m-1}}} P\left(X_{\tau_0}=x_{\tau_0},\ldots,X_{\tau_{m-1}}=x_{\tau_{m-1}}\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right)g(x_{\tau_0},\ldots,x_{\tau_{m-1}})
\end{equation*}
is a convex combination of values $g(x_{\tau_0},\ldots,x_{\tau_{m-1}})$ over all combinations $(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}}$, we have by Equation~\ref{equation:nonmarkov_multiple_variable_theorem_eq} that
\begin{align*}
&\quad \left[T_u^vf\right](x_{t_0},\ldots,x_{t_n}) \\
&= \sum_{x_{\tau_0}}\cdots\sum_{x_{\tau_{m-1}}} P\left(X_{\tau_0}=x_{\tau_0},\ldots,X_{\tau_{m-1}}=x_{\tau_{m-1}}\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right)g(x_{\tau_0},\ldots,x_{\tau_{m-1}}) \\
&\geq \sum_{x_{\tau_0}}\cdots\sum_{x_{\tau_{m-1}}} P\left(X_{\tau_0}=x_{\tau_0},\ldots,X_{\tau_{m-1}}=x_{\tau_{m-1}}\,\vert\,X^u=(x_{t_0},\ldots,x_{t_n})\right)g'(x_{\tau_0},\ldots,x_{\tau_{m-1}}) \\
&= \left[T_u^{\{\tau_0\}}T_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots T_{u\cup\{\tau_0,\ldots,\tau_{m-2}\}}^{\{\tau_{m-1}\}}L_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f\right](x_{t_0},\ldots,x_{t_n})\,.
\end{align*}
Repeatedly applying this argument, i.e. using backward induction on $m$, finally reveals
\begin{align*}
\left[T_u^vf\right](x_{t_0},\ldots,x_{t_n}) &= \left[T_u^{\{\tau_0\}}T_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots T_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f\right](x_{t_0},\ldots,x_{t_n}) \\
 &\geq \left[L_u^{\{\tau_0\}}L_{u\cup\{\tau_0\}}^{\{\tau_1\}}\cdots L_{u\cup\{\tau_0,\ldots,\tau_{m-1}\}}^{\{\tau_m\}} f\right](x_{t_0},\ldots,x_{t_n}) \\
 &= \left[L_u^v f\right](x_{t_0},\ldots,x_{t_n})\,.
\end{align*}
\end{proof}

\begin{theorem}\label{theorem:nonmarkov_multi_variable_lower_envelope}
Consider any $t,s,s'\in\realsnonneg$ such that $t<s<s'$, and let $\mathcal{Q}$ be an arbitrary closed and bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then, for all $u\in\mathcal{U}_{[0,t]}$, all $v\in\mathcal{U}_{[s,s']}$, and all $f\in\gambles(\states^{u\cup v})$, there is some $P\in\mathbb{P}_\mathcal{Q}$ such that, for all $(x_{t_0},\ldots,x_{t_n})\in\states^u$,
\begin{equation*}
\left[L_u^v f\right](x_{t_0},\ldots,x_{t_n}) = \left[T_u^v f\right](x_{t_0},\ldots,x_{t_n})\,.
\end{equation*}
\end{theorem}
\begin{proof}
*** The non-Markovian stochastic process for which, for all $i\in\{0,\ldots,{m-1}\}$ and all $(x_{\tau_0},\ldots,x_{\tau_i})\in\states^{\{\tau_0,\ldots,\tau_i\}}$,
\begin{equation*}
Q_{u\cup\{\tau_0,\ldots,\tau_i,\mu\}}(x_{t_0},\ldots,x_{t_n},x_{\tau_0},\ldots,x_{\tau_i}) \coloneqq \lrate L_\mu^{\tau_{i+1}} \left[L_{u\cup\{\tau_0,\ldots,\tau_{i+1}\}}^{\{\tau_{i+2}\}}f\right](x_{t_0},\ldots,x_{t_n},x_{\tau_0},\ldots,x_{\tau_i})
\end{equation*}
establishes the equality. ***
\end{proof}


\bibliographystyle{plain} 
\bibliography{general}

\appendix

\section{Proofs of Lemmas from Section~\ref{sec:lower_operator}}\label{sec:proof_appendix}

\begin{lemma}\label{lemma:justtheindicator_appendix}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}\leq\Delta\norm{\lrate}.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}
&=\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-\prod_{i=1}^{n-1}(I+\Delta_i\lrate)+\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&\leq\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-\prod_{i=1}^{n-1}(I+\Delta_i\lrate)}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&\leq\norm{(I+\Delta_n\lrate)-I}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&=\Delta_n\norm{\lrate}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:differencenormofcoherenttrans}. By repeating this argument over and over again (actually, by induction), we find that
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}
\leq \Delta_n\norm{\lrate} +\Delta_{n-1}\norm{\lrate}+\cdots
+\Delta_1\norm{\lrate}
=\Delta\norm{\lrate}.
\end{align*}
\end{proof}


\begin{lemma}\label{lemma:justthelinearpart_appendix}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\leq\Delta^2\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&=\norm{\prod_{i=2}^n(I+\Delta_i\lrate)+\Delta_1\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-(I+\sum_{i=2}^n\Delta_i\lrate)-\Delta_1\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\norm{\Delta_1\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-\Delta_1\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1\norm{\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1 2\norm{\lrate}\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-I},
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:differencenormofcoherenttransrate}. Due to Lemma~\ref{lemma:justtheindicator}, this implies that
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1 2\norm{\lrate}\left(\sum_{i=2}^n\Delta_i\right)\norm{\lrate}\\
&=\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right).
\end{align*}
By continuing in this way (applying induction) we find that
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&\leq
\norm{\prod_{i=n}^n(I+\Delta_i\lrate)-(I+\sum_{i=n}^n\Delta_i\lrate)}
+2\norm{\lrate}^2\Delta_{n-1}\left(\sum_{i=n}^n\Delta_i\right)
+\cdots
+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right)\\
&=2\norm{\lrate}^2\Delta_{n-1}\left(\sum_{i=n}^n\Delta_i\right)
+\cdots
+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right)\\
&=2\norm{\lrate}^2\sum_{k=1}^n\Delta_k\sum_{i=k+1}^n\Delta_i\\
&\leq2\norm{\lrate}^2\frac{1}{2}\left(\sum_{k=1}^n\Delta_k\right)^2=\Delta^2\norm{\lrate}^2
\end{align*}
\end{proof}

\begin{lemma}\label{lemma:differencebetweennested_appendix}
For any $k\in\{1,\dots,n\}$, consider a sequence of $\Delta_{k,i}>0$, $i=1,\dots,n_k$ and let $\Delta_k\coloneqq\sum_{i=1}^{n_k}\Delta_{n,k}$. Let $\Delta\coloneqq\sum_{k=1}^n\Delta_k$ and let $\alpha\coloneqq\max\{\Delta_k\colon k\in\{1,\dots,n\}\}$. If $\alpha\leq\nicefrac{1}{\norm{\lrate}}$, then
\begin{equation*}
\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}
\leq\alpha\Delta\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
&\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}\\
&=\norm{\left(\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)\right)\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&\leq\norm{
\left(\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)\right)\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&=\norm{
\left(
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&\leq\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}
\norm{
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
},
\end{align*}

\noindent
which, because of Lemma~\ref{lemma:productiscoherent}, \ref{lemma:normofcoherenttrans} and~\ref{lemma:differencenormofcoherenttrans}, implies that

\begin{align*}
&\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}\\
&\leq\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
(I+\Delta_n\lrate)
}\\
&\leq
\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}
+
\Delta_n^2\norm{\lrate}^2,
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:justthelinearpart}.

By continuing in this way (applying induction), we find that
\begin{align*}
\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}
&\leq
\Delta_1^2\norm{\lrate}^2+\cdot+\Delta_k^2\norm{\lrate}^2+\cdot
+
\Delta_n^2\norm{\lrate}^2\\
&\leq
\alpha\Delta_1\norm{\lrate}^2+\cdot+\alpha\Delta_k\norm{\lrate}^2+\cdot
+
\alpha\Delta_n\norm{\lrate}^2\\
&=
\alpha\Delta\norm{\lrate}^2
\end{align*}
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:lower_transition_has_deriv}]
We start by proving Equation~\eqref{eq:lower_deriv_backward}. Choose any $\epsilon\in\realspos$, and let
\begin{equation}\label{eq:derivative_max_delta}
\delta \coloneqq \frac{\epsilon}{3\norm{\lrate}^2}.
\end{equation}
Then, consider any $\Delta\neq 0$ such that $\lvert\Delta\rvert<\delta$. We will show that
\begin{equation*}
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert<\epsilon
\end{equation*}
Start by rewriting the statement slightly to prevent having to consider different cases for positive and negative $\Delta$. Let $t'\coloneqq\max\{t,t+\Delta\}$, and let $\Delta'\coloneqq t'-t$. Then,
\begin{equation*}
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert = \norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s}\,.
\end{equation*}
Now,
\begin{align*}
\norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s} &= \norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^{t'}L_{t'}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}L_{t'}^s} \\
 &\leq \norm{\frac{I - L_{t'-\lvert\Delta\rvert}^{t'}}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}}\norm{L_{t'}^s} \\
 &\leq \norm{\frac{I - L_{t'-\lvert\Delta\rvert}^{t'}}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}} \\
 &= \norm{\frac{I - L_{0}^{\lvert\Delta\rvert}}{\lvert\Delta\rvert}+\lrate L_{0}^{\Delta'}} \\
 &= \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert}-\lrate L_{0}^{\Delta'}} \\
 &\leq \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert}-\lrate} + \norm{\lrate - \lrate L_{0}^{\Delta'}} \\
 &\leq \frac{1}{\lvert\Delta\rvert}\cdot\norm{L_{0}^{\lvert\Delta\rvert} - (I+\lvert\Delta\rvert\lrate)} + 2\norm{\lrate}\norm{I - L_{0}^{\Delta'}} \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\Delta'\norm{\lrate}^2.
\end{align*}
Because $\Delta'$ satisfies either $\Delta'=0$ or $\Delta'=\lvert\Delta\rvert$, we have that $\Delta'\leq\lvert\Delta\rvert$. Thus,
\begin{align*}
\norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s} &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\Delta'\norm{\lrate}^2 \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &= 3\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &< 3\delta\norm{\lrate}^2 \\
 &= \epsilon\,,
\end{align*}
where the last step used Equation~\eqref{eq:derivative_max_delta}. This concludes the proof of Equation~\eqref{eq:lower_deriv_backward}. We will now prove Equation~\eqref{eq:lower_deriv_forward}.

Again choose any $\epsilon\in\realspos$, and let $\delta$ be given by
\begin{equation*}
\delta \coloneqq \frac{\epsilon}{2\norm{\lrate}^2}\,.
\end{equation*}
Consider any $\Delta\neq 0$ such that $\lvert\Delta\rvert<\delta$. We will show that
\begin{equation*}
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert<\epsilon\,.
\end{equation*}
We again first rewrite the statement to prevent having to perform case-work in the sign of $\Delta$. Let $s'\coloneqq\min\{s,s+\Delta\}$, and let $\Delta'\coloneqq s-s'$. Then,
\begin{equation*}
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert = \norm{\frac{L_t^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'+\Delta'}\lrate}\,.
\end{equation*}
Now,
\begin{align*}
\norm{\frac{L_t^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'+\Delta'}\lrate} &= \norm{\frac{L_t^{s'}L_{s'}^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'}L_{s'}^{s'+\Delta'}\lrate} \\
 &\leq \norm{L_t^{s'}}\norm{\frac{L_{s'}^{s'+\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{s'}^{s'+\Delta'}\lrate} \\
 &\leq \norm{\frac{L_{s'}^{s'+\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{s'}^{s'+\Delta'}\lrate} \\
 &= \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{0}^{\Delta'}\lrate} \\
 &\leq \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - \lrate} + \norm{\lrate - L_{0}^{\Delta'}\lrate} \\
 &\leq \frac{1}{\lvert\Delta\rvert}\cdot\norm{L_{0}^{\lvert\Delta\rvert} - (I+\lvert\Delta\rvert\lrate)} + \norm{\lrate}\norm{I - L_{0}^{\Delta'}} \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + \Delta'\norm{\lrate}^2 \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + \lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &= 2\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &< 2\delta\norm{\lrate}^2 \\
 &= \epsilon\,.
\end{align*}
\end{proof}

\end{document}
