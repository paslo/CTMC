\documentclass[10pt]{paper}
%\documentclass[3p]{elsarticle}
%\documentclass[a4paper,reqno]{amsart}
\usepackage[british]{babel}
%\usepackage[garamond]{mathdesign}

\usepackage{hyperref,url}

\usepackage{mathptmx}
\usepackage{amsmath}
\usepackage{courier}
\usepackage{amssymb}
%\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{enumitem,multicol}
\usepackage{tikz}
\usepackage{nicefrac}
\usepackage{bm}
%\usepackage{algorithm}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}

%\usepackage{hyperref}
%\usepackage{pdfsync}
%\usepackage{authblk}

\theoremstyle{definition}
\newtheorem{exmp}{Example}%[section]
 
\renewcommand{\ttdefault}{cmtt}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem*{remark*}{Remark}

\newtheorem{claim}{Claim}[theorem]
\newtheorem*{claim*}{Claim}

%\algrenewcommand\algorithmicrequire{\textbf{Input:}}
%\algrenewcommand\algorithmicensure{\textbf{Output:}}

% - macros

\newcommand{\nats}{\mathbb{N}}
\newcommand{\natswith}{\nats_{0}}
\newcommand{\reals}{\mathbb{R}}

\newcommand{\realspos}{\reals_{>0}}
\newcommand{\realsnonneg}{\reals_{\geq 0}}

\newcommand{\states}{\mathcal{X}}

\newcommand{\paths}{\Omega}
%\newcommand{\path}{\omega}

\newcommand{\power}{\mathcal{P}(\paths)}
\newcommand{\nonemptypower}{\power_{\emptyset}}
\newcommand{\events}{\mathcal{E}}
%\newcommand{\nonemptyevents}{\events^{\emptyset}}
\newcommand{\filter}[1][t]{\mathcal{F}_{#1}}
\newcommand{\eventst}[1][t]{\events_{#1}}

\newcommand{\processes}{\mathbb{P}}
\newcommand{\mprocesses}{\processes^{\mathrm{M}}}

\newcommand{\hmprocesses}{\processes^{\mathrm{HM}}}

\newcommand{\wprocesses}{\processes^{\mathrm{W}}}
\newcommand{\wmprocesses}{\processes^{\mathrm{WM}}}

\newcommand{\whmprocesses}{\processes^{\mathrm{WHM}}}


\newcommand{\lt}{\underline{T}}
\newcommand{\lbound}{L}

\newcommand{\gambles}{\mathcal{L}}
\newcommand{\gamblesX}{\gambles(\states)} 

\newcommand{\ind}[1]{\mathbb{I}_{#1}}

\newcommand{\rateset}{\mathcal{Q}}
\newcommand{\lrate}{\underline{Q}}

\newcommand{\asa}{\Leftrightarrow}
\newcommand{\then}{\Rightarrow}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\abs}[1]{\left\vert #1 \right\vert}

\newcommand{\coloneqq}{:\!=}

\newcommand{\opinset}{\,\,\widetilde{\in}\,\,}

\newcommand{\argmin}{\arg\min}

\newcommand{\exampleend}{\hfill$\Diamond$}

\def\presuper#1#2%
  {\mathop{}%
   \mathopen{\vphantom{#2}}^{#1}%
   \kern-\scriptspace%
   #2}

\title{Imprecise Continuous-Time Markov Chains}

%\author[1]{Thomas E. Krak\thanks{t.e.krak@uu.nl}}
%\author[2]{Jasper de Bock\thanks{jasper.debock@ugent.be}}
%\affil[1]{Universiteit Utrecht}
%\affil[2]{Ghent University}

\author{Thomas Krak \and Jasper de Bock}
%\author{Thomas Krak and Jasper de Bock}

\begin{document}

%\author{{\bf Thomas E. Krak} \\ Utrecht}
%\address{Utrecht University}
%\curraddr{}
%\email{t.e.krak@uu.nl}
%\thanks{}

%\author{{\bf Jasper de Bock} \\ Ghent}
%\address{Ghent University}

%\author{
	%{\bf Thomas E. Krak} \quad\quad {\bf Jasper de Bock} \\
%	Utrecht University \quad Ghent University \\
	%Department of Information and Computing Sciences \\
	%Princetonplein 5, De Uithof \\
	%3584 CC Utrecht \\
	%The Netherlands \\
%	\texttt{\quad\quad t.e.krak@uu.nl} \quad\quad \texttt{jasper.debock@ugent.be}
%\and
	%{\bf Jasper de Bock} \\
%	Ghent University \\
	%SYSTeMS Research Group \\
	%Technologiepark -- Zwijnaarde 914 \\
	%9052 Zwijnaarde \\ 
	%Belgium \\
%	\texttt{jasper.debock@ugent.be}
%}
\date{}
\maketitle

\begin{abstract}
Lorem ipsum.
\end{abstract}

\section{Introduction}\label{sec:introduction}

*** wat introtekst

*** motivatie: precieze discrete-tijd markov ketens, precieze continue-tijd markov ketens, bruikbaar (en gebruikt) in verschillende domeinen (voorbeelden)

\begin{exmp}
**** motivating toy example
\exampleend
\end{exmp}

*** aanhalen eerder werk in imprecieze varianten: imprecieze discrete-tijd, imprecieze continue-tijd (werk damjan), toepassingen (werk damjan + matthias)

*** doel dit paper: wat willen we doen en waarom, wat zijn onze hoofdresultaten

*** opbouw van paper

*** {\bf lange bewijzen en lemmas die niet verhelderend zijn staan allemaal in appendix}

\section{Preliminaries}\label{sec:prelim}

We will denote the reals as $\reals$, the non-negative reals as $\realsnonneg$, and the positive reals as $\realspos$. The natural numbers will be written as $\nats$, and we will denote $\nats_0\coloneqq\nats\cup\{0\}$. The rationals will be denoted by $\mathbb{Q}$.

Throughout this work, we will consider some fixed finite \emph{state space} $\states=\{1,\dots,m\}$. Let $\gamblesX$ denote the set of all real-valued functions on $\states$. Because $\states$ is finite, we can also interpret any function $f\in\gamblesX$ as a vector in $\reals^m$. Hence, we will in the sequel use the terms `function' and `vector' interchangeably when referring to elements of $\gamblesX$.

An important type of map from $\gamblesX$ to $\gamblesX$ will be matrices. Because the domain and range of these maps is always fixed, we will simply refer to them as `matrices', with which we then always mean `square, $m\times m$, real-valued matrices'. If $A$ is a matrix, we will index its elements as $A(x,y)$ for all $x,y\in\states$, where the indexing is understood to be row-major. Furthermore, $A(x,\cdot)$ will denote the $x$-th row of $A$, and $A(\cdot,y)$ will denote its $y$-th column. The symbol $I$ will be reserved throughout to refer to the $m\times m$ identity matrix.

Infinite sequences of quantities will be denoted $\{a_i\}_{i\in\nats}$, possibly with limit statements of the form $\{a_i\}_{i\in\nats}\to c$. If this sequence is in a space endowed with an ordering relation, we may write $\{a_i\}_{i\in\nats}\to c^+$ or $\{a_i\}_{i\in\nats}\to c^-$ if the limit is approached from above or below, respectively.

Finally, we will make extensive use of finite sequences of time points. For any such sequence $u\coloneqq t_0,t_1,\ldots,t_n$, with $n\in\nats$ and $t_i\in\realsnonneg$, $i\in\{0,\ldots,n\}$, we will write $u<t$ if $\max\left\{t_i:i\in\{0,\ldots,n\}\right\}<t$ for some $t\in\realsnonneg$. For all $t\in\realsnonneg$, we will denote the set of such sequences as $\mathcal{U}_{<t}$. We will sometimes allow $u$ to be an empty sequence, to prevent having to constantly consider several cases separately. However, we will be explicit when doing so. As a special case, for any $t,s\in\realsnonneg$ such that $t<s$, we consider ordered sequences $u$ that partition the interval $[t,s]$, and include the end-points of this interval. Thus, we then have that $u$ is such that $t=t_0 < t_1 <\ldots < t_n = s$, and we will use $\mathcal{U}_{[t,s]}$ to denote the set of all such sequences. Furthermore, given any $u\in\mathcal{U}_{[t,s]}$, we define for all $i\in\{1,\ldots,n\}$ the terms $\Delta_i\coloneqq (t_i-t_{i-1})$ that denote the distance between consecutive time points in $u$, and use $\sigma(u) \coloneqq \max\bigl\{\Delta_i\,:\,i\in\{1,\ldots,n\}\bigr\}$ to denote the maximum such distance.

*** SOME NEW NOTATION AND CONVENTIONS THAT I NEEDED ***

We let $\mathcal{U}$ be the set of all (possibly empty) sequences of time points. For any $u\in\mathcal{U}$, we let $\max u$ be the largest time point in $u$. If $u=\emptyset$, then $t>u$ is taken to be trivially true, regardless of the value of $t$.

\subsection{Operators and Norms}\label{sec:func_oper_norm}
For any vector $f\in\gamblesX$, we let
\begin{equation*}
\norm{f}\coloneqq\norm{f}_{\infty}\coloneqq\max\{\abs {f(x)}\colon x\in\states\}
\end{equation*}
be the maximum norm. For any operator $A$ from $\gamblesX$ to $\gamblesX$ that is non-negatively homogeneous, meaning that $A(\lambda f)=\lambda A(f)$ for all $f\in\gamblesX$ and all $\lambda\geq0$, we consider the induced operator norm
\begin{equation*}
\norm{A}\coloneqq\sup\left\{\norm{Af}\colon f\in\gamblesX,\norm{f}=1\right\}.
\end{equation*}
If $A$ is a matrix, we then have that
\begin{equation*}
\norm{A}
=
\max\left\{\sum_{y\in\states}\abs{A(x,y)}\colon x\in\states\right\}.
\end{equation*}
\noindent
Finally, for any set $\mathcal{A}$ of matrices, we define $\norm{\mathcal{A}}\coloneqq\sup\{\norm{A}\colon A\in\mathcal{A}\}$.


\noindent These norms satisfy the following properties. 

\begin{proposition}\label{prop:norm_properties}
For all $f,g\in\gamblesX$, all $A,B$ from $\gamblesX$ to $\gamblesX$ that are non-negatively homogeneous, all $\lambda\in\reals$ and all $x\in\states$, we have that
\vspace{5pt}

\begin{multicols}{2}
\begin{enumerate}[label=N\arabic*:,ref=N\arabic*]
\item
$\norm{f}\geq0$
\item
$\norm{f}=0\asa f=0$
\item
$\norm{f+g}\leq\norm{f}+\norm{g}$
\item
$\norm{\lambda f}=\abs{\lambda}\norm{f}$
\item
$\abs{f(x)}\leq\norm{f}$ \\
\item
$\norm{A}\geq0$
\item
$\norm{A}=0\asa A=0$
\item
$\norm{A+B}\leq\norm{A}+\norm{B}$
\item\label{N:homogeneous}
$\norm{\lambda A}=\abs{\lambda}\norm{A}$
\item\label{N:normAB}
$\norm{AB}\leq\norm{A}\norm{B}$
\item\label{N:normAf}
$\norm{Af}\leq\norm{A}\norm{f}$
\end{enumerate}
\end{multicols}
\end{proposition}

\subsection{wat notatie voor meerdere variabelen}\label{sec:multivar_notation}

*** dit kan opzich wel korter denk ik, maar kunnen we bij oppoetsen straks nog wel even checken ***

We will also find it convenient to have notation for functions defined on the state space at multiple time points.
To this end, consider any $t,s\in\realsnonneg$ such that $t<s$, and any $u\in\mathcal{U}_{[t,s]}$. We will now define
\begin{equation*}
\states^u\coloneqq \prod_{i=0}^n\states
\end{equation*}
to be the joint state space at times $t_0,\ldots,t_n$. Let $\gambles(\states^u)$ denote the set of functions on $(X_{t_0},\ldots,X_{t_n})$.

For any $t,t',s\in\realsnonneg$ such that $t<t'<s$ and any $u\in\mathcal{U}_{[t,t']}$, let $\states^{\{s\}}$ denote the state space at time $s$, and let
\begin{equation*}
\states^{u\cup\{s\}} \coloneqq \states^u\times\states^{\{s\}}
\end{equation*}
denote the joint state space at times $t_0,\ldots,t_n,s$. Similarly, for any $t,t',s,s'\in\realsnonneg$ such that $t<t'<s<s'$, any $u\in\mathcal{U}_{[t,t']}$ and $v\in\mathcal{U}_{[s,s']}$, let
\begin{equation*}
\states^{u\cup v}\coloneqq\states^u\times\states^v\,.
\end{equation*}
Let the sets of functions $\gambles(\states^{u\cup\{s\}})$ and $\gambles(\states^{u\cup v})$ be defined in the obvious manner.

For any function $f\in\gambles(\states^{\{t_0\}}\times\cdots\times\states^{\{t_n\}})$, let the norm $\norm{f}$ be defined as
\begin{equation*}
\norm{f} \coloneqq \max\left\{ \abs{f(x_{t_0},\ldots,x_{t_n})}\,:\,(x_{t_0},\ldots,x_{t_n})\in \states^{\{t_0\}}\times\cdots\times\states^{\{t_n\}}\right\}\,.
\end{equation*}

For the sake of brevity, we will also write a joint state assignment as
\begin{equation*}
\left(X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\right)\equiv (X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})\,.
\end{equation*}

**** {\bf ATTN:} We started using $x_u\in\states^u$ as shorthand notation for the state assignment $(x_{t_0},\ldots,x_{t_n})\in\states^{\{t_0\}}\times\cdots\times\states^{\{t_n\}}$. Still need to properly introduce that somewhere.

For a function $f\in\gambles(\states^{u\cup\{s\}})$, we will write $f(x_{t_0},\ldots,x_{t_n},X_s)$ for the restriction of $f$ to $\states^{\{s\}}$ specific to the joint state assignment $(x_{t_0},\ldots,x_{t_n})$. Thus, $f(x_{t_0},\ldots,x_{t_n},X_s)$ corresponds to a $g\in\gambles(\states^{\{s\}})$ such that $g(x_s) = f(x_{t_0},\ldots,x_{t_n},x_s)$ for all $x_s\in\states^{\{s\}}$.

Finally, we will want to use operators as defined in Section~\ref{sec:func_oper_norm} for functions defined on (multiple) explicit time points. It is clear that an operator $A$ defined on $\gamblesX$ can be applied to any element of a set of functions $\gambles(\states^{\{s\}})$ that depend on the state at just a single point in time. It remains to determine how to cope with functions defined on multiple time points. 

To avoid introducing overly complex notation, we will stipulate the following convention. If $f\in\gambles(\states^u)$ is a function defined on an ordered sequence $u$ of time points $t_0<t_1<\cdots<t_n$, and if $A$ is a non-negatively homogeneous operator from $\gamblesX$ to $\gamblesX$, we allow $A$ to be applied to $f$ by applying it to the restriction of $f$ to the state $\states^{\{t_n\}}$ at the \emph{latest} time point $t_n$ in $u$. Because such a restriction is dependent on the specific state assignment $(x_{t_0},\ldots,x_{t_{n-1}})$, the result is a function $[Af]\in\gambles(\states^{\{t_0,\ldots,t_{n-1}\}})$. In other words, we then have
\begin{equation*}
\left[Af\right](x_{t_0},\ldots,x_{t_{n-1}}) \equiv \left[A f(x_{t_0},\ldots,x_{t_{n-1}},X_{t_n})\right](x_{t_{n-1}})\,.
\end{equation*}

\subsection{Full Conditional Probabilities}\label{sec:cond_prob}

We will in Section~\ref{sec:stochastic_processes} define continuous-time stochastic processes using the framework of full conditional probabilities, which we describe here. 

Consider some arbitrary random experiment, with some (possibly infinite) \emph{possibility space} $\Omega$. An element $\omega\in\Omega$ of this set is then interpreted as one possible outcome of the random experiment. In order to describe multiple possible outcomes simultaneously, we use the notion of \emph{events}. Such an event $E$ is a subset of $\Omega$. We use $\power$ to denote the set of all events, and let $\nonemptypower\coloneqq\power\setminus\{\emptyset\}$. A full conditional probability measure $P$ is then a map from the set $\power\times\nonemptypower$ of all (conditional) events to $\reals$ that quantifies the uncertainty of the outcomes of the random experiment, as follows.

\begin{definition}[Full conditional probability]\label{def:cond_prob}
A full conditional probability $P$ is a real-valued map from $\power\times\nonemptypower$ to $\reals$ that satisfies the following axioms. For all $A,B\in\power$ and all \mbox{$C,D\in\nonemptypower$}:
\vspace{5pt}

\begin{enumerate}[label=F\arabic*:,ref=F\arabic*]
\item
$P(C\vert C)=1$;\label{def:coh_prob_1}
\item
$0\leq P(A\vert C)\leq 1$;\label{def:coh_prob_2}
\item
$P(A\cup B\vert C)=P(A\vert C)+P(B\vert C)$ if $A\cap B=\emptyset$;\label{def:coh_prob_3}
\item
$P(A\vert C)=P(A\vert D)P(D\vert C)$ if $A\subseteq D\subseteq C$.\label{def:coh_prob_4}
\end{enumerate}
\vspace{5pt}

\noindent
For any $A\in\power$ and $C\in\nonemptypower$, we call $P(A\vert C)$ the probability of $A$ conditional on $C$. Also, for any $A\in\power$, we use the shorthand notation $P(A)\coloneqq P(A\vert\paths)$ and then call $P(A)$ the probability of $A$.
The following additional properties can easily be shown to follow from \ref{def:coh_prob_1}--\ref{def:coh_prob_4}. For all $A\in\power$ and all $C,D\in\nonemptypower$:
\vspace{5pt}

\begin{enumerate}[label=F\arabic*:,ref=F\arabic*]
 \setcounter{enumi}{4}
\item
$P(\Omega\vert C)=1$;\label{def:coh_prob_5}
\item
$P(A\cap D\vert C)=P(A\vert D\cap C)P(D\vert C)$ if $D\cap C\neq\emptyset$;\label{def:coh_prob_6}
\item
$P(A\vert C)=P(A\cap C\vert C)$.\label{def:coh_prob_7}
\item
$P(\emptyset\vert C)=0$.\label{def:coh_prob_8}
\end{enumerate}
\vspace{5pt}

\end{definition}


The following notion of coherent conditional probabilities will be useful whenever we want to check if a given map $P$ from a set of events to $\reals$ is a well-defined conditional probability measure.

\begin{definition}[Coherent conditional probability]\label{def:coherence}
Let $P$ be a real-valued map from $\mathcal{C}\subseteq\power\times\nonemptypower$ to $\reals$. Then $P$ is said to be a \emph{coherent conditional probability} if, for all $n\in\mathbb{N}$ and every choice of $(A_i,C_i)\in\mathcal{C}$ and $\lambda_i\in\reals$, $i\in\{1,\dots,n\}$,
\begin{equation*}
\max\left\{\sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(P(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0\right\}\geq0,
\end{equation*}
with $C_0\coloneqq\cup_{i=1}^nC_i$.
\end{definition}

*** Explain that most authors consider a supremum. However, since $n$ is finite and because, for every $i\in\{1,\dots,n\}$, $\ind{A_i}$ and $\ind{C_i}$ can only take two values---$0$ or $1$---it follows that this supremum is taken over a finite set of real numbers, which implies that it is actually a maximum. ***

\begin{theorem}\label{theo:coherentextendable}
Let $P$ be a real-valued map from $\mathcal{C}\subseteq\power\times\nonemptypower$ to $\reals$. Then $P$ is a coherent conditional probability if and only if it can be extended to a full conditional probability.
\end{theorem}

\begin{corollary}\label{corol:fullcoherent}
Let $P$ be a real-valued map from $\power\times\nonemptypower$ to $\reals$. Then $P$ is a coherent conditional probability if and only if it is a full conditional probability.
\end{corollary}
\begin{proof}
Trivial consequence of Theorem~\ref{theo:coherentextendable}.
\end{proof}

\subsection{Transition (Rate) Matrices}\label{sec:trans_rate_matrices}

*** some intro text, explain why these are useful, and how they are related to stochastic processes

\begin{definition}[Transition Rate Matrix]\label{def:rate_matrix}
A real-valued matrix $Q$ is said to be a \emph{transition rate matrix}, or sometimes simply \emph{rate matrix}, if

\vspace{5pt}
\begin{enumerate}[label=R\arabic*:]
\item
$\sum_{y\in\states}Q(x,y)=0$ for all $x\in\states$;
\item
$Q(x,y)\geq0$ for all $x,y\in\states$ such that $x\neq y$.
\end{enumerate}
\vspace{5pt}
\noindent
We use $\mathcal{R}$ to denote the set of all transition rate matrices. 
\end{definition}

\noindent Clearly, $\mathcal{R}$ is closed under finite sums and multiplication with non-negative scalars. 

\begin{definition}[Transition Matrix]\label{def:stoch_matrix}
A real-valued matrix $T$ is said to be a \emph{transition matrix} if
\vspace{5pt}
\begin{enumerate}[label=S\arabic*:,ref=N\arabic*]
\item
$\sum_{y\in\states}T(x,y)=1$ for all $x\in\states$;\label{def:trans_matrix_is_stochastic}
\item
$T(x,y)\geq0$ for all $x,y\in\states$.
\end{enumerate}
\vspace{5pt}
\noindent
\end{definition}

\noindent We start by establishing some properties of the norm of these matrices. Both propositions follow trivially from the definitions.

\begin{proposition}
Let $Q$ be an arbitrary transition rate matrix. Then, $\norm{Q}<+\infty$.
\end{proposition}

\begin{proposition}
Let $T$ be an arbitrary transition matrix. Then, $\norm{T}=1$.
\end{proposition}

Consider now any set $\rateset\subseteq\mathcal{R}$ of rate matrices. Then $\rateset$ is said to be \emph{non-empty} if $\rateset\neq\emptyset$ and $\rateset$ is said to be \emph{bounded} if $\norm{\rateset}<+\infty$. The following proposition provides a simple alternative characterisation of boundedness.

\begin{proposition}\label{prop:alternativedefforbounded}
A set of rate matrices $\rateset\subseteq\mathcal{R}$ is bounded if and only if
\begin{equation*}
\inf\left\{Q(x,x)\colon Q\in\rateset\right\}>-\infty\text{~~for all $x\in\states$.}
\end{equation*}
\end{proposition}
\begin{proof}
*** {\bf TODO}
\end{proof}

*** tralala, rate matrices and transition matrices zijn sterk gelinkt.  intuitief geven rate matrices aan hoe snel een transitie kans veranderd, in termen van $\Delta$.

\begin{proposition}\label{prop:stochastic_from_rate_matrix}
Consider any transition rate matrix $Q\in\mathcal{R}$, and any $\Delta\in\realsnonneg$ such that $\Delta \leq \nicefrac{1}{\norm{Q}}$. Then, the matrix $(I+\Delta Q)$ is a transition matrix.
\end{proposition}

\begin{proposition}\label{prop:rate_from_stochastic_matrix}
Consider any transition matrix $T$, and any $\Delta\in\realspos$. Then, the matrix $\nicefrac{1}{\Delta}(T-I)$ is a transition rate matrix.
\end{proposition}

\section{Continuous-Time Stochastic Processes}\label{sec:stochastic_processes}

We will in this section start by formalizing the notion of continuous-time stochastic processes. Next, in Section~\ref{sec:well_behaved}, we describe a specific subclass of stochastic processes, which we call well-behaved, and on which we will largely focus throughout this work. Finally, Section~\ref{sec:dynamics} provides some tools with which we can describe the dynamics of stochastic processes.

We start by defining continuous-time stochastic processes. Such a stochastic process is a construct that moves through the state space $\states$ over a continuous time line $\realsnonneg$. A specific realization or instance of this behavior will be called a path or a trajectory. The stochasticity of the process is quantified using a full conditional probability measure on a set of events, which describe specific (combinations of) states in which the process can be at certain time points. These ideas are formalized as follows.

A \emph{path} $\omega$ is a cadlag function from $\realsnonneg$ to $\states$, where cadlag means that it is right continuous for all $t\in\realsnonneg$ and that the left limit exists for all $t\in\realspos$. Let $\paths$ be the set of all paths. For any path $\omega\in\paths$ and any time point $t\in\realsnonneg$, the value of $\omega$ in $t$ is denoted by $\omega(t)$. The set $\Omega$ will form the possibility space for a full conditional probability measure. Hence, an \emph{event} is a subset $E$ of $\paths$. We again denote the set of all events by $\power$ and we let $\nonemptypower\coloneqq\power\setminus\{\emptyset\}$. 

A stochastic process will be defined below as the restriction of a full conditional probability measure to a specific subset of the set $\power\times\nonemptypower$ of all (conditional) events, as follows.

For any $t\in\realsnonneg$ and $x\in\states$, we define the elementary event
\begin{equation*}
(X_t=x)\coloneqq\{\omega\in\paths\colon\omega(t)=x\}.
\end{equation*}
%We use $\events^{\mathrm{f}}$ to denote the set of all these elementary events. 
Similarly, for any finite ordered sequence of time points $u=t_1,\ldots,t_n$ with $n\in\nats_0$ and $t_i\in\realsnonneg,i\in\{1,\ldots,n\}$, and any state assignment $x_u\in\states^u$, we define the event
\begin{align*}
(X_u=x_u)\coloneqq\left(X_{t_1}=x_{t_1}, \dots, X_{t_n}=x_{t_n}\right)
\coloneqq&
%\bigcap_{i\in\{0,\dots,n\}}(X_{t_i}=x_{t_i})\\
%=&
\left\{\omega\in\paths\colon(\forall i\in\{1,\dots,n\}\,:~\omega(t_i)=x_{t_i})\right\}.%,
\end{align*}
%which we will sometimes also denote by $(X_{t_i}=x_{t_i}, i\in\{0,\dots,n\})$.
%We use $\events^{\mathrm{s}}$ to denote the set of all these events.
Consider now any $t\in\realsnonneg$. We then let $\mathcal{A}_{>t}$ be the algebra that is generated by all the elementary events $(X_s=x)$, for all $s> t$ and $x\in\states$,\footnote{This is the smallest subset of $\power$ that contains all these elementary events and that is furthermore closed under complements, finite unions and hence also finite intersections.} and we let $\mathcal{F}_{\leq t}$ be the set of all events $\left(X_{t_1}=x_{t_1}, \dots, X_{t_n}=x_{t_n}\right)$, for all finite sequences $u\leq t$ and all $x_u\in\states^u$.%, and we define $\filter\coloneqq\mathcal{C}_{\leq t}\setminus\{\emptyset\}$.

For a given $t\in\realsnonneg$, we will refer to $\mathcal{A}_{> t}$ as the set of possible future events, and to $\mathcal{F}_{\leq t}$ as the set of historic events, or possible histories.

*** Changing the definition a bit ***

For any set of events $\mathcal{E}\subseteq\power$, we use $\langle\mathcal{E}\rangle$ to denote the algebra that is generated by them. Using this notation, for any $u\in\mathcal{U}$, we let
\begin{equation*}
\mathcal{A}_u
\coloneqq
\left\langle
\left\{
(X_t=x)
\colon
x\in\states,t\in u\cup\reals_{>u}
\right\}
\right\rangle
\end{equation*}
be the algebra that is generated by the elementary events whose time point is either preceded by or belongs to $u$.

\begin{definition}[Stochastic Process]\label{def:stoch_process}
A \emph{stochastic process} is the restriction of a full conditional probability to
\begin{equation*}
\mathcal{C}^\mathrm{SP}\coloneqq\big\{
(A,X_u=x_u)
\colon
u\in\mathcal{U},~x_u\in\states^u,~A\in\mathcal{A}_u\big\}\subset\power\times\nonemptypower.
\end{equation*}
We denote the set of all such stochastic processes by $\processes$.
\end{definition}

\begin{corollary}\label{corol:processiffcoherent}
Let $P$ be a real-valued map from $\mathcal{C}^\mathrm{SP}$ to $\reals$. Then $P$ is a stochastic process if and only if it is a coherent conditional probability.
\end{corollary}
\begin{proof}
Trivial consequence of Theorem~\ref{theo:coherentextendable}.
\end{proof}

Because Definition~\ref{def:cond_prob} only covered finitely additive full conditional probability measures, this also restricts our definition of stochastic processes to finitely additive stochastic processes. The advantage is that this simplifies considerably the subsequent analysis, and, as shown below, the extension to a $\sigma$-additive stochastic process can always be made when this is required.

*** explain that $\sigma$-additivity is not required ***

*** discuss that a unique $\sigma$-additive extension always exists, but that for our purposes, it is not necessary to consider it ***

\begin{proposition}[\cite{berti2002coherent}, Theorem 2]
Let $P\in\processes$ be a stochastic process. Then, there exists an extension $P^*$ of $P$ to the set
\begin{equation*}
\mathcal{C}^{\mathrm{SP}*} \coloneqq \left\{(A,X_u=x_u)\colon
u\in\mathcal{U},~x_u\in\states^u,~A\in\sigma(\mathcal{A}_u)
\right\}\subset\power\times\nonemptypower\,,
\end{equation*}
where $\sigma(\mathcal{A}_u)$ is the $\sigma$-algebra generated by $\mathcal{A}_u$, such that $P^*$ is a coherent conditional probability that is $\sigma$-additive on $\mathcal{C}^{\mathrm{SP}*}$.
\end{proposition}
\begin{proof}
*** {\bf TODO}, but follows rather straightforwardly from \cite[Theorem 2]{berti2002coherent} and Lemma~\ref{lem:stoch_process_sigma_add_on_algebra}. Definitely works for a fixed $t$, maybe show that it also works for the set generated by all $t\in\realsnonneg$.
\end{proof}

\subsection{Well-behaved stochastic processes}\label{sec:well_behaved}

*** explain that stochastic process can behave in rather extreme ways. For example, the transition probabilities can jump instantaneously. In order to avoid this behavior, we restrict our attention to a subclass of stochastic processes, which we call well-behaved. ***

\begin{definition}[Well-Behaved Stochastic Process]
\label{def:well-behaved}
A stochastic process $P\in\processes$ is said to be \emph{well-behaved} if, for any time sequence $0\leq t_0<\dots<t_{n}<t$ and any set of states $x_{0},\dots,x_{n},x,y\in\states$:
\begin{equation*}
\limsup_{\Delta\to 0^{+}}\frac{1}{\Delta}\abs{P(X_{t+\Delta}=y\vert X_t=x, X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n})-\delta_{xy}}<+\infty
\end{equation*}
and
\begin{equation*}
\limsup_{\Delta\to 0^{+}}\frac{1}{\Delta}\abs{P(X_{t}=y\vert X_{t-\Delta}=x, X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n})-\delta_{xy}}<+\infty
\end{equation*}
The set of all well-behaved stochastic processes is denoted by $\wprocesses$.
\end{definition}

This definition of well-behavedness is related to continuity and differentiability, but stronger than the former and weaker than the latter. Example~\ref{exmp:well-behaved} below, and Example~\ref{exmp:well-behaved-no-deriv} in Section~\ref{sec:dynamics}, provide some intuition on this.

\begin{exmp}\label{exmp:well-behaved}
Suppose that a stochastic process $P\in\processes$ is such that, at some time $t\in\realsnonneg$ and for some history $x_u\in\states^u$, $u<t$, for some $x\in\states$ it satisfies for all $\Delta\in[0,1]$,
\begin{equation*}
P(X_{t+\Delta}=x\,\vert\,X_{t}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}) = 1-\sqrt{\Delta}\,.
\end{equation*}
This apparently makes sense, at least in that this probability takes values in the range $[0,1]$, and in that it holds that
\begin{equation*}
P(X_{t}=x\,\vert\,X_{t}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}) = 1\,.
\end{equation*}
Furthermore, this probability is continuous in $\Delta$. However, we clearly have that
\begin{equation*}
\frac{1}{\Delta}\abs{P(X_{t+\Delta}=x\,\vert\,X_{t}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}) - \delta_{xx}} \to +\infty\,,\quad\text{as $\Delta\to0^+$,}
\end{equation*}
and hence $P$ is not well-behaved.
\exampleend
\end{exmp}

\subsection{Process Dynamics}\label{sec:dynamics}

We will now introduce some tools to describe the behavior of stochastic processes. Rather than work with the individual probabilities, it will be convenient to jointly consider probabilities that are related by the same conditioning event. To this end, we will next introduce the notion of transition matrices corresponding to a given stochastic process.

\begin{definition}[Corresponding Transition Matrix]\label{def:trans_matrix}
Consider any stochastic process $P\in\processes$. Then, for any $t,s\in\realsnonneg$ such that $t\leq s$, the \emph{corresponding transition matrix} $T_t^s$ is a matrix that is defined by
\begin{equation*}
T_t^s(x_t, x_s) \coloneqq P(X_s=x_s\,\vert X_t=x_t)\quad\text{for all $x_s,x_t\in\states$}\,.
\end{equation*}
We denote this family of matrices by $\mathcal{T}_P$.%, and call it the \emph{system of transition matrices} that corresponds to $P$.
\end{definition}

Because we will also want to work with conditioning events that contain more than a single time point, we furthermore introduce the following generalization.

\begin{definition}[History-Dependent Corresponding Transition Matrix]
Let $P\in\processes$ be any stochastic process. Then, for any $t,s\in\realsnonneg$ such that $t\leq s$, any sequence of time points $u<t$, and any state assignment $x_u\in\states^u$, the corresponding \emph{history-dependent} transition matrix $T_{t,\,x_u}^s$ is a matrix that is defined by
\begin{equation*}
T^s_{t,\,x_u}(x_t,x_s)
\coloneqq
P(X_s=x_s\vert X_t=x_t, X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n})\quad\text{for all $x_s,x_t\in\states$}\,.
\end{equation*}
For notational convenience, we will allow $u$ to be empty, in which case we will simply have that $T_{t,\,x_u}^s=T_t^s$.
\end{definition}

The following proposition establishes some simple properties of these corresponding (history-dependent) transition matrices.

\begin{proposition}\label{prop:stochasticprocess:simpleproperties}
Let $P\in\processes$ be a stochastic process.  %Then for any $t,s\in\realsnonneg$ such that $t\leq s$, $T_t^s$ is a transition matrix and $T_t^t=I$ and, if $P$ is well-behaved, then also
%\begin{equation}\label{eq:wellbehavedtransitionmatrix}
%\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_t^{t+\Delta}-I}<+\infty
%\text{~~~~and~~~~}
%\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_{t-\Delta}^t-I}<+\infty.
%\end{equation}
%Similarly, 
Then, for any $t,s\in\realsnonneg$ such that $t\leq s$, any sequence of time points $u<t$, and any state assignment $x_u\in\states^u$, the corresponding (history dependent) transition matrix $T_{t,\,x_u}^s$ is---as its name suggests---a transition matrix, and $T_{t,\,x_u}^t=I$. Furthermore, $P$ is well-behaved if and only if
\begin{equation}\label{eq:wellbehavedtransitionmatrix}%\label{eq:wellbehavedhistorictransitionmatrix}
\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_{t,x_u}^{t+\Delta}-I}<+\infty
\text{~~~~and~~~~}
\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_{t-\Delta,x_u}^t-I}<+\infty.
\end{equation}
for all $u\in\mathcal{U}$, $x_u\in\states^u$ and $t\in\reals_{\geq0}$ such that $t>u$.
\end{proposition}
\begin{proof}
Trivial consequence of Definitions~\ref{def:stoch_matrix}, \ref{def:cond_prob}, and \ref{def:well-behaved}.
\end{proof}

\begin{remark*}
Note that for any $P\in\processes$, a corresponding transition matrix $T_{t, x_u}^s$ is a map from $\gamblesX$ to $\gamblesX$, that can therefore be applied to any $f\in\gamblesX$. Observe that for all $x_t\in\states$, we have that
%\begin{align*}
%\left[T_t^sf\right](x_t) &= \sum_{x_s\in\states}f(x_s)P(X_s=x_s\,\vert\,X_t=x_t)
%= \mathbb{E}\left[f(X_s)\,\vert\,X_t=x_t\right]\,,
%\end{align*}
\begin{align*}
\left[T_{t,x_u}^sf\right](x_t) &= \sum_{x_s\in\states}f(x_s)P(X_s=x_s\,\vert\,X_t=x_t,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})\\
 &= \mathbb{E}\left[f(X_s)\,\vert\,X_t=x_t, X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right]\,,
\end{align*}
where the expectation is taken with respect to $P$. %Similarly, for any history-dependent transition matrix $T_{t,x_u}^s$, we have that
\exampleend
\end{remark*}

Because a stochastic process is defined on a continuous time line, and because its corresponding transition matrices $T_{t,x_u}^s$ only describe the behavior of this process on a fixed point in time, we will furthermore require some tools to capture the dynamics of a given process. That is, we will be interested in how these transition matrices change over time.

One seemingly obvious way to describe these dynamics is to use the derivatives of a process' corresponding transition matrices. Unfortunately, for general stochastic processes, these derivatives do not necessarily exist. In fact, also the slightly weaker directional derivatives---which we define below---are not guaranteed to exist. Worse still, they are not even guaranteed to exist for well-behaved processes.

\begin{definition}[Directional Partial Derivatives]\label{def:direc_partial_deriv}
For any stochastic process $P\in\processes$, any $t\in\realsnonneg$, any sequence of time points $u<t$, and any state assignment $x_u\in\states^u$, the \emph{right-} and \emph{left-sided partial derivatives} of $T_{t,x_u}^t$ are defined, respectively, as
\begin{equation*}
\partial_{+}{T_{t,\,x_u}^t}
\coloneqq
\lim_{\Delta\to 0^{+}}
\frac{1}{\Delta}
(T^{t+\Delta}_{t,\,x_u}-T^t_{t,\,x_u})
=
\lim_{\Delta\to 0^{+}}
\frac{1}{\Delta}
(T^{t+\Delta}_{t,\,x_u}-I)
\end{equation*}

\begin{equation*}
\partial_{-}{T_{t,\,x_u}^t}
\coloneqq
\lim_{\Delta\to 0^{+}}
\frac{1}{\Delta}
(T^{t}_{t-\Delta,\,x_u}-T^t_{t,\,x_u})
=
\lim_{\Delta\to 0^{+}}
\frac{1}{\Delta}
(T^{t}_{t-\Delta,\,x_u}-I)
\end{equation*}
\noindent If these partial derivatives exist, then because of Proposition~\ref{prop:rate_from_stochastic_matrix}, they are guaranteed to belong to the set of rate matrices  $\mathcal{R}$. If they both exist and coincide, we write $\partial{T_{t,\,x_u}^t}$ to denote their common value.
\end{definition}

\begin{exmp}\label{exmp:well-behaved-no-deriv}
Suppose that a well-behaved stochastic process $P\in\wprocesses$ is such that, at some time $t\in\realsnonneg$ and for some history $x_u\in\states^u$, $u<t$, the corresponding transition matrix $T_{t,x_u}^{t+\Delta}$ satisfies, for all $\Delta\in\realspos$,
\begin{equation*}
\frac{1}{\Delta}(T_{t,x_u}^{t+\Delta} - I) = \left\{\begin{array}{cl}
Q_1 & \quad \text{if $\Delta\in\mathbb{Q}$, and} \\
Q_2 & \quad \text{otherwise,}
\end{array}\right.
\end{equation*}
for some rate matrices $Q_1,Q_2\in\mathcal{R}$ with $Q_1\neq Q_2$. Clearly, the norm of this quantity is bounded for all $\Delta\in\realspos$, and hence this does not pose a problem for the well-behavedness of $P$. On the other hand, $\partial_{+}{T_{t,\,x_u}^t}$ clearly does not exist.
\exampleend
\end{exmp}

Because these directional partial derivatives do not necessarily exist, it will be more convenient to instead work with \emph{outer partial derivatives} {\bf (REF)}. Intuitively, these can be seen as a kind of set-valued derivatives, containing all accumulation points of the difference equations in Definition~\ref{def:direc_partial_deriv}, obtained as $\Delta\to0^+$.

\begin{definition}[Outer Partial Derivatives]
For any stochastic process $P\in\processes$, any $t\in\realsnonneg$, any sequence of time points $u<t$, and any state assignment $x_u\in\states^u$, the \emph{right-} and \emph{left-sided} \emph{outer partial derivatives} of $T_{t,x_u}^t$ are defined, respectively, as
\begin{align}
\label{eq:rightouterderivative}
\begin{split}
\overline{\partial}_{+}
{T^t_{t,\,x_u}}
&\coloneqq
\left\{
Q\in\mathcal{R}
\colon
\left(\exists \,\{\Delta_i\}_{i\in\nats}\to0^+\,:\,
~
%\lim_{i\to+\infty}\Delta_i=0
%\text{~~and~}
\lim_{i\to+\infty}
\frac{1}{\Delta_i}
(T^{t+\Delta_i}_{t,\,x_u}-I)
=Q
\right)
\right\}\\
\overline{\partial}_{-}
{T^t_{t,\,x_u}}
&\coloneqq
\left\{
Q\in\mathcal{R}
\colon
\left(\exists\, \{\Delta_i\}_{i\in\nats}\to0^+\,:\,
~
%\lim_{i\to+\infty}\Delta_i=0
%\text{~~and~}
\lim_{i\to+\infty}
\frac{1}{\Delta_i}
(T^{t}_{t-\Delta_i,\,x_u}-I)
=Q
\right)
\right\}
\end{split}
\end{align}
Furthermore, the \emph{outer partial derivative} of $T_{t,x_u}^t$ is defined as
\begin{equation*}
\overline{\partial}
{T^t_{t,\,x_u}}
\coloneqq
\overline{\partial}_{+}
{T^t_{t,\,x_u}}
\cup
\overline{\partial}_{-}
{T^t_{t,\,x_u}}\,.
\end{equation*}
\end{definition}

The next result shows that, at least for well-behaved processes $P\in\wprocesses$, these outer partial derivatives always exist; in particular, that they are non-empty and bounded.

\begin{proposition}\label{prop:boundednon-emptyandclosed}
For any $P\in\wprocesses$, $\overline{\partial}_{+}
{T^t_{t,\,x_u}}$, $\overline{\partial}_{-}
{T^t_{t,\,x_u}}$ and $\overline{\partial}
{T^t_{t,\,x_u}}$ are non-empty, bounded and closed subsets of $\mathcal{R}$.
\end{proposition}

\noindent Furthermore, these right- and left-sided outer partial derivatives are clearly related to the directional partial derivatives. The next statement makes this explicit for well-behaved stochastic processes, using an $\epsilon-\delta$ expression for the limits in Definition~\ref{def:direc_partial_deriv}.

\begin{proposition}\label{prop:outerderivativebehaveslikelimit}
Consider any well-behaved stochastic process $P\in\wprocesses$. Then, for any $t\in\realsnonneg$, any sequence of time points $u<t$, any state assignment $x_u\in\states^u$, and any $\epsilon>0$, there is some $\delta>0$ such that, for all $0<\Delta<\delta$:
\begin{equation}
\label{eq:outerderivativebehaveslikelimit1}
(\exists Q\in\overline{\partial}_{+}
{T^t_{t,\,x_u}})
\norm{\frac{1}{\Delta}
(T^{t+\Delta}_{t,\,x_u}-I)-Q}<\epsilon
\end{equation}
and
\begin{equation}
\label{eq:outerderivativebehaveslikelimit2}
(\exists Q\in\overline{\partial}_{-}
{T^t_{t,\,x_u}})
\norm{\frac{1}{\Delta}
(T^{t}_{t-\Delta,\,x_u}-I)-Q}<\epsilon
\end{equation}
\end{proposition}

We conclude this section by establishing that, for well-behaved processes, the outer partial derivatives are a proper generalization of the directional partial derivatives. In particular, if the latter exist, their values correspond exactly to the elements of the former.

\begin{corollary}\label{corol:outersingleton}
Consider any $P\in\wprocesses$. Then $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$ is a singleton if and only if $\smash{\partial_{+}
{T^t_{t,\,x_u}}}$ exists and, in that case, $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}=\{\partial_{+}
{T^t_{t,\,x_u}}\}$. Analogous results hold for $\smash{\overline{\partial}_{-}
{T^t_{t,\,x_u}}}$ and $\smash{\partial_{-}
{T^t_{t,\,x_u}}}$, and for $\smash{\overline{\partial}
{T^t_{t,\,x_u}}}$ and $\smash{\partial
{T^t_{t,\,x_u}}}$.
\end{corollary}
\begin{proof}
This follows trivially from Proposition~\ref{prop:outerderivativebehaveslikelimit}.
\end{proof}

\section{Continuous-Time Markov Chains}\label{sec:cont_time_markov_chains}

Having introduced continuous-time stochastic processes in Section~\ref{sec:stochastic_processes}, we will in this section focus on a specific class of such processes: the \emph{continuous-time Markov chains}.

\begin{definition}[Markov Property, Markov Chain]\label{def:markov_property}
A stochastic process $P\in\processes$ satisfies the \emph{Markov property} if, for any time sequence $0\leq t_0<\dots<t_{n}<t<s$ and any set of states $x_{0},\dots,x_{n},x,y\in\states$:
\begin{equation*}
P(X_s=y\vert X_{t}=x)=P(X_s=y\vert X_t=x, X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n}).
\end{equation*}
A stochastic process that satisfies this property is called a \emph{Markov chain}. We denote the set of all Markov chains by $\mprocesses$ and use $\wmprocesses$ to refer to the subset that only contains the well-behaved Markov chains.
\end{definition}

\subsection{Transition Matrix Systems}\label{sec:trans_mat_systems}

We know from Proposition~\ref{prop:stochasticprocess:simpleproperties} that the transition matrices of a stochastic process---and therefore also, in particular, of a Markov chain---satisfy a number of simple properties. For the specific case of a Markov chain $P\in\mprocesses$, the family of transition matrices $\mathcal{T}_P$ also satisfies an additional property---see Equation~\eqref{eq:transmatrixproduct} below. Whenever this is the case, we will call such a family of transition matrices a transition matrix system.

\begin{definition}[Transition matrix system]
A \emph{transition matrix system} $\mathcal{T}$ is a family of transition matrices $T_t^s$, defined for all $0\leq t\leq s$, such that
\begin{equation}\label{eq:transmatrixproduct}
T_t^s=T_t^r T_r^s
\text{~~for all $0\leq t\leq r\leq s$}
\end{equation}
and $T_t^t=I$ for all $t\geq0$. A transition matrix system  $\mathcal{T}$ is called \emph{well-behaved} if 
\begin{equation}\label{eq:wellbehavedtransitionmatrixsystem}%\label{eq:wellbehavedhistorictransitionmatrix}
\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_{t}^{t+\Delta}-I}<+\infty
\text{~~~~and~~~~}
\lim_{\Delta\to 0^{+}}\frac{1}{\Delta}\norm{T_{t-\Delta}^t-I}<+\infty.
\end{equation}
for all $t\in\reals_{\geq0}$.
\end{definition}

\begin{proposition}\label{prop:Markovhassystem}
Consider a Markov chain $P\in\mprocesses$ and let $\mathcal{T}_P$ be the corresponding family of transition matrices. Then $\mathcal{T}_P$ is a transition matrix system. Furthermore, $\mathcal{T}_P$ is well-behaved if and only if $P$ is well-behaved.
\end{proposition}

At this point, we already know that every (well-behaved) Markov chain has a corresponding (well-behaved) transition matrix system. Our next result establishes that the converse is true as well: every (well-behaved) transition matrix system has a corresponding (well-behaved) Markov chain, and for a given initial distribution, this Markov chain is even unique.

\begin{theorem}\label{theo:uniqueMarkovchain}
 Let $p$ be an arbitrary mass function on $\states$ and let $\mathcal{T}$ be a transition matrix system. Then there is a unique Markov chain $P\in\mprocesses$ such that $\mathcal{T}_P=\mathcal{T}$ and, for all $y\in\states$, $P(X_0=y)=p(y)$. Furthermore, if $\mathcal{T}$ is well-behaved, then $P$ is also well-behaved.
\end{theorem}

Hence, Markov chains---and well-behaved Markov chains in particular---are completely characterised by their transition matrices and their initial distribution. 
We now focus on a number of special cases.

\subsection{Homogeneous Markov chains}\label{sec:homogen_markov_chain}

\begin{definition}[Homogeneous Markov chain]\label{def:homogeneousMarkov}
A Markov chain $P\in\mprocesses$ is called \emph{homogeneous} if its transition matrices $T_t^s$ do not depend on the absolute value of $t$ and $s$, but only on the time-difference $s-t$:
\begin{equation}\label{eq:homogeneousMarkov}
T_t^s=T_{t+\Delta}^{s+\Delta}
\text{~~for all $0\leq t\leq s$ and $\Delta\geq0$.}
\end{equation}
We denote the set of all homogeneous Markov chains by $\hmprocesses$ and use $\whmprocesses$ to refer to the subset that consists of the well-behaved homogeneous Markov chains.
\end{definition}


\begin{definition}\label{def:systemfromQ}For any rate matrix $Q\in\mathcal{R}$, we use $\mathcal{T}_Q$ to denote the family of stochastic matrices that is defined by
\begin{equation*}
T_t^s=e^{Q(s-t)}
\text{~~for all $t,s\in\realsnonneg$ such that $t\leq s$.}
\end{equation*}
Here, the right-hand side denotes the \emph{matrix exponential} of $Q(s-t)$ {\bf REF}. *** we verwijzen voor nu gewoon naar de literatuur, en komen later nog terug op wat details
\end{definition}

\begin{proposition}
\label{prop:systemQ}
For any $Q\in\mathcal{R}$, $\mathcal{T}_Q$ is a well-behaved transition matrix system.
\end{proposition}
\begin{proof}
*** trivial ***
\end{proof}

\begin{corollary}\label{cor:rate_has_unique_homogen_markov_process}
Consider any rate matrix $Q\in\mathcal{R}$ and let $p$ be an arbitrary mass function on $\states$. Then there is a unique Markov chain $P\in\mprocesses$ such that $\mathcal{T}_P=\mathcal{T}_Q$ and $P(X_0)=p(X_0)$ and, furthermore, this unique Markov chain is well-behaved and homogeneous.
\end{corollary}

%As our next result shows, the converse is true as well: every well-behaved transition matrix system of a well-behaved homogeneous Markov chain can be uniquely characterised by a single transition rate matrix.

\begin{theorem}\label{theo:homogeneoushasQ}
For any well-behaved homogeneous Markov chain $P\in\whmprocesses$, there is a unique rate matrix $Q\in\mathcal{R}$ such that $\mathcal{T}_P=\mathcal{T}_Q$.
\end{theorem}

Hence, any well-behaved homogenous Markov chain $P\in\whmprocesses$ is completely characterised by its initial distribution and a rate matrix $Q\in\mathcal{R}$. We will denote this rate matrix by $Q_P$.

\subsection{Restricted Transition Matrix Systems}

**** blablabla

Recall from Section~\ref{sec:trans_mat_systems} that a transition matrix system $\mathcal{T}$ is a family of transition matrices $T_t^s$, defined for all $t,s\in\realsnonneg$ for which $t\leq s$. In particular, such a family of matrices satisfies $T_t^t=I$ for all $t\in\realsnonneg$, and $T_t^s=T_t^rT_r^s$ for all $t,r,s\in\realsnonneg$ with $t\leq r\leq s$.

We will now consider restrictions of transition matrix systems to some specified interval of $\realsnonneg$. In particular, for any transition matrix system $\mathcal{T}$ and any $t,s\in\realsnonneg$, let
\begin{equation*}
\mathcal{T}^{[t,s]} \coloneqq \left\{T_q^r\in\mathcal{T}\,:\,q,r\in[t,s],\, q\leq r\right\}\,.
\end{equation*}
We call such a family $\mathcal{T}^{[t,s]}$ a \emph{restricted transition matrix system}.

Because these restricted transition matrix systems are only defined on some given interval, it will be useful to define a concatenation operator between two such systems defined on adjacent intervals. To his end, for any $t,r,s\in\realsnonneg$ such that $t\leq r\leq s$, and any two restricted transition matrix systems $\mathcal{T}^{[t,r]}$ and $\mathcal{T}^{[r,s]}$, let
\begin{align*}
\mathcal{T}^{[t,r]} \otimes \mathcal{T}^{[r,s]} \coloneqq &\mathcal{T}^{[t,r]} \cup \mathcal{T}^{[r,s]} \\
 &\quad \cup \left\{T_\tau^\sigma\coloneqq T_\tau^rT_r^{\sigma}\,\Big\vert\,T_{\tau}^r\in\mathcal{T}^{[t,r]},\,T_r^{\sigma}\in\mathcal{T}^{[r,s]},\,\forall\tau\in[t,r],\,\forall\sigma\in[r,s]\right\}\,.
\end{align*}
\begin{proposition}\label{prop:concat_restr_trans_mat_systems_is_system}
Consider any $t,r,s\in\realsnonneg$ such that $t\leq r\leq s$, and any two restricted transition matrix systems $\mathcal{T}^{[t,r]}$ and $\mathcal{T}^{[r,s]}$. Then,
\begin{equation*}
\mathcal{T}^{[t,s]} \coloneqq \mathcal{T}^{[t,r]}\otimes \mathcal{T}^{[r,s]}
\end{equation*}
is a restricted transition matrix system defined on $[t,s]$. Furthermore, if both $\mathcal{T}^{[t,r]}$ and $\mathcal{T}^{[r,s]}$ are well behaved, then $\mathcal{T}^{[t,s]}$ is also well-behaved.
\end{proposition}

\subsection{Non-homogeneous Markov chains}

In contrast to homogeneous Markov chains, a Markov chain for which Equation~\eqref{eq:homogeneousMarkov} does not hold is called---rather obviously---\emph{non-homogeneous}. While we know from Theorem~\ref{theo:homogeneoushasQ} that homogeneous Markov chains can be characterized (up to an initial distribution) by a fixed rate matrix $Q\in\mathcal{R}$, this does not hold for non-homogeneous Markov chains. 

Instead, such systems are typically described by a function $Q_t$ that gives for each time point $t\in\realsnonneg$ a rate matrix $Q_t\in\mathcal{R}$. For any such function $Q_t$, the existence and uniqueness of a corresponding non-homogeneous Markov chain then depend on the specific properties of $Q_t$. Rather than attempt to treat all these different cases here, we instead refer to some examples from the literature. 

Typically, some kind of (piecewise-)continuity of $Q_t$ in terms of $t$ is assumed. The specifics of these assumptions may then depend on the intended generality of the results, computational considerations, the domain of application, and so forth. For example,~\cite{aalen1978empirical} assumes that $Q_t$ is left-continuous and has bounded right-hand limits. As a stronger restriction,~\cite{johnson1989nonhomogeneous} uses a collection $Q_1,\ldots,Q_n$ of commuting rate matrices, and defines $Q_t$ as a weighted linear combination of these component rate matrices wherein the weights vary continuously with $t$. In~\cite{rindos1995exact}, a right-continuous and piecewise-constant $Q_t$ is used, meaning that $Q_t$ takes different values on various (half-open) intervals of $\realsnonneg$, but fixed values within those intervals.

The case of a left-continuous and piecewise-constant $Q_t$ is used in some proofs in our present work, and we have therefore chosen to include it here for completeness. The formal construction of such a $Q_t$, and specifically that of a corresponding transition matrix system $\mathcal{T}_{Q_t}$, is somewhat convoluted. We have therefore moved its construction to Lemma~\ref{lemma:nonhomogen_trans_mat_system} in the appendix. Intuitively, the result below can be understood as describing the existence of a non-homogeneous Markov chain that is constructed by piecing together various homogeneous Markov chains on given intervals.

\begin{proposition}\label{prop:continuous_rate_matrix_has_process}
Consider any left-continuous, piecewise-constant function $Q_t$ that gives for each time point $t\in\realsnonneg$ a rate matrix $Q_t\in\mathcal{R}$, such that $Q_t$ takes different values on at most a finite number of intervals. Then, there exists a well-behaved continuous-time Markov chain $P\in\wmprocesses$ such that $\mathcal{T}_P=\mathcal{T}_{Q_t}$, where $\mathcal{T}_{Q_t}$ is defined as in Lemma~\ref{lemma:nonhomogen_trans_mat_system}.
\end{proposition}

\section{Imprecise Continuous-Time Markov chains}
\label{sec:iCTMC}

**** stukje algemene intro imprecise probability

*** stukje intro lower expectations

\begin{definition}[Lower Expectation]\label{def:lower_exp}
Consider any set of stochastic processes $\mathcal{P}\subseteq\processes$. Then, the \emph{(conditional) lower expectation with respect to $\mathcal{P}$} is defined as
\begin{equation*}
\underline{\mathbb{E}}[\cdot\,\vert\,\cdot] \coloneqq \inf\left\{\mathbb{E}[\cdot\,\vert\,\cdot]\,:\,P\in\mathcal{P}\right\}\,.
\end{equation*}
\end{definition}

Because such (conditional) lower expectations are linked to a given set $\mathcal{P}\subseteq\processes$ of stochastic processes, we will next look at how we can describe such a set $\mathcal{P}$.
Recall from Section~\ref{sec:dynamics} that for a given stochastic process $P\in\processes$, its behavior can be described using the outer partial derivatives $\smash{\overline{\partial}}T_{t,\,x_u}^t$ of its transition matrices $T_{t,\,x_u}^t$ at each time point $t\in\realsnonneg$ and for each history $x_u\in\states^u$. There, we found that---at least for well-behaved processes---these outer partial derivatives are non-empty bounded sets of rate matrices. Hence, because individual stochastic processes can be described using sets of rate matrices, this is also a natural starting point for describing sets of processes.

Therefore, consider some non-empty bounded set $\rateset\subset\mathcal{R}$ of rate matrices. We can then ask if there are any processes that are described by this set $\rateset$. Indeed, we found in Section~\ref{sec:homogen_markov_chain} that for any $Q\in\rateset$, there is a well-behaved homogeneous Markov chain that is characterized---up to its initial distribution---by this $Q$. Hence, an obvious way to construct a set $\mathcal{P}$ from a given set $\rateset$ is as the set of well-behaved homogeneous Markov chains characterized by elements of $\rateset$. Observe, however, that in doing so we ignore the initial distributions of these processes. %Therefore, one obvious way to describe a set of well-behaved homogeneous Markov chains $\mathcal{P}\subset\whmprocesses$ is with the set of rate matrices that characterize the various $P\in\mathcal{P}$. Turning this around, we can for a given set $\rateset\subset\mathcal{R}$ construct $\mathcal{P}$ as the set of all well-behaved homogeneous Markov chains described by elements of $\rateset$. Note that in either case---describing $\mathcal{P}$ with some $\rateset$, or, given some $\rateset$, constructing a $\mathcal{P}$---we ignore the initial distributions of the processes. 
We here briefly note that this is not problematic for our intended purposes, and will return to this observation shortly.

For now, we first consider whether we can also describe sets of non-homogeneous, (non-)Markov processes using a given set $\rateset$ of rate matrices. However, it should be clear that for such processes, this is less straightforward than in the homogeneous case. In particular, because such a set $\rateset$ is not explicitly connected to any time point $t$ or history $x_u$, asking if a (non-homogeneous, non-Markov) process is described by this set is in some sense an ill-posed question.
Therefore, rather than asking if a process can be described by some set of rate matrices, we will now introduce the following weaker notion of \emph{consistency} of a stochastic process with a given set of rate matrices.

\begin{definition}[Consistent Process]
Consider any non-empty bounded set $\rateset$ of rate matrices, and any stochastic process $P\in\processes$. Then $P$ is said to be \emph{consistent} with $\rateset$, if
\begin{equation*}
(\forall t\in\realsnonneg)(\forall u\in\mathcal{U}_{<t})(\forall x_u\in\states^u)\,:\, \smash{\overline{\partial}}T_{t,x_u}^t \subseteq \rateset\,.
\end{equation*}
If $P$ is consistent with $\rateset$, we will write $P\sim\rateset$.
\end{definition}

Thus, when a process $P\in\processes$ is consistent with some $\rateset\subset\mathcal{R}$, we know that its behavior over time can always be described using the elements of $\rateset$. However, we do not know which of these elements $Q\in\rateset$ describe this behavior at any given time  $t\in\realsnonneg$ or for any given history $x_u\in\states^u$. Furthermore, consistency of a process with some set $\rateset$ only asserts ``consistency in behavior"; in particular, it does not tell us anything about the initial distribution of the process. It should therefore be clear that there will be many processes consistent with any non-empty bounded set $\rateset\subset\mathcal{R}$. The next example shows that this is already the case when $\rateset$ is singleton.

\begin{exmp}\label{example:singleton_infinite_consistent}
Suppose that $\rateset=\{Q\}$ for some $Q\in\mathcal{R}$. Then, there are an infinite number of stochastic processes consistent with $\rateset$. In particular, recall from Section~\ref{sec:homogen_markov_chain} that there exists a well-behaved homogeneous Markov chain that is characterized uniquely by the rate matrix $Q$, \emph{up to} its initial distribution $P(X_0)$. Therefore, for each choice of probability mass function $p$ on $\states$, there is a well-behaved homogeneous Markov chain $P$ that is consistent with $\rateset$, and for which $P(X_0=x)=p(x)$ for all $x\in\states$.
\exampleend
\end{exmp}

Hence, if we consider the set $\mathcal{P}$ of all stochastic processes consistent with some $\rateset$, this set will contain (infinitely) many processes that differ only in their initial distributions. Of course, this should hardly be surprising; even individual homogeneous Markov chains require both a rate matrix $Q$ and initial distribution $p$ to be uniquely characterized. 

**** some notes on how to fix this: ignore it (works if only interested in conditional lower expectation, as shown below), fix the initial $P(X_0=x)=p(x)$ for all $P\in\mathcal{P}$ consistent with some $\rateset$ (then we can also ignore it: compute the conditional, and multiply the $p$ to get unconditional), or take a set $\mathcal{M}$ of probability mass functions on $\states$, and constrain $\mathcal{P}$ such that for all $P\in\mathcal{P}$, $P(X_0)\in\mathcal{M}$. (under some?? conditions), we can just focus on conditional, then compute lower expectation w.r.t. $\mathcal{M}$. hence, we can always ignore it.

We briefly mentioned earlier that our ignoring of the initial distributions is not a problem for our intended purposes. The reason for this is that we are constructing these sets $\mathcal{P}$ of processes with the intent to compute conditional lower expectations with respect to these sets. In particular, this conditioning is done on states in the process' history. Therefore, once this conditioning is taken into account, the under-parameterization with respect to the initial distributions becomes irrelevant, as shown by the example below.

\begin{exmp}
Suppose that $\mathcal{P}$ is the set of all well-behaved homogeneous Markov chains consistent with some $\rateset=\{Q\}$. As is clear from Example~\ref{example:singleton_infinite_consistent}, $\mathcal{P}$ contains an infinite number of stochastic processes. However, while these processes differ in their initial distributions, for any time points $t,s\in\realsnonneg$ such that $t\leq s$, their transition matrices $T_t^s$ are identical. In particular, these satisfy $T_t^s=e^{Q(s-t)}$, as was found in Section~\ref{sec:homogen_markov_chain}.

Suppose now that we want to compute the lower expectation $\underline{\mathbb{E}}$ of some function $f\in\gamblesX$ with respect to $\mathcal{P}$, at some time $s\in\realsnonneg$ and given the initial state $x_0\in\states$ at time $t=0$. Then, using the observation from Section~\ref{sec:dynamics} that conditional expectations can be represented using transition matrices, we have that
\begin{align*}
\underline{\mathbb{E}}[f(X_s)\,\vert\,X_{0}=x_0] &= \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_{0}=x_0]\,:\,P\in\mathcal{P}\right\} \\
 &= \inf\left\{ [T_0^sf](x_0) \,:\,P\in\mathcal{P}\right\} \\
 &= \inf\left\{ [e^{Q\cdot s}f](x_0)\,:\,P\in\mathcal{P}\right\} \\
 &= [e^{Q\cdot s}f](x_0)\,.
\end{align*}
Hence, even though $\mathcal{P}$ contains an infinite number of processes which differ only in their initial distributions, this is not problematic for the computation of lower expectations. In particular, these initial distributions do not influence the conditional expectation functionals in which we are mostly interested.
\exampleend
\end{exmp}

%**** some notes that this doesnt matter, since we're largely interested in \emph{conditional} lower expectations, with the conditioning done on the history. once this conditioning is taken into account, the under-parameterization w.r.t. the initial distribution cancels out.

%**** however, if $\rateset$ is not singleton, the collection of processes consistent with $\rateset$ becomes more interesting.

Therefore, even though different processes may be consistent with the same set $\rateset$, we need not actually find the difference between these processes interesting. In particular, this is the case whenever different processes always have the same (conditional) expectation. However, when $\rateset$ is not singleton, the collection of processes consistent with $\rateset$ actually starts to exhibit differences that lead to different conditional expectations, and that we would therefore consider interesting.

\begin{exmp}
Suppose that $\rateset=\{Q_1,Q_2\}$ for some $Q_1,Q_2\in\mathcal{R}$ with $Q_1\neq Q_2$. Then, clearly, all well-behaved homogeneous Markov chains described by either $Q_1$ or $Q_2$ are consistent with $\rateset$. Furthermore, there will also be different non-homogeneous Markov chains consistent with $\rateset$. In particular, not only can such processes differ in their initial distribution, there will be non-homogeneous Markov chains with the same initial distribution but which differ in the choice of $Q_1$ or $Q_2$ for any given time $t\in\realsnonneg$. 

Furthermore, various non-homogeneous, non-Markov processes will be consistent with $\rateset$ as well. For example, for some $t\in\realsnonneg$ and some $x_u,y_u\in\states^u$ such that $x_u\neq y_u$, such a process may satisfy $\smash{\overline{\partial}}T_{t,x_u}^t=\{Q_1\}$ and $\smash{\overline{\partial}}T_{t,y_u}^t=\{Q_2\}$.
\exampleend
\end{exmp}

In summary, we conclude that for a given non-empty bounded set $\rateset$ of rate matrices, there are many stochastic processes consistent with this $\rateset$. We will in the sequel focus on such sets of processes. However, rather than look at the set of \emph{all} processes consistent with some $\rateset$, we will for the sake of generality and ease of notation consider the consistent subset of a given set of processes $\mathcal{P}\subseteq\processes$.

%*** dit leidt dan voor een gegeven $\rateset$ naar het idee om naar de verzameling van alle $P\in\processes$ te kijken die consistent zijn met $\rateset$. Voor notationeel gemak en generiekheid kijken we echter liever naar de subset van een gegeven $\mathcal{P}\subseteq\processes$ die consistent is met $\rateset$:

\begin{definition}[Consistent Subset of Processes]\label{def:consistent_process_set}
Consider any non-empty bounded set of rate matrices $\rateset$, and any set of stochastic processes $\mathcal{P}\subseteq\processes$. Then, the \emph{subset of $\mathcal{P}$ consistent with} $\rateset$ is denoted $\mathcal{P}_\rateset$, and defined as
\begin{equation*}
\mathcal{P}_{\rateset} \coloneqq \left\{P\in\mathcal{P}\,:\,P\sim\rateset\right\}\,.
\end{equation*}
\end{definition}

\subsection{Types of Imprecise Continuous-Time Markov Chains}

*** lalala we behandelen verschillende specifieke gevallen ***

\begin{definition}\label{def:process_sets}
For any non-empty bounded set of rate matrices $\rateset$,
\begin{itemize}
\item $\whmprocesses_\rateset\subset\whmprocesses$ is the set of all well-behaved homogeneous Markov chains consistent with $\rateset$;
\item $\wmprocesses_\rateset\subset\wmprocesses$ is the set of all well-behaved Markov chains consistent with $\rateset$;
\item $\wprocesses_\rateset\subset\wprocesses$ is the set of all well-behaved stochastic processes consistent with $\rateset$.
\end{itemize}
We will denote the lower expectation with respect to $\whmprocesses_\rateset$ as $\underline{\mathbb{E}}_\rateset^{\mathrm{WHM}}$, with respect to $\wmprocesses_\rateset$ as $\underline{\mathbb{E}}_\rateset^{\mathrm{WM}}$, and with respect to $\wprocesses_\rateset$ as $\underline{\mathbb{E}}_\rateset^{\mathrm{W}}$.
\end{definition}

\begin{proposition}\label{prop:process_sets_simplify}
For any non-empty bounded set of rate matrices $\rateset$, it holds that
\begin{align*}
\whmprocesses_\rateset &= \left\{P\in\whmprocesses\,:\,P\sim\rateset\right\} \\
 &= \left\{P\in\whmprocesses\,:\,\left((\forall t\in\realsnonneg):~
\overline{\partial}
{T^t_{t}}\subseteq\rateset
\right) \right\} \\
 &= \left\{P\in\whmprocesses\,:\,Q_P\in\rateset\right\}\,.
\end{align*}
Furthermore, it holds that
\begin{align*}
\wmprocesses_\rateset &= \left\{P\in\wmprocesses\,:\,P\sim\rateset\right\} \\
 &= \left\{P\in\wmprocesses\,:\,\left((\forall t\in\realsnonneg):~
\overline{\partial}
{T^t_{t}}\subseteq\rateset
\right) \right\}\,.
\end{align*}
\end{proposition}
\begin{proof}
*** {\bf TODO}, but trivial.
\end{proof}

%\subsubsection{Imprecise Homogeneous Markov Chains}
%
%*** uitleggen dat we hier NIET op focussen, en dat dit ironisch genoeg het moeilijkste geval is; wel opgenomen voor compleetheid ***
%\begin{definition}[Set of Homogeneous Markov Processes]\label{def:homogen_markov_process_set_new}
%For any bounded set of rate matrices $\rateset$, we define the set $\whmprocesses_{\rateset}$ of all well-behaved homogeneous continuous-time Markov processes \emph{consistent} with $\rateset$. Formally, we let $\whmprocesses_{\rateset}$ be the set of all $P\in\whmprocesses$ such that
%\begin{align*}
%\whmprocesses_\rateset
%\coloneqq&
%\left\{
%P\in\whmprocesses
%\colon
%\left((\forall t\in\realsnonneg)(\forall u<t)(\forall x_u\in\states^u):~
%\overline{\partial}
%{T^t_{t,\,x_u}}\subseteq\rateset
%\right)\right\}\\
%=&
%\left\{
%P\in\whmprocesses
%\colon
%\left((\forall t\in\realsnonneg):~
%\overline{\partial}
%{T^t_{t}}\subseteq\rateset
%\right)\right\}\\
%=&
%\left\{
%P\in\whmprocesses
%\colon
%Q_P\in\rateset
%\right\}
%\end{align*}
%\end{definition}
%
%\begin{definition}[Lower Expectation for Set of Homogeneous Markov Processes]\label{def:lower_homogen_markov} Consider any bounded set of rate matrices $\rateset$, and the set of corresponding well-behaved homogeneous continuous-time Markov processes $\whmprocesses_\rateset$. Then, the \emph{lower expectation with respect to $\whmprocesses_\rateset$} is defined as
%\begin{equation*}
%\underline{\mathbb{E}}_\rateset^\mathrm{WHM}[\cdot\,\vert\,\cdot] \coloneqq \inf\left\{\mathbb{E}[\cdot\,\vert\,\cdot]\,:\,P\in\whmprocesses_\rateset\right\}\,.
%\end{equation*}
%\end{definition}
%
%
%\subsubsection{Imprecise Markov Chains}
%
%\begin{definition}[Set of Markov Processes]\label{def:markov_process_set_new}
%For any bounded set of rate matrices $\rateset$, we define the set $\wmprocesses_{\rateset}$ of all well-behaved continuous-time Markov processes \emph{consistent} with $\rateset$. Formally, we let $\wmprocesses_{\rateset}$ be the set of all $P\in\wmprocesses$ such that
%\begin{align*}\label{eq:conditionforMarkov_new}
%(\forall\epsilon\in\realspos)&\,
%(\exists\delta\in\realspos)\,
%(\forall t\in\realsnonneg)\,
%(\forall\Delta\in(0,\delta))\,
%(\exists Q\in\rateset)\,:\\
% &\,(\forall f\in\gamblesX)(\forall x\in\states)~
%\left\lvert\frac{\mathbb{E}_{X_{t+\Delta}}[f(X_{t+\Delta})\,\vert\,X_t=x]-f(x)}{\Delta}-\left[Qf\right](x)\right\rvert<\epsilon\cdot\norm{f}\,.
%\end{align*}
%\begin{align*}
%\wmprocesses_\rateset
%\coloneqq&
%\left\{
%P\in\wmprocesses
%\colon
%\left((\forall t\in\realsnonneg)(\forall u<t)(\forall x_u\in\states^u):~
%\overline{\partial}
%{T^t_{t,\,x_u}}\subseteq\rateset
%\right)\right\}\\
%=&
%\left\{
%P\in\wmprocesses
%\colon
%\left((\forall t\in\realsnonneg):~
%\overline{\partial}
%{T^t_{t}}\subseteq\rateset
%\right)\right\}
%\end{align*}
%\end{definition}
%
%\begin{definition}[Lower Expectation for Set of Markov Processes]\label{def:lower_markov} Consider any bounded set of rate matrices $\rateset$, and the set of corresponding well-behaved continuous-time Markov processes $\wmprocesses_\rateset$. Then, the \emph{lower expectation with respect to $\wmprocesses_\rateset$} is defined as
%\begin{equation*}
%\underline{\mathbb{E}}^\mathrm{M}[f(X_s)\,\vert\,X_t=x_t] \coloneqq \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_t=x_t]\,:\,P\in\mprocesses_\rateset\right\}\,.
%\end{equation*}
%\begin{equation*}
%\underline{\mathbb{E}}_\rateset^\mathrm{WM}[\cdot\,\vert\,\cdot] \coloneqq \inf\left\{\mathbb{E}[\cdot\,\vert\,\cdot]\,:\,P\in\wmprocesses_\rateset\right\}\,.
%\end{equation*}
%\end{definition}
%
%\subsubsection{Imprecise Non-Markov Chains}
%
%\begin{definition}[Set of Non-Markov Processes]\label{def:set_non_markov_process}
%For any bounded set of rate matrices $\rateset$, we consider the set $\wprocesses_\rateset$ of all stochastic processes \emph{consistent} with $\rateset$. Formally, we let $\wprocesses_\rateset$ be the set of all $P\in\wprocesses$ such that
%\begin{align*}
%&(\forall\epsilon\in\realspos)\,(\exists\delta\in\realspos)\,: \\
% &(\forall t\in\realsnonneg)\,(\forall\Delta\in(0,\delta))\,(\forall u\in\mathcal{U}_{[0,t]})\,(\forall(x_{t_0},\ldots,x_{t_{n-1}})\in\states^{\{t_0,\ldots,t_{n-1}\}})\,(\exists Q\in\rateset)\,: \\
% &(\forall f\in\gambles(\states^{u\cup\{t+\Delta\}}))\,(\forall x_{t_n}\in\states^{\{t_n\}}): \\
% &\abs{\frac{\mathbb{E}_{X_{t+\Delta}}[f(x_{t_0},\ldots,x_{t_n},X_{t+\Delta})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] - f(x_{t_0},\ldots,x_{t_n},x_{t_n})}{\Delta} - \left[Q f(x_{t_0},\ldots,x_{t_{n}},X_{t+\Delta})\right](x_{t_n})} \\ 
% &\quad\quad < \epsilon\cdot\norm{f}\,.
%\end{align*}
%\begin{equation}
%\label{def:nonmarkovsetQ}
%\wprocesses_\rateset
%\coloneqq
%\left\{
%P\in\wprocesses
%\colon
%\left((\forall t\in\realsnonneg)(\forall u<t)(\forall x_u\in\states^u):~
%\overline{\partial}
%{T^t_{t,\,x_u}}\subseteq\rateset
%\right)\right\}
%\end{equation}
%\end{definition}
%
%\begin{definition}[Lower Expectation for Set of Non-Markov Processes]\label{def:lower_non_markov} Consider any bounded set of rate matrices $\rateset$, and the set of corresponding well-behaved continuous-time non-Markov processes $\wprocesses_\rateset$. Then, the \emph{lower expectation with respect to $\wprocesses_\rateset$} is defined as
%\begin{equation*}
%\underline{\mathbb{E}}[f(X_s)\,\vert\,X_t=x_t] \coloneqq \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_t=x_t]\,:\,P\in\processes_\rateset\right\}\,.
%\end{equation*}
%\begin{equation*}
%\underline{\mathbb{E}}_\rateset^\mathrm{W}[\cdot\,\vert\,\cdot] \coloneqq \inf\left\{\mathbb{E}[\cdot\,\vert\,\cdot]\,:\,P\in\wprocesses_\rateset\right\}\,.
%\end{equation*}
%\end{definition}

%\subsection{Properties of Imprecise Continuous-Time Markov Chains}

\begin{proposition}\label{prop:markov_set_subset_of_nonmarkov_set}
Consider any bounded set of rate matrices $\rateset$, and the corresponding consistent sets $\whmprocesses_\rateset$, $\wmprocesses_\rateset$, and $\wprocesses_\rateset$.% of well-behaved homogeneous continuous-time Markov processes, well-behaved continuous-time Markov processes, and well-behaved continuous-time non-Markov processes, respectively. Then,
Then,
\begin{equation*}
\whmprocesses_\rateset \subseteq \wmprocesses_\rateset \subseteq \wprocesses_\rateset\,.
\end{equation*}
\end{proposition}
\begin{proof}
This is immediate from Definition~\ref{def:process_sets} and Proposition~\ref{prop:process_sets_simplify}.
\end{proof}

\begin{proposition}\label{prop:lower_exp_markov_bounded_by_nonmarkov}
Consider any bounded set of rate matrices $\rateset$, and the corresponding consistent sets $\whmprocesses_\rateset$, $\wmprocesses_\rateset$, and $\wprocesses_\rateset$.% of well-behaved homogeneous continuous-time Markov processes, well-behaved continuous-time Markov processes, and well-behaved continuous-time non-Markov processes, respectively. Then,
Then,
\begin{equation*}
\underline{\mathbb{E}}_\rateset^\mathrm{W}[\cdot\,\vert\,\cdot] \leq
\underline{\mathbb{E}}_\rateset^\mathrm{WM}[\cdot\,\vert\,\cdot] \leq
\underline{\mathbb{E}}_\rateset^\mathrm{WHM}[\cdot\,\vert\,\cdot]\,.
\end{equation*}
\end{proposition}
\begin{proof}
This is immediate from Definition~\ref{def:lower_exp} and Proposition \ref{prop:markov_set_subset_of_nonmarkov_set}.
\end{proof}

\subsection{Compactness of Space of Transition Matrix Systems}

**** blablabla

For any two restricted transition matrix systems $\mathcal{T}^{[t,s]}$ and $\mathcal{S}^{[t,s]}$ defined on the same interval $[t,s]$, we define a metric $d$ as
\begin{equation}\label{eq:trans_mat_system_metric}
d(\mathcal{T}^{[t,s]},\mathcal{S}^{[t,s]}) \coloneqq \sup\left\{\norm{T_q^r - S_q^r}\,:\,q,r\in[t,s], q\leq r\right\}\,,
\end{equation}
where, for all $q,r\in[t,s]$, it is understood that $T_q^r\in\mathcal{T}^{[t,s]}$ and $S_q^r\in\mathcal{S}^{[t,s]}$.

**** blablabla

We will now look at spaces of such restricted transition matrix systems. To this end, for any non-empty bounded set of rate matrices $\rateset$ and any $t,s\in\realsnonneg$ such that $t\leq s$, let
\begin{equation*}
\mathbb{T}_\rateset^{[t,s]} \coloneqq \left\{\mathcal{T}_P^{[t,s]}\,:\,P\in\wmprocesses_\rateset\right\}\,.
\end{equation*}

**** blablabla

\begin{theorem}\label{theorem:restricted_transmatsystem_space_compact_if_Q_closed}
Consider any non-empty, bounded and closed set of rate matrices $\rateset$, and any $t,s\in\realsnonneg$ such that $t\leq s$. Then, the metric space $(\mathbb{T}_\rateset^{[t,s]},d)$ is compact under the topology generated by the metric $d$, defined as in Equation~\eqref{eq:trans_mat_system_metric}.
\end{theorem}

\subsection{Stuff that needs to find a place}

*** opmerking dat $\whmprocesses_\rateset$ nogal tricky is, en dat we hier niet op focussen.

**** --- $>$ MISSCHIEN DAAROM ANDERS GEWOON WEGLATEN UIT FORMELE DEFINITIES? dan verliezen we alleen wel de ongelijkheden daarmee in bovenstaande proposities. iemand enig idee?

*** some notes about upper expectations, and that it suffices to just consider the lower ***

*** onderstaande breekt het verhaal wel een beetje. Misschien uiteindelijk in zijn geheel naar appendix?

\begin{theorem}\label{theo:aanelkaarplakken}
Consider a non-empty convex set of rate matrices $\rateset\subseteq\mathcal{R}$.
Fix a finite sequence of time points $u$. Choose any $P_\emptyset\in\wprocesses_\rateset$ and, for all $x_u\in\states^u$, choose some $P_{x_u}\in\wprocesses_\rateset$. Then there is a stochastic process $P\in\wprocesses_\rateset$ such that
\begin{equation}\label{eq:theo:aanelkaarplakken:equalsfirst}
P(X_u=x_u)=P_{\emptyset}(X_u=x_u)
\text{~for all $x_u\in\states^u$}
\vspace{-7pt}
\end{equation}
and
\begin{equation}\label{eq:theo:aanelkaarplakken:equalssecond}
P(A\vert X_u=x_u)=P_{x_u}(A\vert X_u=x_u)
\text{~for all $x_u\in\states^u$ and $A\in\mathcal{A}_u$.}
\vspace{7pt}
\end{equation}
\end{theorem}
\begin{proof}
Let $\mathcal{C}\coloneqq\mathcal{C}_\emptyset\cup(\bigcup_{x_u\in\states^u}\mathcal{C}_{x_u})$, with
\begin{multline}\label{eq:theo:aanelkaarplakken:firstpartofdomain}
\mathcal{C}_\emptyset\coloneqq
\{(A,X_v=x_v)\in\mathcal{C}^{\mathrm{SP}}\colon \max v<\max u\text{~and~}\\A\in\left\langle
\left\{
(X_t=x)
\colon
x\in\states,t\in[0,\max u]
\right\}
\right\rangle\}
\end{multline}
and
\begin{equation}\label{eq:theo:aanelkaarplakken:secondpartofdomain}
\mathcal{C}_{x_u}\coloneqq\{
(A,X_v=x_v)
\colon
u\subseteq v\in\mathcal{U},\,
x_{v\setminus u}\in\states^{v\setminus u},\,
 A\in\mathcal{A}_{u\cup(v\setminus[0,\max u])}
\}
\end{equation}
for all $x_u\in\states^u$, and consider a real-valued function $\tilde{P}$ on $\mathcal{C}$ that is defined by 
\begin{equation}\label{eq:theo:aanelkaarplakken:defPtilde}
\tilde{P}(A\vert X_v=x_v)
\coloneqq
\begin{cases}
P_\emptyset(A\vert X_v=x_v)&\text{~if $(A,X_v=x_v)\in\mathcal{C}_\emptyset$}\\
P_{x_u}(A\vert 
X_{u\cup(v\setminus[0,\max u])}=x_{u\cup(v\setminus[0,\max u])})&\text{~if $(A,X_v=x_v)\in\mathcal{C}_{x_u}$}
\end{cases}
\end{equation}
for all $(A,X_v=x_v)\in\mathcal{C}$.

We first prove that $\tilde{P}$ is a coherent conditional probability on $\mathcal{C}$. So consider any $n\in\nats$ and, for all $i\in\{1,\dots,n\}$, choose $(A_i,C_i)\in\mathcal{C}$ and $\lambda_i\in\reals$. We need to show that
\begin{equation}\label{eq:theo:aanelkaarplakken:coh}
\max\left\{\sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0\right\}\geq0,
\end{equation}
with $C_0\coloneqq\cup_{i=1}^nC_i$.

Let $S^*\coloneqq\left\{i\in\{1,\dots,n\}\colon(A_i,C_i)\in\mathcal{C}_\emptyset\right\}$. We first consider the case $S^*\neq\emptyset$. Then since $P_\emptyset$ is a stochastic process, it follows from Corollary~\ref{corol:processiffcoherent} and Equation~\eqref{eq:theo:aanelkaarplakken:defPtilde} that
\begin{equation*}%\label{eq:theo:aanelkaarplakken:cohfirstpart}
\max\left\{\sum_{i\in S^*}\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_\emptyset\right\}\geq0,
\end{equation*}
with $C^*\coloneqq\cup_{i\in S^*}C_i$. Therefore, there is some $\omega^*\in C^*$ such that
\begin{equation}\label{eq:theo:aanelkaarplakken:geqfirstpart}
\sum_{i\in S^*}\lambda_i\ind{C_i}(\omega^*)\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^*)\bigr)\geq0.
\end{equation}
If $S^*=\emptyset$, we let $\omega^*$ be any element of $C_0$ (this is always possible, because $C_0\neq\emptyset$). Clearly, this path $\omega^*$ will then also satisfy Equation~\eqref{eq:theo:aanelkaarplakken:geqfirstpart}.


Let $x_u^*\in\states^u$ be defined by $x_t^*\coloneqq \omega^*(t)$ for all $t\in u$.
Then for all $i\in\{1,\dots,n\}$ such that $(A_i,C_i)\in\mathcal{C}_{x_u^*}$, we know from Equation~\eqref{eq:theo:aanelkaarplakken:secondpartofdomain} that there are $u\subseteq v_i\in\mathcal{U}$ and $x_{v_i\setminus u}\in\states^{v_i\setminus u}$ such that
\begin{equation}\label{eq:theo:aanelkaarplakken:Cisplit}
C_i=(X_u=x_u^*)\cap(X_{v_i\setminus u}=x_{v_i\setminus u})=C_i^*\cap C_i^{**},
\end{equation}
with 
\begin{equation}\label{eq:theo:aanelkaarplakken:Cistarstar}
C_i^{**}\coloneqq(X_u=x_u^*)\cap(X_{v_i\setminus [0,\max u]}=x_{v_i\setminus [0,\max u]})\vspace{2mm}
\end{equation}
and $C_i^{*}\coloneqq(X_{v_i\cap [0,\max u]}=x_{v_i\cap [0,\max u]})$. Using this notation, we define
\begin{equation}\label{eq:theo:aanelkaarplakken:Sstarstardef}
S^{**}\coloneqq
\{
i\in\{1,\dots,n\}
\colon
(A_i,C_i)\in\mathcal{C}_{x_u^*}
\text{~and~}
\ind{C_i^*}(\omega^*)=1
\}.
\end{equation}


We first consider the case $S^{**}\neq\emptyset$. Since $P_{x_u^*}$ is a stochastic process, it then follows from Corollary~\ref{corol:processiffcoherent} that
\begin{equation*}%\label{eq:theo:aanelkaarplakken:secondpart}
\max\left\{\sum_{i\in S^{**}}\lambda_i\ind{C_i^{**}}(\omega)\bigl(P_{x_u^*}(A_i\vert C_i^{**})-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C^{**}\right\}\geq0,
\end{equation*}
with $C^{**}\coloneqq\cup_{i\in S^{**}}C_i^{**}$. Because of Equation~\eqref{eq:theo:aanelkaarplakken:defPtilde}, this implies that
\begin{equation*}%\label{eq:theo:aanelkaarplakken:secondpart}
\max\left\{\sum_{i\in S^{**}}\lambda_i\ind{C_i^{**}}(\omega)\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C^{**}\right\}\geq0,
\end{equation*}
which allows us to infer that there is some $\omega^{**}\in C^{**}$ such that
\begin{equation}\label{eq:theo:aanelkaarplakken:geqsecondpart}
\sum_{i\in S^{**}}\lambda_i\ind{C_i^{**}}(\omega^{**})\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^{**})\bigr)\geq0.
\end{equation}
Furthermore, since $\omega^{**}\in C^{**}$, Equation~\eqref{eq:theo:aanelkaarplakken:Cistarstar} implies that
\begin{equation}\label{eq:theo:aanelkaarplakken:starstarniceonu}
\omega^{**}(t)=x_t^*
\text{~~for all $t\in u$.}
\end{equation}
If $S^{**}=\emptyset$, we let $\omega^{**}=\omega^{*}$. Clearly, also in this case, $\omega^{**}$ satisfies Equations~\eqref{eq:theo:aanelkaarplakken:geqsecondpart} and~\eqref{eq:theo:aanelkaarplakken:starstarniceonu}.

Now let $\omega^{***}$ be defined by
\begin{equation*}%\label{eq:theo:aanelkaarplakken:omegatriplestar}
\omega^{***}(t)\coloneqq
\begin{cases}
\omega^{*}(t) & \text{if $t<\max u$}\\
\omega^{**}(t) & \text{if $t\geq \max u$}
\end{cases}
\text{~~~for all $t\in\reals_{\geq0}$.}
\end{equation*}
Then since $\omega^*$ and $\omega^{**}$ both belong to $\Omega$---are cadlag functions from $\reals_{\geq0}$ to $\states$---it follows that $\omega^{***}\in\Omega$. Furthermore, because of Equation~\eqref{eq:theo:aanelkaarplakken:starstarniceonu}, we know that
\begin{equation}\label{eq:theo:aanelkaarplakken:triplestarpartone}
\omega^{***}(t)=\omega^*(t)
\text{~~for all $t\in [0,\max u]$}\vspace{-3mm}
\end{equation}
and
\begin{equation}\label{eq:theo:aanelkaarplakken:triplestarparttwo}
\omega^{***}(t)=\omega^{**}(t)
\text{~~for all $t\in u\cup [\max u,+\infty)$}
\vspace{2mm}
\end{equation}
and therefore, it follows from Equation~\eqref{eq:theo:aanelkaarplakken:Cisplit} that
\begin{equation}\label{eq:theo:aanelkaarplakken:triplestarequivalence}
\omega^{***}\in C_i
\Leftrightarrow
(\omega^{***}\in C_i^*
\text{~and~}
\omega^{***}\in C_i^{**})
\Leftrightarrow
(\omega^{*}\in C_i^*
\text{~and~}
\omega^{**}\in C_i^{**})
\end{equation}
for all $i\in\{1,\dots,n\}$ such that $(A_i,C_i)\in\mathcal{C}_{x_u^*}$.

%*** still need to finish the stuff below ***

Next, for any $i\in S^*$, we infer from Equation~\eqref{eq:theo:aanelkaarplakken:firstpartofdomain} that the value of $\ind{A_i}(\omega^{***})$ and $\ind{C_i}(\omega^{***})$ is completely determined by $\omega^{***}(t)$, $t\in[0,\max u]$. Therefore, it follows from Equations~\eqref{eq:theo:aanelkaarplakken:geqfirstpart} and ~\eqref{eq:theo:aanelkaarplakken:triplestarpartone} that 
\begin{equation}\label{eq:theo:aanelkaarplakken:geqfirstparttriplestar}
\sum_{i\in S^*}\lambda_i\ind{C_i}(\omega^{***})\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^{***})\bigr)
%=
%\sum_{i\in S^*}\lambda_i\ind{C_i}(\omega^{*})\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^{*})\bigr)
\geq0.
\end{equation}

Similarly, for any $i\in S^{**}$, 
Equations~\eqref{eq:theo:aanelkaarplakken:triplestarequivalence} and~\eqref{eq:theo:aanelkaarplakken:Sstarstardef} imply that $\ind{C_i}(\omega^{***})=\ind{C_i^{**}}(\omega^{**})$,
and Equations~\eqref{eq:theo:aanelkaarplakken:secondpartofdomain} and~\eqref{eq:theo:aanelkaarplakken:triplestarparttwo} imply that $\ind{A_i}(\omega^{***})=\ind{A_i}(\omega^{**})$. Therefore, it follows from Equation~\eqref{eq:theo:aanelkaarplakken:geqsecondpart} that
\begin{equation}\label{eq:theo:aanelkaarplakken:geqsecondparttriplestar}
\sum_{i\in S^{**}}\lambda_i\ind{C_i}(\omega^{***})\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^{***})\bigr)
\geq0.
\end{equation}

Consider now any $i\in\{1,\dots,n\}$ such that $i\notin S^*$ and $i\notin S^{**}$. Since $i\notin S^*$, there is some $x_u\in\states^u$ such that $(A_i,C_i)\in\mathcal{C}_{x_u}$. If $x_u= x_u^*$, then since $i\notin S^{**}$, it follows from Equation~\eqref{eq:theo:aanelkaarplakken:Sstarstardef} that $\ind{C_i^*}(\omega^*)=0$, and therefore, Equation~\eqref{eq:theo:aanelkaarplakken:triplestarequivalence} implies that $\ind{C_i}(\omega^{***})=0$. 
If $x_u\neq x_u^*$, then $(X_u=x_u)\cap(X_u=x_u^*)=\emptyset$, and therefore, since $(A_i,C_i)\in\mathcal{C}_{x_u}$ implies that $C_i\subseteq (X_u=x_u)$, it follows that $C_i\cap (X_u=x_u^*)=\emptyset$. Since it follows from Equations~\eqref{eq:theo:aanelkaarplakken:starstarniceonu} and~\eqref{eq:theo:aanelkaarplakken:triplestarparttwo} that $\omega^{***}(t)=x_t^*$ for all $t\in u$, this implies that $\omega^{***}\notin C_i$, and therefore, we find that $\ind{C_i}(\omega^{***})=0$.
Hence, in all cases, we find that $\ind{C_i}(\omega^{***})=0$. Since this is true for any $i\in\{1,\dots,n\}$ such that $i\notin S^*$ and $i\notin S^{**}$, it follows from Equations~\eqref{eq:theo:aanelkaarplakken:geqfirstparttriplestar} and~\eqref{eq:theo:aanelkaarplakken:geqsecondparttriplestar} that
\begin{equation}\label{eq:theo:aanelkaarplakken:geqtotal}
\sum_{i=1}^n\lambda_i\ind{C_i}(\omega^{***})\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega^{***})\geq0.
\end{equation}

We will now prove that $\omega^{***}\in C_0$. We consider two cases: $S^*\neq\emptyset$ and $S^*=\emptyset$. First assume that $S^*\neq\emptyset$. In that case, we have that $\omega^*\in C^*$, which implies that there is some $i\in S^*$ such that $\omega^*\in C_i$. It then follows from Equations~\eqref{eq:theo:aanelkaarplakken:firstpartofdomain} and~\eqref{eq:theo:aanelkaarplakken:triplestarpartone} that $\omega^{***}\in C_i\subseteq C_0$. 
Next, assume that $S^*=\emptyset$. In that case, we have that $\omega^*\in C_0$, which implies that there is some $i\in\{1,\dots,n\}$ such that $\omega^*\in C_i$. Since $(A_i,C_i)\in\mathcal{C}$ and $S^*=\emptyset$, there is some $x_u\in\states^u$ such that $(A_i,C_i)\in\mathcal{C}_{x_u}$ and, since Equation~\eqref{eq:theo:aanelkaarplakken:secondpartofdomain} implies that $x_t=\omega^*(t)$ for all $t\in u$, it follows that $x_u=x_u^*$. We conclude from this that $(A_i,C_i)\in\mathcal{C}_{x_u^*}$. Furthermore, since $\omega^*\in C_i\subseteq C_i^*$, we know that $\ind{C_i^*}(\omega^*)=1$. Therefore, it follows from Equation~\eqref{eq:theo:aanelkaarplakken:Sstarstardef} that $S^{**}\neq\emptyset$, which implies that $\omega^{**}\in C^{**}$. Hence, there is some $j\in S^{**}$ such that $\omega^{**}\in C_j^{**}$ and, since $j\in S^{**}$, we also know that $\ind{C_j^*}(\omega^*)=1$, or equivalently, that $\omega^*\in C_j^*$. By combining this with Equation~\eqref{eq:theo:aanelkaarplakken:triplestarequivalence}, it follows that $\omega^{***}\in C_j\subseteq C_0$.
So, in all cases, we find that $\omega^{***}\in C_0$. By combining this with Equation~\eqref{eq:theo:aanelkaarplakken:geqtotal}, it follows that Equation~\eqref{eq:theo:aanelkaarplakken:coh} holds, and therefore, that $\tilde{P}$ is coherent.


Since $\tilde{P}$ is coherent, and because of Theorem~\ref{theo:coherentextendable}, $\tilde{P}$ can be extended to a full conditional probability $\tilde{P}^*$. If we now let $P$ be the restriction of $\tilde{P}^*$ to $\mathcal{C}^\mathrm{SP}$, then $P$ is a stochastic process that extends $\tilde{P}$, which implies that $P$ satisfies Equations~\eqref{eq:theo:aanelkaarplakken:equalsfirst} and~\eqref{eq:theo:aanelkaarplakken:equalssecond}. In the remainder of this proof, we will show that $P\in\wprocesses_\rateset$.

*** still need to finish the stuff below ***

Consider any $v\in\mathcal{U}$ and $t\in\reals_{\geq0}$ such that $v<t$ and $u<t$. Then for all $x_v\in\states^v$ and $y\in\states$, we have that
\begin{align*}
P(X_t&=y\vert X_v=x_v)
%&=P(X_t=y\vert X_{v\setminus u}=x_{v\setminus u}, X_{v\cap u}=x_{v\cap u})\\
=
\sum_{x_{u\setminus v}\in\states^{u\setminus v}}
P(X_t=y,
X_{u\setminus v}=x_{u\setminus v}
\vert X_v=x_v)\\
%\vert X_{v\setminus u}=x_{v\setminus u}, X_{v\cap u}=x_{v\cap u})
&=
\sum_{x_{u\setminus v}\in\states^{u\setminus v}}
P(X_t=y\vert
X_{u\setminus v}=x_{u\setminus v}, X_v=x_v)
P(X_{u\setminus v}=x_{u\setminus v}
\vert X_v=x_v)\\
&=
\sum_{x_{u\setminus v}\in\states^{u\setminus v}}
P(X_t=y\vert
X_{u}=x_{u}, X_{v\setminus u}=x_{v\setminus u})
P(X_{u\setminus v}=x_{u\setminus v}
\vert X_v=x_v)\\
&=
\sum_{x_{u\setminus v}\in\states^{u\setminus v}}
\tilde{P}(X_t=y\vert
X_{u}=x_{u}, X_{v\setminus u}=x_{v\setminus u})
P(X_{u\setminus v}=x_{u\setminus v}
\vert X_v=x_v)\\
&=
\sum_{x_{u\setminus v}\in\states^{u\setminus v}}
P_{x_u}(X_t=y\vert
X_{u}=x_{u}, X_{v\setminus [0,\max u]}=x_{v\setminus [0,\max u]})
P(X_{u\setminus v}=x_{u\setminus v}
\vert X_v=x_v)
\end{align*}
*** Because of this equality, well-behavedness and compatibility with $\rateset$ will follow from the fact that $P_{x_u}$ has these properties. ***
\end{proof}

\section{An Important Lower Transition Operator}
\label{sec:lowertrans}

Having introduced the notion of lower expectations with respect to sets of (non-)Markov processes, one might wonder how to compute these quantities, either numerically or for analytical purposes. 

Obviously, one way to go about doing this is to work directly with the definitions. That is, explicitly generate the entire set $\wmprocesses_\rateset$ (or $\wprocesses_\rateset$) for a given $\rateset$, compute expectations of a function $f$ for each element of this set, and then find the infimum of these expectations. It should be clear that this approach is fairly unwieldy, not in the least because for arbitrary $\rateset$ the corresponding set of processes may be infinite. Therefore, we will instead provide an alternative characterization of these lower expectations. 

In particular, we will in this section introduce a specific \emph{lower transition operator}, which is a map from $\gamblesX$ to $\gamblesX$ that generalizes the notion of a transition matrix. We will here focus on introducing the relevant concepts, and showing that this operator of interest is well-defined. We end this section by establishing that this (family) of operators is in many ways intuitively comparable to the transition matrix system of a well-behaved homogeneous Markov chain. In Section~\ref{sec:connections} we will then establish the relation between this operator and lower expectations, and show that we can indeed use it to compute the quantities of interest. In Section~\ref{sec:prev_work} we will show how this operator is related to previous work from the literature.

\subsection{Lower Transition (Rate) Operators}

It is clear from Section~\ref{sec:trans_rate_matrices} that there is a strong connection between transition rate matrices and transition matrices. We here generalize these two concepts to \emph{lower transition rate operators} and \emph{lower transition operators}, respectively.

\begin{definition}[Lower Transition Rate Operator]\label{def:coh_low_trans_rate}
We will call a map $\lrate$ from $\gamblesX$ to $\gamblesX$ a \emph{lower transition rate operator} if, for all $f,g\in\gamblesX$, all $\lambda\in\realsnonneg$, all constant functions $\mu\in\gamblesX$, and all $x\in\states$:

%\vspace{5pt}
\begin{enumerate}[label=LR\arabic*:,ref=LR\arabic*]
\item\label{LR:constantzero}
$\lrate(\mu)(x)=0$;
\item\label{LR:subadditive}
$\lrate(f+g)(x)\geq\lrate(f)(x)+\lrate(g)(x)$;
\item\label{LR:homo}
$\lrate(\lambda f)(x)=\lambda\lrate(f)(x)$;
\item\label{LR:nondiagpos}
$\lrate(\ind{y})(x)\geq0$ for all $y\in\states$ such that $x\neq y$.
\end{enumerate}
\vspace{5pt}
\end{definition}


\begin{definition}[Lower Transition Operator]\label{def:coh_low_trans}
We will call a map $\lt$ from $\gamblesX$ to $\gamblesX$ a \emph{lower transition operator} if, for all $f,g\in\gamblesX$, all $\lambda\in\realsnonneg$, and all $x\in\states$:

%\vspace{5pt}
\begin{enumerate}[label=C\arabic*:]
\item
$\lt(f)(x)\geq\min\left\{f(y)\,\vert\,y\in\states\right\}$
\item
$\lt(f+g)(x)\geq\lt(f)(x)+\lt(g)(x)$;
\item
$\lt(\lambda f)(x)=\lambda\lt(f)(x)$.
\end{enumerate}
%\vspace{5pt}
\noindent We use $\underline{\mathcal{T}}$ to denote the set of all lower transition operators.
\vspace{5pt}
\end{definition}

\noindent We start by giving some useful properties of the norm of these operators.

\begin{proposition}\label{lem:normlratefinite}
For any lower transition rate operator $\lrate$, we have that $0\leq\norm{\lrate}<+\infty$.
\end{proposition}

\begin{proposition}\label{lemma:normofcoherenttrans}
For any lower transition operator $\lt$, we have that $0\leq \norm{\lt}\leq 1$.
\end{proposition}

We next establish that there is a correspondence between lower transition rate operators and lower transition operators that is analogous to the one found in Section~\ref{sec:trans_rate_matrices}.

\begin{proposition}\label{lemma:normQsmallenough}
Consider any lower transition rate operator $\lrate$, and any $\Delta\in\realsnonneg$ such that $\Delta\leq\nicefrac{1}{\norm{\lrate}}$. Then, the operator $(I+\Delta\lrate)$ is a lower transition operator.
\end{proposition}

\begin{proposition}\label{lemma:lower_trans_to_lower_rate}
Consider any lower transition operator $\lt$, and any $\Delta\in\realspos$. Then, the operator $\nicefrac{1}{\Delta}(\lt - I)$ is a lower transition rate operator.
\end{proposition}

We now have two results about the set $\underline{\mathcal{T}}$ of all lower transition operators. As the first result shows, this set is closed under composition.
\begin{proposition}\label{lemma:compositioncoherence}
For any $\lt,\underline{S}\in\underline{\mathcal{T}}$, we have that $\left(\lt\underline{S}\right)\in\underline{\mathcal{T}}$.
\end{proposition}
\begin{proof}
Simply check each of the properties.
\end{proof}

\noindent Furthermore, this set is a complete metric space under our usual norm.

\begin{proposition}\label{lemma:completemetricspace}
The metric space $(\underline{\mathcal{T}},d)$ is complete under the metric $d$ induced by our usual norm $\norm{\cdot}$.
\end{proposition}

\noindent We conclude this section with the following result.
\begin{proposition}\label{lemma:productiscoherent}
Consider any $t,s\in\realsnonneg$ such that $t<s$, any lower transition rate operator $\lrate$, and any sequence $u\in\mathcal{U}_{[t,s]}$ of time points such that $\sigma(u)\leq\nicefrac{1}{\norm{\lrate}}$. Then
\begin{equation*}
\prod_{k=1}^n(I+\Delta_k\lrate)\coloneqq (I+\Delta_1\lrate)(I+\Delta_2\lrate)\cdots (I+\Delta_n\lrate)
\end{equation*}
is a lower transition operator.
\end{proposition}
\begin{proof}
Trivial consequence of Propositions~\ref{lemma:normQsmallenough} and~\ref{lemma:compositioncoherence}.
\end{proof}

\subsection{The Operator of Interest}

We will in this section introduce a specific lower transition operator on which we will focus for the remainder of this work. We will assume here that we are given some arbitrary lower transition rate operator $\lrate$, and define for any $u\in\mathcal{U}_{[t,s]}$ the auxiliary operator
\begin{equation}\label{eq:aux_lower_trans}
\Phi_u\coloneqq\prod_{k=1}^n(I+\Delta_k\lrate)\,.
\end{equation}
Before defining the operator of interest, we first give some preliminary results to provide intuition on how this operator will be constructed. We start with a bound on the distance between two operators $\Phi_u$ and $\Phi_{u*}$.

\begin{proposition}\label{prop:differencebetweenu}
Consider any $t,s\in\realsnonneg$ such that $t<s$, and any $u,u^*\in\mathcal{U}_{[t,s]}$ such that $\sigma(u)<\alpha$ and $\sigma(u^*)<\alpha$, with $0<\alpha\leq\nicefrac{1}{\norm{\lrate}}$. Let $\Delta\coloneqq s-t$. Then,
\begin{equation*}
\norm{\Phi_u-\Phi_{u^*}}\leq 2\alpha\Delta\norm{\lrate}^2
\end{equation*}
\end{proposition}

Using this bound established by Proposition~\ref{prop:differencebetweenu}, we find that for any sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{i\to\infty}\sigma(u_i)=0$, the corresponding sequence $\{\Phi_{u_i}\}_{i\in\nats}$ is convergent.

\begin{corollary}\label{corol:cauchy}
For every sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{i\to\infty}\sigma(u_i)=0$, the corresponding sequence $\{\Phi_{u_i}\}_{i\in\nats}$ is a \emph{Cauchy sequence}, meaning that
\begin{equation*}
(\forall \epsilon>0)(\exists n\in\nats)(\forall i,j\geq n)
\norm{\Phi_{u_i}-\Phi_{u_j}}<\epsilon.
\end{equation*}
\end{corollary}
\begin{proof}
This follows almost directly from Proposition~\ref{prop:differencebetweenu}.
\end{proof}

\noindent Due to Proposition~\ref{lemma:completemetricspace}, we therefore have the following result.

\begin{corollary}\label{corol:limitexistsandiscoherent}
For every sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{i\to\infty}\sigma(u_i)=0$, the corresponding sequence $\{\Phi_{u_i}\}_{i\in\nats}$ converges to a lower transition operator.
\end{corollary}

Our next result establishes that this limit is also unique, i.e., that it is independent of the choice of $\{u_i\}_{i\in\nats}$.

\begin{theorem}\label{theo:convergencelowerbound}
For any $t,s\in\realsnonneg$ such that $t<s$ and any lower transition rate operator $\lrate$, there is a lower transition operator $\lt\in\underline{\mathcal{T}}$ such that 
\begin{equation*}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall u\in\mathcal{U}_{[t,s]}\colon\sigma(u)<\delta)~\norm{\lt - \Phi_u}<\epsilon.
\end{equation*}
\end{theorem}

Note that the $\epsilon-\delta$ expression in Theorem~\ref{theo:convergencelowerbound} is a kind of limit statement. Specifically, it is a limit of operators $\Phi_{u}$ corresponding to increasingly finer partitions $u$ of the interval $[t,s]$. In the sequel, whenever such a limit exists and equals some lower transition operator $\lt$, we will denote it as
\begin{equation}\label{eq:net_limit_lower_trans}
\lim_{\sigma(u)\to0}\left\{\Phi_u\,\big\vert\,u\in\mathcal{U}_{[t,s]}\right\} = \lt\,.
\end{equation}
Here, the notation is understood to indicate that the limit of these operators $\Phi_{u}$ is independent of the exact choice of $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$, so long as $\lim_{i\to\infty}\sigma(u_i)=0$.

We are now ready to define the \emph{lower transition operator corresponding to $\lrate$}, which is the operator in which we will be interested for the remainder of this work.

\begin{definition}[Corresponding Lower Transition Operator]\label{def:low_trans}
Consider any $t,s\in\realsnonneg$ such that $t<s$ and let $\lrate$ be an arbitrary lower transition rate operator. The \emph{corresponding lower transition operator} $\lbound_t^s$ is a map from $\gamblesX$ to $\gamblesX$, defined by
\begin{equation}\label{eq:lowerbound}
\lbound_t^s\coloneqq\lim_{\sigma(u)\to0}\left\{ \Phi_u\,\big\vert\,u\in\mathcal{U}_{[t,s]}\right\},
\end{equation}
where the limit is understood as in Equation~\eqref{eq:net_limit_lower_trans}.
\end{definition}

\subsection{Properties of the Operator of Interest}

*** tralala, beschouw nu de familie van die dingen op elk tijdstip en over elk interval

\begin{definition}[Lower Transition Operator System]
Let $\lrate$ be an arbitrary lower transition rate operator. Then, the \emph{lower transition operator system} corresponding to $\lrate$ is the family $\underline{\mathcal{T}}_{\lrate}$ of lower transition operators corresponding to $\lrate$, defined as
\begin{equation*}
\underline{\mathcal{T}}_{\lrate} \coloneqq \Bigl\{L_t^s\,\Big\vert\,\forall t,s\in\realsnonneg, t\leq s\Bigr\}\,,
\end{equation*}
where for all $t,s\in\realsnonneg$ with $t\leq s$, $L_t^s$ is defined as in Definition~\ref{def:low_trans}.
\end{definition}

*** tralala, kijk, het lijkt qua eigenschappen op een homogene markov keten

\begin{proposition}\label{prop:lower_trans_system_is_system}
Let $\lrate$ be an arbitrary lower transition rate operator, and let $\underline{\mathcal{T}}_{\lrate}$ be the corresponding lower transition operator system. Then, for all $t,r,s\in\realsnonneg$ such that $t\leq r\leq s$,
\begin{equation*}
L_t^s = L_t^rL_r^s\,.
\end{equation*}
Furthermore, for all $t\in\realsnonneg$, we have that $L_t^t=I$.
\end{proposition}

\begin{proposition}\label{prop:lower_transition_is_homogeneous}
Let $\lrate$ be an arbitrary lower transition rate operator, and let $\underline{\mathcal{T}}_{\lrate}$ be the corresponding lower transition operator system. Then, for all $t,s\in\realsnonneg$ such that $t\leq s$, and all $\Delta\in\realsnonneg$, we have that
\begin{equation*}
L_t^s = L_{t+\Delta}^{s+\Delta}\,.
\end{equation*}
\end{proposition}

*** kijk, differentiaalvergelijking die lijkt op die van matrix exponential:

\begin{proposition}\label{prop:lower_transition_has_deriv}
Let $\lrate$ be an arbitrary lower transition rate operator, and let $\underline{\mathcal{T}}_{\lrate}$ be the corresponding lower transition operator system. Then, for all $t,s\in\realsnonneg$ such that $t<s$, it holds that
\begin{equation*}
\frac{d}{dt}\lbound_t^s=-\lrate\lbound_t^s\,,\quad\text{and,}\quad\frac{d}{ds}\lbound_t^s=\lbound_t^s\lrate\,.
\end{equation*}
% Then $\frac{d}{dt}\lbound_t^s=-\lrate\lbound_t^s$ and $\frac{d}{ds}\lbound_t^s=\lbound_t^s\lrate$, meaning that
\end{proposition}

**** blabla kijk het lijkt inderdaad op matrix exponential

There are various ways in which this matrix exponential can be expressed. For example, it is well known~{\bf REF} that it is the solution to the differential equation
\begin{equation*}
\frac{\partial }{\partial s}e^{Q(s-t)}\coloneqq Qe^{Q(s-t)}\,,\quad e^{Q\cdot (t-t)} \coloneqq I\,.
\end{equation*}
From this we find that its Taylor-series~{\bf REF?} expansion yields the representation:
\begin{equation*}
e^{Q(s-t)} \coloneqq \sum_{i=0}^{\infty}\frac{1}{i!}Q^i(s-t)^i\,,
\end{equation*}
where $Q^i$ denotes the $i$-th matrix power of $Q$.
%Yet another representation is the Peano-Baker series~{\bf REF}, the solution of which is also known as a Picard matrix~{\bf REF} in this context, obtained by recursive integration of the differential equation:
%\begin{align*}
%e^{Q(s-t)} &\coloneqq I + \int_t^s Qe^{Q(\tau_1-t)}\mathrm{d}\tau_1 \\
% &= I + \int_t^s Q\mathrm{d}\tau_1 + \int_t^s Q\int_t^sQ\mathrm{d}\tau_2\mathrm{d}\tau_1 + \cdots + \int_t^s Q\int_t^s\cdots \int_t^s Q\mathrm{d}\tau_n\cdots\mathrm{d}\tau_2\mathrm{d}\tau_1 + \cdots
%\end{align*}
A related representation that we will find useful is given~{\bf ref/proof?} by the following $\epsilon-\delta$ limit expression:
\begin{equation}\label{eq:matrix_exp_limit}
(\forall\epsilon\in\realspos)(\exists\delta\in\realspos)(\forall u\in\mathcal{U}_{[t,s]}\,:\,\sigma(u)<\delta)\,\norm{e^{Q(s-t)} - \prod_{i=1}^n(I+\Delta_iQ)} < \epsilon\,.
\end{equation}

**** beetje conclusie

\section{Connections Between $L_t^s$ and Imprecise Continuous-Time Markov Chains}\label{sec:connections}

One of the objectives of this paper is to establish a connection between the operator $\lbound_t^s$ that we have just introduced, and the different types of imprecise continous-time Markov chains that were discussed in Section~\ref{sec:iCTMC}. Since the former is derived from a lower transition rate operator $\lrate$ and the latter are derived from a non-empty bounded set of rate matrices $\rateset$, an obvious first step is to investigate the connection between lower transition rate operators and non-empty bounded sets of rate matrices.

\subsection{Connections Between $\lrate$ and Sets of Rate Matrices $\rateset$}\label{sec:connections_rate}

% $\rateset$ and $\lrate$. 
%In order to do that, we start by discussing some properties of sets of rate matrices.

We start by considering a non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices. For any $f\in\gamblesX$,
\begin{equation}\label{eq:correspondinglowertrans}
\lrate f\coloneqq\inf\{Qf\colon Q\in\rateset\}\\[2mm]
\end{equation}
is then again an element of $\gamblesX$.\footnote{%Since $\rateset$ is non-empty, the components of $\lrate f$ cannot be $+\infty$.
Since $\rateset$ is bounded,~\ref{N:normAf} implies that $\norm{Qf}\leq\norm{Q}\norm{f}<+\infty$ for all $Q\in\rateset$. Therefore, and since $\rateset$ is non-empty, the components of $\lrate f$ cannot be infinite. Hence, $\lrate f$ is a real-valued function on $\states$.}
Therefore, $\lrate$ is a map from $\gamblesX$ to $\gamblesX$. We call this operator $\lrate$, as defined by Equation~\eqref{eq:correspondinglowertrans}, the \emph{lower envelope} of $\rateset$. It is a matter of straightforward verification to see that $\lrate$ is a lower transition rate operator.

\begin{proposition}\label{prop:lowerenvelopeislowertrans}
For any non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices, the corresponding operator $\lrate\colon\gamblesX\to\gamblesX$, as defined by Equation~\eqref{eq:correspondinglowertrans}, is a lower transition rate operator.
\end{proposition}

\noindent
Inspired by this result, we will also refer to the lower envelope of $\rateset$ as the \emph{lower transition rate operator that corresponds to $\rateset$}. %As we have just seen, every non-empty bounded set $\rateset\subseteq\mathcal{R}$ of rate matrices has such a corresponding lower transition rate operator $\lrate$. 
However, this correspondence is not one-to-one. As the following example establishes, different non-empty bounded sets of rate matrices may have the same corresponding lower transition rate operator.

\begin{exmp}\label{example:different_sets_same_lower_rate}
For the sake of simplicity, we will assume that the state space $\states$ has only two elements, so that we can work with $2\times 2$ matrices. Consider two rate matrices $A,B\in\mathcal{R}$ defined as
\begin{equation*}
A\coloneqq\left[\begin{array}{rr}-1 & 1 \\2 & -2\end{array}\right]\,,\quad\text{and}\quad
B\coloneqq\left[\begin{array}{rr}-3 & 3 \\1 & -1\end{array}\right]\,.
\end{equation*}
Define a third rate matrix $C\coloneqq \nicefrac{1}{2}(A+B)$. We will now construct two different non-empty bounded sets of rate matrices; let $\rateset^1\coloneqq\{A,B\}$, and let $\rateset^2\coloneqq\{A,B,C\}$. Then, clearly, $\rateset^1\neq\rateset^2$. 
Let now, respectively, $\lrate_1$ and $\lrate_2$ be the lower transition rate operators corresponding to $\rateset^1$ and $\rateset^2$, as defined by Equation~\eqref{eq:correspondinglowertrans}. We will show that $\lrate_1=\lrate_2$.

Consider any $f\in\gamblesX$. It is easily verified that if $f(1)\leq f(2)$, it holds that $[Af](1)\leq[Bf](1)$ and $[Af](2)\leq[Bf](2)$. Hence, if $f(1)\leq f(2)$, we have $Af\leq Bf$. Contrariwise, if $f(2)\leq f(1)$, we have $[Bf](1)\leq [Af](1)$ and $[Bf](2)\leq[Af](2)$, and hence also $Bf\leq Af$. Note also that by the construction of $C$, it holds that if $Af\leq Bf$, we have $Af\leq Cf$, and if $Bf\leq Af$, we have $Bf\leq Cf$.

Now, because clearly either $f(1)\leq f(2)$ or $f(2)\leq f(1)$, it follows from Equation~\eqref{eq:correspondinglowertrans} and the inequalities above that either $\lrate_1f=Af$, if $Af\leq Bf$, or $\lrate_1f=Bf$, if $Bf\leq Af$. Furthermore, as noted, if $Af\leq Bf$ then also $Af\leq Cf$, and if $Bf\leq Af$ then $Bf\leq Cf$. Therefore, we find that also either $\lrate_2f=Af$, or $\lrate_2f=Bf$. Hence, $\lrate_1f=\lrate_2f$, and because the $f\in\gamblesX$ was arbitrary, we have that $\lrate_1=\lrate_2$.
\exampleend
\end{exmp}

Next, we consider some fixed lower transition rate operator $\lrate$.
All the non-empty bounded sets $\rateset$ of rate matrices that have $\lrate$ as their lower envelope then share a common property: they consist of rate matrices $Q$ that dominate $\lrate$, in the sense that $Qf\geq\lrate f$ for all $f\in\gamblesX$. Therefore, each of these sets $\rateset$ is contained in the following set of dominating rate matrices:
\begin{equation}\label{eq:dominatingratematrices}
\rateset_{\lrate}\coloneqq
\left\{
Q\in\mathcal{R}
\colon
Qf\geq\lrate f\text{ for all $f\in\gamblesX$}
\right\}.
\end{equation}
As our next result shows, this set $\rateset_{\lrate}$ is non-empty and bounded, and has $\lrate$ as its lower envelope. Even stronger, the infimum in Equation~\eqref{eq:correspondinglowertrans} is reached---can be replaced by a minimum.

\begin{proposition}\label{prop:dominating_nonempty_bounded}
Consider a lower transition rate operator $\lrate$ and let $\rateset_{\lrate}$ be the corresponding set of dominating rate matrices, as defined by Equation~\eqref{eq:dominatingratematrices}. Then $\rateset_{\lrate}$ is non-empty and bounded and, for all $f\in\gamblesX$, there is some $Q\in\rateset_{\lrate}$ such that $\lrate f=Qf$.
\end{proposition}

\noindent
Because of this result, and since---as discussed above---every non-empty bounded set of rate matrices that has $\lrate$ as its lower envelope is a subset of $\rateset_{\lrate}$, it follows that $\rateset_{\lrate}$ is the largest non-empty bounded set of rate matrices that has $\lrate$ as its lower envelope.
Furthermore, as we will show in Proposition~\ref{prop:dominatingproperties} below, this set $\rateset_{\lrate}$ is also closed and convex, and has \emph{separately specified rows}. We say that a set of rate matrices has separately specified rows if it is closed under taking arbitrary combinations of rows from its elements.

\begin{definition}
A set of rate matrices $\rateset\subseteq\mathcal{R}$ has separately specified rows if
\begin{equation*}
\rateset=\left\{
Q\in\mathcal{R}
\colon
(\forall x\in\states)~Q(x,\cdot)\in\rateset_x\right\},
\end{equation*}
where, for every $x\in\states$, $\rateset_x\coloneqq\{Q(x,\cdot)\colon Q\in\rateset\}$ is some set of rows from which the $x$-th row of the rate matrices in $\rateset$ are taken.
\end{definition}

\begin{proposition}\label{prop:dominatingproperties}
Consider a lower transition rate operator $\lrate$ and let $\rateset_{\lrate}$ be the corresponding set of dominating rate matrices, as defined by Equation~\eqref{eq:dominatingratematrices}. Then $\rateset_{\lrate}$ is closed and convex, and has separately specified rows.
\end{proposition}

\noindent
These additional properties characterize $\rateset_{\lrate}$ completely, in the sense that no other set satisfies them.

\begin{proposition}\label{prop:dominating_unique_characterization}
Consider any non-empty, bounded, closed and convex set of rate matrices $\rateset\subseteq\mathcal{R}$ with separately specified rows that has $\lrate$ as its lower envelope. Then $\rateset=\rateset_{\lrate}$.
\end{proposition}

\begin{exmp}
Let $\rateset^1$ and $\rateset^2$ be constructed as in Example~\ref{example:different_sets_same_lower_rate}, and let $\lrate\coloneqq\lrate_1=\lrate_2$ be their common lower transition rate operator. We will construct the set $\rateset_{\lrate}$ of rate matrices that dominate $\lrate$. Note that this construction is specific to the example, and will not work in general.

Recall from Example~\ref{example:different_sets_same_lower_rate} that for all $f\in\gamblesX$, it holds that either $\lrate f=Af$, or $\lrate f=Bf$. Using a similar argument as we used there for the rate matrix $C$, it is clear that any convex combination $Q_\lambda\coloneqq \lambda A+(1-\lambda)B$, with $\lambda\in[0,1]$, is a rate matrix that dominates $\lrate$. Furthermore, because we there found that $[Af](1)\leq [Bf](1)$ if and only if $[Af](2)\leq[Bf](2)$, any matrix constructed by combining rows from $A$ and $B$ will dominate $\lrate$. For example, let $D$ be a rate matrix such that $D(1,\cdot)\coloneqq A(1,\cdot)$ and $D(2,\cdot)\coloneqq B(2,\cdot)$. Then, if $Af\leq Bf$, it also holds that $Af\leq Df$. Similarly, if $Bf\leq Af$, then also $Bf\leq Df$. A similar argument shows that the same is true for any matrix constructed by combining rows from different convex combinations of $A$ and $B$.

From these ideas, we first construct two sets of rows. For all $x\in\states$, let
\begin{equation*}
\rateset_x \coloneqq \left\{\lambda A(x,\cdot)+(1-\lambda)B(x,\cdot)\,:\,\lambda\in[0,1]\right\}\,.
\end{equation*}
Let now $\rateset \coloneqq \{Q\in\mathcal{R}\,:\,(\forall x\in\states)\, Q(x,\cdot)\in\rateset_x\}$. Then, for all $Q\in\rateset$, $Q$ is such that
\begin{equation*}
Q=\left[\begin{array}{rr}-a & a \\ b& -b\end{array}\right]\,,\quad\text{where $a\in[1,3]$ and $b\in[1,2]$.}
\end{equation*}
The converse also holds; for all $a\in[1,3]$ and $b\in[1,2]$, there is a $Q\in\rateset$ that takes the above form. From this, it is clear that for all $Q\in\rateset$, it holds that $\lrate f\leq Qf$, for all $f\in\gamblesX$. Furthermore, $\rateset^1\subset\rateset$ and $\rateset^2\subset\rateset$. Hence, $\rateset$ has $\lrate$ as its corresponding lower transition rate operator. 

It remains to determine that $\rateset=\rateset_{\lrate}$. One way to verify this is to consider any $Q'\notin\rateset$, and show that there is then some $f\in\gamblesX$ and some $x\in\states$ such that $[Q'f](x)<[\lrate f](x)$. We leave this method as an exercise for the reader, and note instead the following. $\rateset$ is clearly non-empty, bounded, closed, convex, has separately specified rows, and has $\lrate$ as its lower transition rate operator. Therefore, by Proposition~\ref{prop:dominating_unique_characterization}, we find that indeed $\rateset=\rateset_{\lrate}$.
\exampleend
\end{exmp}

We conclude from all of this that non-empty bounded sets of rate matrices are more informative than lower transition rate operators. Different non-empty bounded sets of rate matrices $\rateset$ may have the same lower transition rate operator $\lrate$ and therefore, in general, knowledge of $\lrate$ does not suffice to reconstruct $\rateset$; we can only reconstruct an outer approximation $\rateset_{\lrate}$, which is guaranteed to include $\rateset$. This changes if, besides non-empty and bounded, $\rateset$ is also closed and convex and has separately specified rows. In that case, $\lrate$ serves as an alternative representation for $\rateset$ because, since $\rateset=\rateset_{\lrate}$, we can use $\lrate$ to reconstruct $\rateset$. In other words: there is a one-to-one correspondence between lower transition rate operators and non-empty, bounded, closed and convex sets of rate matrices that have separately specified rows.

%\section{Imprecise Continuous-Time Markov Chains}\label{sec:imp_markov}

%\subsection{New Version}

%This section contains the new, simplified proofs.

\subsection{Connections Between $L_t^s$ and Lower Expectations $\underline{\mathbb{E}}$}\label{sec:single_var_lower_exp}

Having established a strong connection between the operator $\lrate$ and non-empty bounded sets of rate matrices $\rateset$, we will now turn to the connection between the operator $L_t^s$ and lower expectations $\underline{\mathbb{E}}$ with respect to sets of (non-)Markov processes. Specifically, we will in this section focus on the lower expectation of functions defined on the state space at a single point in time. In Section~\ref{sec:funcs_multi_time_points} we will then use and generalize these results when we consider functions defined on the state space at multiple time points.

As the following result shows, the operator $L_t^s$ corresponding to a lower transition rate operator $\lrate$ computes a lower bound on the expectation of a function $f\in\gamblesX$, with respect to the set $\wprocesses_\rateset$ of well-behaved stochastic processes consistent with any set $\rateset$ of which $\lrate$ is the lower envelope.

\begin{proposition}\label{theorem:nonmarkov_single_var_lower_bounded}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for any $P\in\wprocesses_\rateset$, any $s\in\realsnonneg$, any $u\in\mathcal{U}_{<s}$, any $x_u\in\states^u$, and any $f\in\gamblesX$,
\begin{equation*}
[L_{t_n}^s f](x_{t_n}) \leq \mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,.
\end{equation*}
\end{proposition}

As this result shows, $L_t^sf$ is a lower bound on the expectation of a function $f\in\gamblesX$, with respect to a set of stochastic processes $\wprocesses_\rateset$ induced by some non-empty bounded set of rate matrices $\rateset$. Our next result establishes that this bound is tight if $\rateset$ also has separately specified rows. Specifically, we show that $L_t^sf$ can then be approximated to arbitrary precision by carefully choosing a Markov process $P$ from the set $\wmprocesses_\rateset$.

\begin{proposition}\label{theorem:lower_markov_bound_is_tight}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then for all $t,s\in\realsnonneg$ such that $t<s$, all $f\in\gamblesX$, and all $\epsilon\in\realspos$, there exists a $P\in\wmprocesses_{\rateset}$ such that
\begin{equation*}
\norm{\lbound_t^sf-T_t^sf} < \epsilon\,.
\end{equation*}
\end{proposition}

Together, Propositions~\ref{theorem:nonmarkov_single_var_lower_bounded} and~\ref{theorem:lower_markov_bound_is_tight} establish a strong connection between $L_t^s$ and lower expectations $\underline{\mathbb{E}}$. In particular, for functions defined on a single point in time, they turn out to be equivalent, as shown by the result below.

\begin{corollary}\label{cor:lower_operator_is_infimum}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $f\in\gamblesX$, all $t,s\in\realsnonneg$ such that $t<s$, all $u\in\mathcal{U}_{<t}$, all $x_u\in\states^u$, and all $x\in\states$,
\begin{align*}
\left[L_t^sf\right](x) &= \underline{\mathbb{E}}^{\mathrm{WM}}_{\,\rateset}[f(X_s)\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] \\
 &= \underline{\mathbb{E}}^{\mathrm{WM}}_{\,\rateset}[f(X_s)\,\vert\,X_t=x]\,,%\inf\Bigl\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\Bigr\}\,.
\end{align*}
and furthermore,
\begin{equation*}
\left[L_t^sf\right](x) = \underline{\mathbb{E}}^{\mathrm{W}}_{\,\rateset}[f(X_s)\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,.%\inf\Bigl\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\Bigr\}\,.
\end{equation*}
\end{corollary}

**** blablabla, ondergrens bereikt als $\rateset$ ook closed is

\begin{proposition}
Let $\rateset$ be an arbitrary non-empty, bounded, and closed set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $t,s\in\realsnonneg$ such that $t<s$, and all $f\in\gamblesX$, there is some $P\in\wmprocesses_\rateset$ such that
\begin{equation*}
L_t^sf = T_t^sf\,.
\end{equation*}
\end{proposition}
\begin{proof}
Consider any sequence $\{\epsilon_i\}_{i\in\nats}$ in $\realspos$ such that $\{\epsilon_i\}_{i\in\nats}\to0^+$. Due to Proposition~\ref{theorem:lower_markov_bound_is_tight}, for all $i\in\nats$, there is some $P_i\in\wmprocesses_\rateset$ such that
\begin{equation*}
\norm{L_t^sf - \presuper{i}T_t^sf} < \epsilon_i\,,
\end{equation*}
where $\presuper{i}T_t^s$ is the transition matrix corresponding to $P_i$. Consider the sequence $\{P_i\}_{i\in\nats}$. Then, because $\{\epsilon_i\}_{i\in\nats}\to0^+$, the corresponding sequence $\{\presuper{i}T_t^s\}_{i\in\nats}$ clearly satisfies
\begin{equation}\label{eq:prop_lower_is_reached_limit}
\lim_{i\to\infty}\norm{L_t^sf - \presuper{i}T_t^sf} = 0\,.
\end{equation}

For each $P_i$ in $\{P_i\}_{i\in\nats}$, consider the restricted transition matrix system $\mathcal{T}_i^{[t,s]}$. Because $P_i\in\wmprocesses_\rateset$, we clearly have that $\mathcal{T}_i^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$, where $\mathbb{T}_\rateset^{[t,s]}$ is the space of all restricted transition matrix systems corresponding to $\wmprocesses_\rateset$, defined as in Section~{\bf REF}.

Therefore, the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is clearly in $\mathbb{T}_\rateset^{[t,s]}$. Because $\rateset$ is non-empty, bounded, and closed, by Theorem~\ref{theorem:restricted_transmatsystem_space_compact_if_Q_closed}, the space $\mathbb{T}_\rateset^{[t,s]}$ is compact under the metric $d$ defined as in Equation~\eqref{eq:trans_mat_system_metric}. Therefore, the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ contains a convergent subsequence $\left\{\mathcal{T}_{i_k}^{[t,s]}\right\}_{k\in\nats}$, of which the limit $\mathcal{T}_*^{[t,s]}\coloneqq \lim_{k\to\infty}\mathcal{T}_{i_k}^{[t,s]}$ belongs to $\mathbb{T}_\rateset^{[t,s]}$.

Because $\mathcal{T}_*^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$, there must be some $P_*\in\wmprocesses_\rateset$ such that $\mathcal{T}_{P_*}^{[t,s]}=\mathcal{T}_*^{[t,s]}$. Furthermore, this $P_*$ has a corresponding transition matrix $\presuper{*}T_t^s$ which, by Lemma~{\bf REF}, is given by
\begin{equation*}
\presuper{*}T_t^s = \lim_{k\to\infty}\presuper{i_k}T_t^s\,.
\end{equation*}
Therefore, and because the sequence $\left\{\presuper{i_k}T_t^s \right\}_{k\in\nats}$ is a subsequence of $\left\{\presuper{i}T_t^s\right\}_{i\in\nats}$, we find from Equation~\eqref{eq:prop_lower_is_reached_limit} that
\begin{equation*}
\norm{L_t^sf - \presuper{*}T_t^sf} = 0\,.
\end{equation*}
In summary, we have found a $P_*\in\wmprocesses_\rateset$ with a corresponding transition matrix $\presuper{*}T_t^s$, such that
\begin{equation*}
L_t^sf = \presuper{*}T_t^sf\,.
\end{equation*}
\end{proof}

**** blablabla

Thus, we find that there is a correspondence between the operator $L_t^s$ and lower expectations with respect to sets of stochastic processes. However, we also find that this correspondence is not one-to-one. Clearly, Corollary~\ref{cor:lower_operator_is_infimum} shows that $L_t^s$ computes the lower expectation for the different sets $\wmprocesses_\rateset$ and $\wprocesses_\rateset$. Furthermore, we know from Section~\ref{sec:connections_rate} that different sets $\rateset^1$ and $\rateset^2$ may have the same corresponding lower transition rate operator $\lrate$. Hence, whenever this is the case, $L_t^s$ would---assuming the conditions in Corollary~\ref{cor:lower_operator_is_infimum} are met by both $\rateset^1$ and $\rateset^2$---then compute the lower expectation with respect to both $\wmprocesses_{\rateset^1}$ and $\wmprocesses_{\rateset^2}$ (and also, furthermore, for $\wprocesses_{\rateset^1}$ and $\wprocesses_{\rateset^2}$). An obvious question, therefore, would be what the largest set of stochastic processes is for which $L_t^s$ computes the lower expectation.

%*** This needs some rewording ***
%
%One somewhat unsurprising result is therefore that $L_t^s$ computes the lower expectation of functions $f\in\gamblesX$ with respect to sets of Markov processes $\mprocesses_\rateset$. The reason that this is to be expected is the previously established correspondence between $L_t^s$ and the solution of the differential equation introduced in {\bf DAMJANREF}, which was there shown to compute exactly this quantity.
%
%A rather more surprising result, perhaps, is that this \emph{same} operator also computes lower expectations with respect to sets $\processes_\rateset$ of non-Markov processes. Our next result strengthens this connection between $L_t^s$ and sets of non-Markov processes.

Recall from Section~\ref{sec:connections_rate} that for a given lower transition rate operator $\lrate$, its set of dominating rate matrices $\rateset_{\lrate}$ is---by definition---the largest set of rate matrices which has $\lrate$ as its lower envelope. The following result shows that the set $\wprocesses_{\rateset_{\lrate}}$ of well-behaved stochastic processes consistent with $\rateset_{\lrate}$ is the largest set of stochastic processes for which $L_t^s$ computes the lower expectation.

\begin{theorem}\label{theo:dominating_rate_processes_max_set}
Let $\lrate$ be an arbitrary lower transition rate operator, with $\rateset_{\lrate}$ its set of dominating rate matrices, and let  $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $f\in\gamblesX$, all $t,s\in\realsnonneg$ such that $t<s$, all $u\in\mathcal{U}_{<t}$, all $x_u\in\states^u$, and all $x\in\states$,
\begin{equation*}
\left[L_t^sf\right](x) = \inf\left\{\mathbb{E}[f(X_s)\,\vert\,X_t=x,X_{t_0},\ldots,X_{t_n}=x_{t_n}]\,:\,P\in\wprocesses_{\rateset_{\lrate}}\right\}\,,
\end{equation*}
and, contrariwise, for all $P\in\processes$ such that $P\notin\wprocesses_{\rateset_{\lrate}}$, there is some $f\in\gamblesX$, some $t,s\in\realsnonneg$ with $t<s$, some $u\in\mathcal{U}_{<t}$, and some $x_u\in\states^u$, such that for some $x\in\states$,
\begin{equation*}
\mathbb{E}\left[f(X_s)\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right] < \left[L_t^sf\right](x)\,.
\end{equation*}
\end{theorem}

Similar to our results from Section~\ref{sec:connections_rate}, we conclude from this that sets of stochastic processes are more informative than their corresponding lower expectations. In general, different sets $\wprocesses_\rateset$ of stochastic processes can have their lower expectations computed by the same lower transition operator $L_t^s$, and hence they necessarily have the same lower expectation. 

Therefore, even if $L_t^s$ computes the lower expectation with respect to $\wprocesses_\rateset$, knowledge of $L_t^s$ does not in general suffice to reconstruct $\wprocesses_\rateset$. We can, however, construct an outer approximation which is guaranteed to contain $\wprocesses_\rateset$, as follows. From Proposition~\ref{prop:lower_transition_has_deriv}, we can find the lower transition rate operator $\lrate$ that characterizes $L_t^s$, using $\lim_{\Delta\to0^+}\nicefrac{1}{\Delta}(L_t^{t+\Delta}-I)=\lrate$. Using this operator $\lrate$, we can construct the set $\rateset_{\lrate}$ of rate matrices that dominate $\lrate$. Finally, we can construct the set $\wprocesses_{\rateset_{\lrate}}$. Because $L_t^s$ computes the lower expectation with respect to $\wprocesses_\rateset$, Theorem~\ref{theo:dominating_rate_processes_max_set} now guarantees that $\wprocesses_\rateset\subseteq\wprocesses_{\rateset_{\lrate}}$.

This changes if the set $\wprocesses_\rateset$ is not only well-behaved, includes non-Markov processes, and is such that $\rateset$ is non-empty and bounded with separately specified rows, but furthermore is such that $\rateset$ is closed and convex. In that case, $L_t^s$ serves as an alternative characterization of $\wprocesses_\rateset$, because then, by Proposition~\ref{prop:dominating_unique_characterization}, it holds that $\wprocesses_\rateset=\wprocesses_{\rateset_{\lrate}}$.

**** ergens voelt het wel nice om die karakterisatie in termen van de set $\wprocesses_\rateset$ zelf te doen, in plaats van in termen van $\rateset$. een resultaat zoals hieronder staat (in commentaar, in de latex file) zou daarvoor kunnen helpen.

%**** misschien nog zoiets toevoegen ergens? voor elke $\mathcal{P}\subset\processes$, (misschien rekening houden met $t,s,x_u$ om geldig te laten zijn),
%\begin{equation*}
%\mathcal{T}_{\mathcal{P}} \coloneqq \left\{T_{t,\,x_u}^s\,:\,P\in\mathcal{P}\right\}
%\end{equation*}
%
%dan, voor $\mathcal{T}_{\wprocesses_\rateset}$:
%\begin{align*}
%\rateset\neq \emptyset &\Leftrightarrow \mathcal{T}_{\wprocesses_\rateset}\neq\emptyset \\
%\rateset~\text{is closed} &\Leftrightarrow \mathcal{T}_{\wprocesses_\rateset}~\text{is closed} \\
%\rateset~\text{is convex} &\Leftrightarrow \mathcal{T}_{\wprocesses_\rateset}~\text{is convex} \\
%\rateset~\text{has s.s.r.} &\Leftrightarrow \mathcal{T}_{\wprocesses_\rateset}~\text{has s.s.r.}
%\end{align*}
%
%vervolgens laten zien dat als voor $\mathcal{P}\subset\wprocesses$ de set $\mathcal{T}_{\mathcal{P}}$ al die eigenschappen heeft, dat dan $\mathcal{P}=\wprocesses_{\rateset}$, waarbij $\rateset$ al die eigenschappen heeft en verder ook bounded is.
%
%dan als voor $\mathcal{P}\subset\wprocesses$ de set $\mathcal{T}_{\mathcal{P}}$ al die eigenschappen heeft, zijn $\mathcal{P}$, $L_t^s$ (en $\lrate$) allemaal even sterk, in de zin dat
%\begin{align*}
%\mathcal{P}&=\wprocesses_{\rateset} \Rightarrow \rateset \Rightarrow \lrate \Rightarrow \underline{\mathcal{T}}_{\lrate} \Rightarrow L_t^s \\
%L_t^s &\Rightarrow \lim_{\Delta\to0^+}\frac{1}{\Delta}(L_t^{t+\Delta} - I)=\lrate \Rightarrow \rateset_{\lrate}=\rateset \Rightarrow \wprocesses_{\rateset} = \mathcal{P} \\
%\lrate &\Rightarrow \underline{\mathcal{T}}_{\lrate} \Rightarrow L_t^s,\quad\text{and,}\quad \lrate\Rightarrow \rateset_{\lrate} \Rightarrow \wprocesses_{\rateset_{\lrate}} = \mathcal{P}
%\end{align*}

\section{Functions Defined on Multiple Time Points}\label{sec:funcs_multi_time_points}

Having shown in Section~\ref{sec:single_var_lower_exp} that the operator $L_t^s$ computes lower expectations for functions $f\in\gamblesX$ defined on a single point in time, we will now turn our attention to functions defined on multiple time points. Because we are considering \emph{conditional} expectations, where the conditioning is done with respect to states in a (non-)Markov chain's history, it makes sense to distinguish between two different classes of functions defined at multiple time points. 

First, in Section~\ref{sec:function_single_future_multiple_past}, we will consider functions defined on a single time point in a chain's future, and multiple time points in the chain's history. Thus, we will consider functions $f\in\gambles(\states^{u\cup\{s\}})$, and lower expectations of the form
\begin{equation*}
\underline{\mathbb{E}}\left[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0},\ldots,X_{t_n}\right]\,.
\end{equation*}
We will see that it is a straightforward implication of our results from Section~\ref{sec:single_var_lower_exp} that such lower expectations are computable using $L_t^s$, both with respect to sets of Markov chains and with respect to sets of non-Markov chains.

In Section~\ref{sec:decomposition} we will generalize this to functions defined on multiple time points in a chain's future and history, considering functions $f\in\gambles(\states^{u\cup v})$ and lower expectations of the form
\begin{equation*}
\underline{\mathbb{E}}\left[f(X_{t_0},\ldots,X_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0},\ldots,X_{t_n}\right]\,.
\end{equation*}
As we will see, for functions of this kind the lower expectations with respect to sets of non-Markov chains no longer correspond to those taken with respect to sets of Markov chains. One of the main results of this paper, however, is that we can still use the operator $L_t^s$ to compute lower expectations of this form if taken with respect to sets of non-Markov chains. We will see that this is because the optimization problem involved in computing lower expectations in some sense becomes simpler when we drop the Markov assumption.

Finally, in Section~\ref{sec:tractability}, we will show that although $L_t^s$ provides us with a way to compute such lower expectations, doing so for general functions $f\in\gambles(\states^{u\cup v})$ is still computationally intractable. However, we then provide algorithms to tractably compute lower expectations for large and practically useful subclasses of $\gambles(\states^{u\cup v})$.

\subsection{Multi-Variable Functions on a Single Point in the Future}\label{sec:function_single_future_multiple_past}

We start by considering functions $f\in\gambles(\states^{u\cup\{s\}})$ defined on a single time point $s$ in a (non-)Markov chain's future, and multiple time points $u=t_0,\ldots,t_n$ in a chain's history. Recall our notation from Section~\ref{sec:multivar_notation}; we write $f(x_{t_0},\ldots,x_{t_n},X_s)$ for the restriction of $f$ to $\states^{\{s\}}$ for a specific state assignment $(x_{t_0},\ldots,x_{t_n})$, and have defined
\begin{equation*}
\left[L_{t_n}^sf\right](x_{t_0},\ldots,x_{t_n}) \equiv \left[L_{t_n}^sf(x_{t_0},\ldots,x_{t_n},X_s)\right](x_{t_n})\,.
\end{equation*}
The following results are now direct implications of, and analogies to, our results from Section~\ref{sec:single_var_lower_exp}.

\begin{proposition}\label{prop:multi_var_single_future_bounded}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for any $P\in\wprocesses_\rateset$, any $s\in\realsnonneg$, any $u\in\mathcal{U}_{<s}$, any $x_u\in\states^u$, and any $f\in\gambles(\states^{u\cup\{s\}})$,
\begin{equation*}
\left[L_{t_n}^sf\right](x_{t_0},\ldots,x_{t_n}) \leq \mathbb{E}\left[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right]\,.
\end{equation*}
\end{proposition}

\begin{proposition}\label{prop:multi_var_single_future_tight}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $s\in\realsnonneg$, all $u\in\mathcal{U}_{<s}$, all $x_u\in\states^u$, all $f\in\gambles(\states^{u\cup\{s\}})$, and all $\epsilon\in\realspos$, there is a $P\in\wmprocesses_\rateset$ such that
\begin{equation*}
\abs{\left[L_{t_n}^sf\right](x_{t_0},\ldots,x_{t_n}) - \mathbb{E}\left[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right]} < \epsilon\,.
\end{equation*}
\end{proposition}

Note that this result is weaker than the corresponding Theorem~\ref{theorem:lower_markov_bound_is_tight} in Section~\ref{sec:single_var_lower_exp}. Specifically, this says that for a given history $x_u\in\states^u$, there is a $P\in\wmprocesses_\rateset$ that approaches $\left[L_{t_n}^sf\right](x_{t_0},\ldots,x_{t_n})$. This does not imply that there is a $P\in\wmprocesses_\rateset$ that approaches $\left[L_{t_n}^sf\right](x_{t_0},\ldots,x_{t_n})$ for \emph{all} histories! 

We will see in Section~\ref{sec:decomposition} that this is exactly the reason that computing lower expectations with respect to sets of non-Markov processes is ``easy''; by dropping the Markov assumption, the corresponding optimization problems become solvable locally with respect to a given history. In contrast, the optimization over sets of Markov processes must there be done globally with respect to all possible histories, because they do not allow for minimizing selections specific to a given trajectory.

For our present purposes, Proposition~\ref{prop:multi_var_single_future_tight} is still strong enough to imply the following result.

%\begin{proposition}
%In essentie, voor alle $f\in\gambles(\states^{u\cup\{s\}})$ en alle $\epsilon\in\realspos$, is er een $P\in\mprocesses_\rateset$ zodat
%\begin{equation*}
%\norm{L_t^s f - \mathbb{E}[f(X_{t_0},\ldots,X_{t_n},X_s)\,\vert\,X_{t_0,\ldots,t_n}]} < \epsilon\,.
%\end{equation*}
%\end{proposition}
%\begin{proof}
%{\bf TODO} This is immediate.
%\end{proof}

\begin{corollary}\label{cor:inf_works_for_single_future_var}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $s\in\realsnonneg$, all $u\in\mathcal{U}_{<s}$, all $x_u\in\states^u$, and all $f\in\gambles(\states^{u\cup\{s\}})$,
\begin{equation*}
\left[L_{t_n}^s f\right](x_{t_0},\ldots,x_{t_n}) = \underline{\mathbb{E}}^{\mathrm{WM}}_{\,\rateset}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,,
\end{equation*}
and furthermore,
\begin{equation*}
\left[L_{t_n}^s f\right](x_{t_0},\ldots,x_{t_n}) = \underline{\mathbb{E}}^\mathrm{W}_{\,\rateset}[f(x_{t_0},\ldots,x_{t_n},X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,.
\end{equation*}
\end{corollary}

Thus, we see that the operator $L_t^s$ can also be used to compute lower expectations of functions $f\in\gambles(\states^{u\cup\{s\}})$, both with respect to sets of Markov processes and with respect to sets of non-Markov processes. We will now turn to functions defined on multiple time points in a process' future, where we will find this correspondence to no longer hold.


\subsection{Multi-Variable Functions on Multiple Points in the Future}\label{sec:decomposition}

*** I would generalise this section a bit. How about we first prove an extended version of Corollary~\ref{cor:inf_works_for_multivar} that does not use $L$, but instead just decomposes a lower expectation operator into two parts (both of which may consist of multiple time points). The specific version with $L$ then follows by combining this result with Corollary~\ref{cor:inf_works_for_single_future_var}. ***

**** notatie moet nog geupdate worden ***

We now consider functions $f\in\gambles(\states^{u\cup v})$, where $u=t_0,\ldots,t_n$ is a sequence of time points in a process' history, and $v=s_0,\ldots,s_m$ is a sequence of time points in a process' future; hence, we assume $s_0>t_n$. As the next example shows, the lower expectation of such functions, when taken with respect to a set $\wmprocesses_\rateset$ of Markov processes, no longer necessarily corresponds to the lower expectation taken with respect to a set $\wprocesses_\rateset$ of non-Markov processes.

\begin{exmp}
{\bf TODO} Example that sometimes $\underline{\mathbb{E}}^\mathrm{M}\neq \underline{\mathbb{E}}$ for functions $f\in\gambles(\states^{u\cup v})$.
\exampleend
\end{exmp}

An obvious question is therefore what the operator $L_t^s$ computes for functions of this form, as it clearly cannot compute both $\underline{\mathbb{E}}^{\mathrm{WM}}_{\,\rateset}$ and $\underline{\mathbb{E}}^\mathrm{W}_{\,\rateset}$. As we will see below, it turns out that we can use $L_t^s$ to compute the lower expectation of such functions with respect to sets of non-Markov processes. We start by showing that, using a composition of these operators, we can compute a lower bound with respect to a set $\wprocesses_\rateset$.
\begin{proposition}\label{prop:multivar_bounded}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for any $P\in\wprocesses_\rateset$, any $s,s'\in\realsnonneg$ such that $s<s'$, any $u\in\mathcal{U}_{<s}$ and $x_u\in\states^u$, any $v\in\mathcal{U}_{[s,s']}$, and any $f\in\gambles(\states^{u\cup v})$,
\begin{equation*}
\left[L_{t_n}^{s_0}L_{s_0}^{s_1}\cdots L_{s_{m-1}}^{s_m}f\right](x_{t_0},\ldots,x_{t_n}) \leq \mathbb{E}[f(x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
\end{proposition}

Note that a direct implication of this, together with Proposition~\ref{prop:lower_exp_markov_bounded_by_nonmarkov}, is that $L_t^s$ can also be used to compute lower bounds on the expectation with respect to a set $\wmprocesses_\rateset$ of Markov processes. However, this bound will then in general not be tight, and hence will not correspond to the lower expectation.

To see why, observe that in the term $[L_{t_n}^{s_0}L_{s_0}^{s_1}\cdots L_{s_{m-1}}^{s_m}f](x_{t_0},\ldots,x_{t_n})$, the operators $L_{s_{i-1}}^{s_i}$ can take on different values depending on the choice of $(x_{t_0},\ldots,x_{t_n},x_{s_0},\ldots,x_{s_{i-1}})$. Hence, to approach these values of $L_{s_{i-1}}^{s_i}$ from within a set $\wmprocesses$ of Markov processes, we have to be able to pick the approximating values such that they depend on the specific trajectory $(x_{t_0},\ldots,x_{t_n},x_{s_0},\ldots,x_{s_{i-1}})$, and this is exactly what the Markov condition prevents us from doing. As the next result shows, we can however approach this quantity from within a set $\wprocesses_\rateset$ of non-Markov processes.

\begin{proposition}\label{prop:multivar_bound_tight}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $s,s'\in\realsnonneg$ such that $s<s'$, all $u\in\mathcal{U}_{<s}$, all $v\in\mathcal{U}_{[s,s']}$, all $f\in\gambles(\states^{u\cup v})$, and all $\epsilon\in\realspos$, there is a $P\in\wprocesses_\rateset$ such that
\begin{equation*}
\norm{L_{t_n}^{s_0}L_{s_0}^{s_1}\cdots L_{s_{m-1}}^{s_m}f - \mathbb{E}[f(X_{t_0},\ldots,X_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}]} < \epsilon\,.
\end{equation*}
\end{proposition}

\begin{corollary}\label{cor:inf_works_for_multivar}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$, and let $\underline{\mathcal{T}}_{\lrate}$ be the family of lower transition operators corresponding to $\lrate$. Then, for all $s,s'\in\realsnonneg$ such that $s<s'$, all $u\in\mathcal{U}_{<s}$ and $x_u\in\states^u$, all $v\in\mathcal{U}_{[s,s']}$, and all $f\in\gambles(\states^{u\cup v})$,
\begin{equation*}
\left[L_{t_n}^{s_0}L_{s_0}^{s_1}\cdots L_{s_{m-1}}^{s_m}f\right](x_{t_0},\ldots,x_{t_n}) = \underline{\mathbb{E}}^{\mathrm{W}}_{\,\rateset}[f(x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]\,.
\end{equation*}
\end{corollary}

\subsection{Computational Aspects}\label{sec:tractability}

**** notes about computational aspects/tractability, observation that decomposition reduces the problem to discrete-time computations, reference earlier work containing algorithms to compute this

**** computation can also be brute-forced if state space and number of time points allow for it.

**** our proof in Section~\ref{sec:lowertrans} shows that we can numerically approximate to arbitrary precision using a fine enough partition of the intervals

\begin{exmp}
**** result for motivating toy example from introduction
\exampleend
\end{exmp}

\section{Relation to Previous Work}\label{sec:prev_work}

To the best of our knowledge, the concept of imprecise continuous-time Markov chains was first introduced in the literature by the work of {\v{S}}kulj~\cite{Skulj:2015cq}. There, the idea was used to define $\lrate$ as a lower envelope of a set of rate matrices $\rateset$ that has separately specified rows. It was shown that then, for a given $f\in\gamblesX$, the differential equation
\begin{align}\label{eq:damjans_diff}
\begin{split}
\frac{d \underline{f}_{\,t}}{d t} &\coloneqq \lrate\,\underline{f}_{\,t}\,,\quad
\underline{f}_{\,0} \coloneqq f\,,
\end{split}
\end{align}
has a unique solution, and that this solution satisfies
\begin{equation}\label{eq:damjans_lower}
\underline{f}_{\,s} = \underline{\mathbb{E}}_{\rateset}^{\mathrm{WM}}[f(X_s)\,\vert\,X_0]\,.
\end{equation}
Our work extends these results in several ways. First, as shown by Proposition~\ref{prop:lower_transition_has_deriv}, the differential equation~\eqref{eq:damjans_diff} has a uniform solution, i.e. one that is independent of $f$, and this solution is given\footnote{There are some notational discrepancies between this previous work and our work here. To see this correspondence, take from Proposition~\ref{prop:lower_transition_has_deriv} the quantity $\nicefrac{\partial}{\partial t}L_t^s=-\lrate L_t^s$, with boundary condition $L_s^s=I$, and ``integrate'' backward from $s$ to $0$. This fixes the directional inconsistency of the derivatives, and yields the proper correspondence to differential equation~\eqref{eq:damjans_diff}.} by the operator $L_0^s$ corresponding to $\lrate$. Second, Corollary~\ref{cor:lower_operator_is_infimum} confirms Equation~\eqref{eq:damjans_lower}, but furthermore shows that the solution $\underline{f}_{\,s}$ also corresponds to the lower expectation with respect to a set of non-Markov processes.

Our present work furthermore adds to the literature in several ways. In~\cite{Skulj:2015cq}, the arguments were cast purely in terms of lower envelopes of expectation functionals; but side-stepped the question of which sets of processes these envelopes correspond to. In contrast, our work in Section~\ref{sec:iCTMC} makes explicit the sets of processes that we are dealing with, and Theorem~\ref{theo:dominating_rate_processes_max_set} exactly characterizes the largest set of processes for which our lower transition operator---and indeed the differential equation~\eqref{eq:damjans_diff}---computes a lower envelope.

This earlier work also contains several results that are of significance to us. In particular, {\v{S}}kulj discusses several practical techniques to numerically compute, or approximate to arbitrary precision, the quantity $\underline{f}_{\,s}$ for a given $f\in\gamblesX$. Hence, because of the correspondence between $\underline{f}_{\,s}$ and $L_0^sf$, these results can be applied when numerically working with our lower transition operator.

*** onderstaande beetje herschrijven nog

Finally, previous work only focused on functions $f\in\gamblesX$ defined at a single point in time. We will now turn to functions defined on multiple time points, where we will find that it is crucial to be aware of the set of processes with respect to which one is taking lower envelopes.

\section{Conclusions \& Future Work}\label{sec:conclusions}

*** kijk, dit hebben we besproken

*** wat hebben we daarvan geleerd?

*** wat kunnen we nog meer doen? Nou, bijvoorbeeld:

*** I would discuss sigma-additivity things here: explain that this is possible with our approach by using Kolmogorovs extension theorem, say that this would allow us to consider for example the lower and upper expected time till absorbtion. ***

*** mogelijk nog opmerking over dat dit Hidden-ICTMCs mogelijk maakt omdat GBR in subklasse van berekenbare functies zit

*** mogelijk iets over dat het handig kan zijn om voor berekenbaarheid nieuwe methodes te vinden om $\hat{f}_t^s$ numeriek uit te rekenen.


\bibliographystyle{plain} 
\bibliography{general}

\appendix

\section{Proofs and Lemmas for Section~\ref{sec:prelim}}

\begin{lemma}\label{lemma:recursive}
Consider two sequences $A_1,\ldots,A_n$ and $B_1,\ldots,B_n$ of non-negatively homogeneous operators from $\gamblesX$ to $\gamblesX$, such that $\norm{A_i}\leq 1$ and $\norm{B_i}\leq 1$ for all $i\in\{1,\ldots,n\}$. Suppose that it holds for all $i\in\{1,\ldots,n\}$ that $\norm{A_i - B_i} \leq c_i$, for some $c_i\in\realsnonneg$. Then,
\begin{equation}\label{eq:lemma_recursive_inequality}
\norm{\prod_{i=1}^nA_i - \prod_{i=1}^nB_i} \leq \sum_{i=1}^n c_i\,.
\end{equation}
Furthermore, if it strictly holds that $\norm{A_i - B_i} < c_i$ for some $i\in\{1,\ldots,n\}$, then the inequality in Equation~\eqref{eq:lemma_recursive_inequality} is also strict.
\end{lemma}
\begin{proof}
We provide a proof by induction. Clearly, Equation~\eqref{eq:lemma_recursive_inequality} holds for $n=1$. Suppose that it holds for $n=k-1$. We show that it then also holds for $n=k$.
\begin{align*}
\norm{\prod_{i=1}^nA_i - \prod_{i=1}^nB_i} &= \norm{\prod_{i=1}^nA_i - \left(\prod_{i=1}^{n-1}A_i\right)B_n + \left(\prod_{i=1}^{n-1}A_i\right)B_n - \prod_{i=1}^nB_i} \\
 &\leq \norm{\prod_{i=1}^nA_i - \left(\prod_{i=1}^{n-1}A_i\right)B_n} + \norm{\left(\prod_{i=1}^{n-1}A_i\right)B_n - \prod_{i=1}^nB_i} \\
 &= \norm{\left(\prod_{i=1}^{n-1}A_i\right)(A_n - B_n)} + \norm{\left(\prod_{i=1}^{n-1}A_i - \prod_{i=1}^{n-1}B_i\right)B_n} \\
 &\leq \norm{\prod_{i=1}^{n-1}A_i}\norm{A_n - B_n} + \norm{\prod_{i=1}^{n-1}A_i - \prod_{i=1}^{n-1}B_i}\norm{B_n} \\
 &\leq \norm{A_n - B_n} + \norm{\prod_{i=1}^{n-1}A_i - \prod_{i=1}^{n-1}B_i} \\
 &\leq c_n + \sum_{i=1}^{n-1}c_i = \sum_{i=1}^{n}c_i\,.
\end{align*}
Here, in the second-to-last inequality, we used the fact that $\norm{A_i}\leq 1$ and $\norm{B_i}\leq 1$ for all $i\in\{1,\ldots,n\}$. In the final inequality, we used the induction hypothesis and the assumption that $\norm{A_n - B_n}\leq c_n$. If instead strictly $\norm{A_n - B_n}< c_n$, we can therefore replace the final inequality with a strict inequality.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:norm_properties}]
*** Most are obvious, as that's what it means to be a ``norm''. Others follow trivially from the definitions. Properties~\ref{N:normAB} and \ref{N:normAf} probably require a proof.
\end{proof}

\begin{lemma}\label{lemma:alt_axiom_prob}
Let $P$ be any map from $\power\times\nonemptypower$ to $\reals$. Then, $P$ is a full conditional probability if and only if it satisfies
\begin{enumerate}[label=P\arabic*:,ref=P\arabic*]
\item $P(\cdot\,\vert\,C)$ is a non-negative, (finitely-)additive function on $\power$, for all $C\in\nonemptypower$;\label{lem:alt_axiom_prob_1}
\item $P(A\,\vert\,C)=1$ for all $A\in\power$ and $C\in\nonemptypower$ such that $C\subseteq A$;\label{lem:alt_axiom_prob_2}
\item $P(A\cap D\,\vert\,C)=P(A\,\vert\,D\cap C)P(D\,\vert\,C)$ for all $A\in\power$ and $C,D\cap C\in\nonemptypower$.\label{lem:alt_axiom_prob_3}
\end{enumerate}
Note that because $\power$ and $\nonemptypower$ both contain subsets of $\Omega$, the subset and intersection relations in~\ref{lem:alt_axiom_prob_2} and~\ref{lem:alt_axiom_prob_3} are properly defined.
\end{lemma}
\begin{proof}
We start by proving the ``if" direction; if $P$ satisfies~\ref{lem:alt_axiom_prob_1}-\ref{lem:alt_axiom_prob_3}, it is a full conditional probability, i.e., it then satisfies~\ref{def:coh_prob_1}-\ref{def:coh_prob_4}.

Property~\ref{def:coh_prob_1} is immediate from~\ref{lem:alt_axiom_prob_2}. Furthermore, property~\ref{def:coh_prob_3} is the formal definition of (finite-)additivity from~\ref{lem:alt_axiom_prob_1}. The non-negativity in~\ref{def:coh_prob_2} follows from the non-negativity in~\ref{lem:alt_axiom_prob_1}. To fully prove~\ref{def:coh_prob_2}, it remains to show that for all $A\in\power$ and all $C\in\nonemptypower$, it holds that $P(A\,\vert\,C)\leq 1$. Note that $A\cap A^c=\emptyset$, where $A^c$ denotes the complement of $A$ in $\Omega$. Hence, by~\ref{def:coh_prob_3}, we have $P(A\,\vert\,C)+P(A^c\,\vert\,C)=P(A\cup A^c\,\vert\,C)=P(\Omega\,\vert\,C)=1$, where the last equality follows from~\ref{lem:alt_axiom_prob_2}, since $C\subseteq \Omega$. Hence, by non-negativity of $P(A\,\vert\,C)$ and $P(A^c\,\vert\,C)$, we find that $P(A\,\vert\,C)\leq 1$.

For property~\ref{def:coh_prob_4}, take any $A\in\power$ and any $C,D\in\nonemptypower$ such that $A\subseteq D\subseteq C$. Then clearly, $A\cap D=A$ and $D\cap C=D$. Hence, it also holds that $D\cap C\in\nonemptypower$. Therefore, by property~\ref{lem:alt_axiom_prob_3}, we have that $P(A\,\vert\,C)=P(A\cap D\,\vert\,C)=P(A\,\vert\,D\cap C)P(D\,\vert\,C)=P(A\,\vert\,D)P(D\,\vert\,C)$, which confirms~\ref{def:coh_prob_4}.

We now prove the other direction; if $P$ satisfies~\ref{def:coh_prob_1}-\ref{def:coh_prob_4}, it also satisfies~\ref{lem:alt_axiom_prob_1}-\ref{lem:alt_axiom_prob_3}.

The non-negativity in~\ref{lem:alt_axiom_prob_1} follows from~\ref{def:coh_prob_2}. The (finite-)additivity is equal to~\ref{def:coh_prob_3}, which concludes the proof for~\ref{lem:alt_axiom_prob_1}.

For property~\ref{lem:alt_axiom_prob_2}, take any $A\in\power$ and any $C\in\nonemptypower$ such that $C\subseteq A$. Let $B\coloneqq A\setminus C$. Then clearly, $B\in\power$, $B\cup C=A$, and $B\cap C=\emptyset$. Hence, we have $P(A\,\vert\,C)=P(B\cup C\,\vert\,C)$, and by~\ref{def:coh_prob_3}, we have $P(B\cup C\,\vert\,C)=P(B\,\vert\,C)+P(C\,\vert\,C)$. Using properties~\ref{def:coh_prob_1} and~\ref{def:coh_prob_2}, it then follows that $P(B\,\vert\,C)=0$, and furthermore, $P(A\,\vert\,C)=P(B\cup C\,\vert\,C)=1$, confirming~\ref{lem:alt_axiom_prob_2}. 

For property~\ref{lem:alt_axiom_prob_3}, we first show that $P(A\cap C\,\vert\,C) = P(A\,\vert\,C)$ for all $A\in\power$ and all $C\in\nonemptypower$. To show this, take any $A\in\power$, any $C\in\nonemptypower$, and let $B\coloneqq A\setminus(A\cap C)$. Then clearly, $A=B\cup(A\cap C)$ and $B\cap (A\cap C)=\emptyset$. Hence, by~\ref{def:coh_prob_3}, we have
\begin{align*}
P(A\,\vert\,C) = P(B\cup(A\cap C)\,\vert\,C)= P(B\,\vert\,C) + P(A\cap C\,\vert\,C).
\end{align*}
It remains to show that $P(B\vert\,C)=0$. Note that because $B=A\setminus(A\cap C)$, it follows that $B\cap C=\emptyset$. Therefore, by~\ref{def:coh_prob_3},
\begin{align*}
P(B\cup C\,\vert\,C)=P(B\,\vert\,C) + P(C\,\vert\,C) \\
P(B\cup C\,\vert\,C)=P(B\,\vert\,C) + 1\,,
\end{align*}
using~\ref{def:coh_prob_1}. Since $0\leq P(B\,\vert\,C)$ and $P(B\cup C\,\vert\,C)\leq 1$ by~\ref{def:coh_prob_2}, it follows that $P(B\,\vert\,C)=0$. Hence,
\begin{align*}
P(A\,\vert\,C) = P(B\cup(A\cap C)\,\vert\,C)= P(B\,\vert\,C) + P(A\cap C\,\vert\,C) = P(A\cap C\,\vert\,C)\,.
\end{align*}

Now, to prove property~\ref{lem:alt_axiom_prob_3}, take any $A\in\power$ and any $C,D\cap C\in\nonemptypower$. Let $E\coloneqq A\cap D\cap C$, and let $G\coloneqq D\cap C$. Then clearly, $E\subseteq G\subseteq C$. Hence, by~\ref{def:coh_prob_4},
\begin{align*}
P(E\,\vert\,C) &= P(E\,\vert\,G)P(G\,\vert\,C) \\
P(A\cap D\cap C\,\vert\,C) &= P(A\cap D\cap C\,\vert\,D\cap C)P(D\cap C\,\vert\,C)\,.
\end{align*}
Using the previously established property, we have that $P(A\cap D\cap C\,\vert\,C)=P(A\cap D\,\vert\,C)$, $P(A\cap D\cap C\,\vert\,D\cap C)=P(A\,\vert\,D\cap C)$, and $P(D\cap C\,\vert\,C)=P(D\,\vert\,C)$. Hence, we find
\begin{align*}
P(A\cap D\cap C\,\vert\,C) &= P(A\cap D\cap C\,\vert\,D\cap C)P(D\cap C\,\vert\,C) \\
P(A\cap D\,\vert\,C) &= P(A\,\vert\,D\cap C)P(D\,\vert\,C)\,,
\end{align*}
which proves~\ref{lem:alt_axiom_prob_3}.
\end{proof}

\begin{definition}
*** coherent on set
\end{definition}

\begin{corollary}
*** if map from subset of conditional events to R is coherent on this subset, it is a coherent conditional probability
\end{corollary}
\begin{proof}
(duh)
\end{proof}

\begin{lemma}
if map is coherent on set, then it is also coherent on any subset
\end{lemma}
\begin{proof}
todo
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theo:coherentextendable}]
We start by proving the ``if" direction; if $P$ can be extended to a full conditional probability, it is a coherent conditional probability on $\mathcal{C}\subseteq\power\times\nonemptypower$. Let $P$ be a map from $\mathcal{C}\subseteq\power\times\nonemptypower$ to $\reals$ such that it has an extension $P^*$ on $\power\times\nonemptypower$ that is a full conditional probability. 

Because events are subsets of $\Omega$, we have that the set $\power$ of all events is the power set of $\Omega$. Hence, $\power$ is an algebra of events. Furthermore, because $P^*$ satisfies~\ref{def:coh_prob_1}-\ref{def:coh_prob_4}, by Lemma~\ref{lemma:alt_axiom_prob}, it also satisfies~\ref{lem:alt_axiom_prob_1}-\ref{lem:alt_axiom_prob_3}. Therefore~\cite{berti1991coherent}, $P^*$ is a coherent conditional probability on $\power\times\nonemptypower$. Hence {(\bf LEMMA?)}, $P^*$ is coherent on the subset $\mathcal{C}\subseteq\power\times\nonemptypower$. Note that because $P^*$ is an extension of $P$, $P$ and $P^*$ take the same values on $\mathcal{C}$. Therefore, and because $P^*$ is coherent on $\mathcal{C}$, $P$ is also coherent on $\mathcal{C}$. Hence, $P$ is a coherent conditional probability.

We now prove the other direction; if $P$ is coherent on $\mathcal{C}\subseteq\power\times\nonemptypower$, it can be extended to a full conditional probability.
Let $P$ be a coherent conditional probability on $\mathcal{C}\subseteq\power\times\nonemptypower$. Then, there exists~\cite[Theorem 4]{regazzini1985finitely} an extension $P^*$ of $P$ to the set $\power\times\nonemptypower$, such that $P^*$ is a coherent conditional probability.

Recall that $\power$ is an algebra of events. Therefore~\cite{berti1991coherent}, and because $P^*$ is coherent on $\power\times\nonemptypower$, $P^*$ satisfies~\ref{lem:alt_axiom_prob_1}-\ref{lem:alt_axiom_prob_3}. Hence, by Lemma~\ref{lemma:alt_axiom_prob}, $P^*$ also satisfies~\ref{def:coh_prob_1}-\ref{def:coh_prob_4}. Therefore, $P^*$ is an extension of $P$ that is a full conditional probability.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:stochastic_from_rate_matrix}]
Let $T=[I+\Delta Q]$. We will verify the properties from Definition~\ref{def:stoch_matrix}.

We start with property S1. Consider any $x\in\states$. Then
\begin{equation*}
\sum_{y\in\states} T(x,y) = \sum_{y\in\states} [I + \Delta Q](x,y) = \sum_{y\in\states}I(x,y) + \Delta \sum_{y\in\states}Q(x,y) = 1\,,
\end{equation*}
where we used property R1 from Definition~\ref{def:rate_matrix}.

For property S2, note that $0\leq \Delta \leq \nicefrac{1}{\norm{Q}}$. Hence, for all $x\in\states$, we have $-1\leq \Delta Q(x,x) \leq 0$, so that $[I+\Delta Q](x,x) \geq 0$. Furthermore, for all $x,y\in\states$ s.t. $x\neq y$, we have $0\leq \Delta Q(x,y) \leq 1$, so that $[I+\Delta Q](x,y)\geq 0$.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:rate_from_stochastic_matrix}]
This follows from a similar argument as the proof of Proposition~\ref{prop:stochastic_from_rate_matrix}; simply verify the properties from Definition~\ref{def:rate_matrix}.
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:stochastic_processes}}

*** Next 2 Lemmas use old definitions, ignore for now please

\begin{lemma}
For any $t\in\realsnonneg$, let $\mathcal{A}_{>t}$ be the algebra of subsets of $\Omega$ generated by all the elementary events $(X_s=x)= \{\omega\in\Omega\,:\,\omega(s)=x\}$, for all $x\in\states$ and all $s>t$. Consider any pairwise-disjoint sequence $\{A_i\}_{i\in\nats}$ such that $A_i\in\mathcal{A}_{>t}$ for all $i\in\nats$ and $A_i\cap A_j=\emptyset$ for all $i,j\in\nats$ with $i\neq j$, and for which $\cup_{i=1}^\infty A_i\in\mathcal{A}_{>t}$. Then, there is some $n\in\nats$ such that, for all $j>n$, it holds that $A_j=\emptyset$.
\end{lemma}
\begin{proof}
{\bf TODO}, but fairly trivial since $\mathcal{A}_{>t}$ is the algebra generated by all elementary events.
\end{proof}

\begin{lemma}\label{lem:stoch_process_sigma_add_on_algebra}
Let $P:\mathcal{C}^{\mathrm{SP}}\to\reals$ be a stochastic process, where $\mathcal{C}^{\mathrm{SP}}$ is defined as in Definition~\ref{def:stoch_process}. Then, for all $t\in\realsnonneg$ and all $C\in\mathcal{F}_{\leq t}$, the map $P(\cdot\,\vert\,C):\mathcal{A}_{>t}\to\reals$ is $\sigma$-additive on $\mathcal{A}_{>t}$, meaning that for every pairwise-disjoint sequence $\{A_i\}_{i\in\nats}$ such that $A_i\in\mathcal{A}_{>t}$ for all $i\in\nats$ and $A_i\cap A_j=\emptyset$ for all $i,j\in\nats$ with $i\neq j$, and for which $\cup_{i=1}^\infty A_i\in\mathcal{A}_{>t}$, it holds that
\begin{equation*}
P\left(\bigcup_{i=1}^\infty A_i\,\Big\vert\,C\right) = \sum_{i=1}^\infty P(A_i\,\vert\,C)\,.
\end{equation*}
\end{lemma}
\begin{proof}
Consider any $t\in\realsnonneg$, any $C\in\mathcal{F}_{\leq t}$, and any pairwise-disjoint sequence $\{A_i\}_{i\in\nats}$ in $\mathcal{A}_{>t}$ such that $\cup_{i=1}^\infty A_i\in\mathcal{A}_{>t}$. Then, by Lemma {\bf REF}, there is some $n\in\nats$ such that, for all $j>n$, it holds that $A_j=\emptyset$. Hence, we find that the claim reduces to
\begin{align*}
P\left(\bigcup_{i=1}^\infty A_i\,\Big\vert\,C\right) &= \sum_{i=1}^\infty P(A_i\,\vert\,C) \\
%P\left(\bigcup_{i=1}^n A_i\,\Big\vert\,C\right) &= \sum_{i=1}^n P(A_i\,\vert\,C) + \sum_{i=n+1}^\infty P(A_i\,\vert\,C) \\
P\left(\bigcup_{i=1}^n A_i\,\Big\vert\,C\right) &= \sum_{i=1}^n P(A_i\,\vert\,C) + \sum_{i=n+1}^\infty P(\emptyset\,\vert\,C) \\
P\left(\bigcup_{i=1}^n A_i\,\Big\vert\,C\right) &= \sum_{i=1}^n P(A_i\,\vert\,C)\,,
\end{align*}
which we know to be true from finite-additivity of $P(\cdot\,\vert\,C)$.

**** Maybe expand this last argument a bit by linking it to~\ref{def:coh_prob_3}.
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:boundednon-emptyandclosed}]
We only give the proof for $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$. The proof for $\smash{\overline{\partial}_{-}
{T^t_{t,\,x_u}}}$ is completely analogous. The proof for $\smash{\overline{\partial}
{T^t_{t,\,x_u}}}$ then follows trivially because a union of two bounded, non-empty and closed sets is always bounded, non-empty and closed itself.

We start by establishing the boundedness of $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$. Since $P$ is well-behaved, it follows from Definition~\ref{def:well-behaved} that there is some $B>0$ and $\delta>0$ such that
\begin{equation}\label{eq:boundedbyB}
(\forall 0<\Delta<\delta)
~
\norm{\frac{1}{\Delta}
(T^{t+\Delta}_{t,\,x_u}-I)}\leq B.
\end{equation}
Consider now any $Q\in\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$. Because of Equation~\eqref{eq:rightouterderivative}, $Q$ is the limit of a sequence of matrices $Q_k$, $k\in\nats$, defined by
\begin{equation}\label{eq:sequenceofQsinproof}
Q_k\coloneqq\frac{1}{\Delta_k}
(T^{t+\Delta_k}_{t,\,x_u}-I)
\text{~~for all $k\in\nats$}.
\end{equation}
Because of Equation~\eqref{eq:boundedbyB}, the norms $\norm{Q_k}$ of these matrices are eventually (for large enough $k$) bounded above by $B$. Hence, it follows that $\norm{Q}\leq B$. Since this is true for any $Q\in\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$, we find that $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$ is bounded.


In order to prove that $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$ is non-empty, we consider any sequence $\Delta_k\to0^+$, $k\in\nats$. The corresponding sequence of matrices $Q_k$, $k\in\nats$, as defined by Equation~\eqref{eq:sequenceofQsinproof}, is then bounded because $P$ is well-behaved---see Definition~\ref{def:well-behaved}---and therefore, it follows from the Bolzano-Weierstrass theorem that it has a convergent subsequence $Q_{k_i}$, $i\in\nats$, of which we denote the limit by $Q^*$. Hence, we have found a sequence $\Delta_{k_i}\to0^+$, $i\in\nats$, such that $Q_{k_i}\to Q^*$.
Since we know from Lemma~\ref{prop:rate_from_stochastic_matrix} that each of the matrices $Q_{k_i}$, $i\in\nats$, is a rate matrix, the limit $Q^*$ is also a rate matrix, which therefore clearly belongs to $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$.

We end by showing that $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$ is closed, or equivalently, that for any converging sequence $Q^*_k$, $k\in\nats$, of rate matrices in $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$, the limit point $Q^*\coloneqq\lim_{k\to+\infty}Q^*_k$ is again an element of $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$. Since the rate matrices $Q^*_k$ belong to the bounded set $\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$, their limit $Q^*$ is a (real-valued) rate matrix. For any $k\in\nats$, it now follows from Definition~\eqref{eq:rightouterderivative} that there is some $0<\Delta_k<\nicefrac{1}{k}$ such that $\norm{Q_k-Q^*_k}\leq\nicefrac{1}{k}$, with $Q_k$ defined as in Equation~\eqref{eq:sequenceofQsinproof}.
Since
\begin{equation*}
0\leq\lim_{k\to+\infty}\norm{Q^*-Q_k}\leq\lim_{k\to+\infty}\norm{Q^*-Q^*_k}+\lim_{k\to+\infty}\norm{Q^*_k-Q_k}=0,
\end{equation*}
we find that the sequence $Q_k$, $k\in\nats$, converges to $Q^*$: $\lim_{k\to+\infty}Q_k=Q^*$. Hence, because $\lim_{k\to+\infty}\Delta_k=0$, we conclude that $Q^*\in\smash{\overline{\partial}_{+}
{T^t_{t,\,x_u}}}$.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:outerderivativebehaveslikelimit}]
Fix any $\epsilon>0$.
Assume \emph{ex absurdo} that
\begin{equation*}
(\forall\delta>0)(\exists0<\Delta<\delta)
(\forall Q\in\overline{\partial}_{+}
{T^t_{t,\,x_u}})
\norm{\frac{1}{\Delta}
(T^{t+\Delta}_{t,\,x_u}-I)-Q}\geq\epsilon.
\end{equation*}
Clearly, this implies the existence of a sequence $\Delta_k\to0^+$, $k\in\nats$, such that
\begin{equation}\label{eq:boundednonelement}
\norm{Q_k-Q}\geq\epsilon
\text{~~for all $k\in\nats$ and all $Q\in\overline{\partial}_{+}
{T^t_{t,\,x_u}}$},
\end{equation}
with $Q_k$ defined as in Equation~\eqref{eq:sequenceofQsinproof}. As we know from the proof of Proposition~\ref{prop:boundednon-emptyandclosed}, the sequence $Q_k$, $k\in\nats$, has a convergent subsequence $Q_{k_i}$, $i\in\nats$, of which the limit $Q^*$ belongs to $\overline{\partial}_{+}
{T^t_{t,\,x_u}}$. Hence, since Equation~\eqref{eq:boundednonelement} implies that $\norm{Q^*-Q}\geq\epsilon$ for all $Q\in\overline{\partial}_{+}
{T^t_{t,\,x_u}}$, we find that $0=\norm{Q^*-Q^*}\geq\epsilon$. From this contradiction, it follows that there must be some $\delta_1>0$ such that Equation~\eqref{eq:outerderivativebehaveslikelimit1} holds for all $0<\Delta<\delta_1$. Similarly, using a completely analogous argument, we infer that there must be some $\delta_2>0$ such that Equation~\eqref{eq:outerderivativebehaveslikelimit2} holds for all $0<\Delta<\delta_1$. Now let $\delta\coloneqq\min\{\delta_1,\delta_2\}$.
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:cont_time_markov_chains}}

\begin{proof}[Proof of Proposition~\ref{prop:Markovhassystem}]
Consider any Markov chain $P\in\mprocesses$, with $\mathcal{T}_P$ its corresponding family of transition matrices. Then, for any $t,r,s\in\realsnonneg$ such that $t\leq r\leq s$, it follows from Definition~\ref{def:markov_property} that for all $x_t,x_r,x_s\in\states$,
\begin{equation*}
P(X_s=x_s\,\vert\,X_r=x_r,X_t=x_t) = P(X_s=x_s\,\vert\,X_r=x_r)\,.
\end{equation*}
Furthermore, because $P$ is a stochastic process, it follows from~\ref{def:coh_prob_6} that
\begin{align*}
P(X_s=x_s,X_r=x_r\,\vert\,X_t=x_t) &= P(X_s=x_s\,\vert\,X_r=x_r,X_t=x_t)P(X_r=x_r\,\vert\,X_t=x_t) \\
 &= P(X_s=x_s\,\vert\,X_r=x_r)P(X_r=x_r\,\vert\,X_t=x_t)\,,
\end{align*}
where the second equality used the Markov property. From~\ref{def:coh_prob_3}, it then follows that
\begin{equation*}
P(X_s=x_s\,\vert\,X_t=x_t) = \sum_{y\in\states} P(X_s=x_s,X_r=y\,\vert\,X_t=x_t)\,.
\end{equation*}
From the definition of $\mathcal{T}_P$ in Definition~\ref{def:trans_matrix}, it now follows that
\begin{equation*}
T_t^s = T_t^rT_r^s\,.
\end{equation*}
Furthermore, because $P$ is a stochastic process, it follows from Proposition~\ref{prop:stochasticprocess:simpleproperties} that $T_t^t=I$. Therefore, and because the $t,r,s\in\realsnonneg$ were arbitrary, $\mathcal{T}_P$ is a transition matrix system.

The fact that $\mathcal{T}_P$ is well-behaved if and only if $P$ is well-behaved follows immediately from Definition~\ref{def:trans_matrix} and Proposition~\ref{prop:stochasticprocess:simpleproperties}.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theo:uniqueMarkovchain}]
Let
\begin{multline*}
\mathcal{C}\coloneqq\{
(X_s=y,X_u=x_u)
\colon 
u\in\mathcal{U}_\emptyset,~s>u,~x_u\in\states^u,~y\in\states
\}\\
\cup
\{
(X_0=y,X_\emptyset=x_\emptyset)\colon y\in\states
\}
\end{multline*}
and consider a real-valued function $\tilde{P}$ on $\mathcal{C}$ that is defined by 
\begin{equation*}
\tilde{P}(X_s=y\vert X_u=x_u)
%=
%\tilde{P}(X_s=y\vert X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n})
\coloneqq
\begin{cases}
p(y)&\text{~if $u=\emptyset$}\\
T_{\max u}^s(x_{\max u},y)&\text{~otherwise}
\end{cases}
\text{~~~for all $(X_s=y,X_u=x_u)\in\mathcal{C}$.}
\end{equation*}


We first prove that $\tilde{P}$ is a coherent conditional probability on $\mathcal{C}$. So consider any $n\in\nats$ and, for all $i\in\{1,\dots,n\}$, choose $(A_i,C_i)=(X_{s_i}=y_i,X_{u_i}=x_{u_i})\in\mathcal{C}$ and $\lambda_i\in\reals$. We need to show that
\begin{equation}\label{eq:theo:uniqueMarkovchain:coh1}
\sup\left\{\sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0\right\}\geq0,
\end{equation}
with $C_0\coloneqq\cup_{i=1}^nC_i$.
Since every sequence $u_i$ is finite, there is some finite set $w=\{w_0,w_1,\dots,w_m\}\subset\reals_{\geq0}$ of time points, with $m\in\nats$, such that $0=w_0<w_1<\dots<w_m$ and, for all $i\in\{1,\dots,n\}$, $u_i\subseteq w$ and $s_i\in w$.
Let $P_w$ be the restriction of $\tilde{P}$ to $\mathcal{C}_w$, with $\mathcal{C}_w$ defined as in Lemma~\ref{lemma:simplechaincoherence}. Then since $P_w$ clearly satisfies the conditions of Lemma~\ref{lemma:simplechaincoherence}, it follows that $P_w$ is a coherent conditional probability. Because of Theorem~\ref{theo:coherentextendable}, this implies that $P_w$ is the restriction to $\mathcal{C}_w$ of some full conditional probability $\tilde{P}_w$ that, because of Corollary~\ref{corol:fullcoherent}, is coherent. Hence, we find that
\begin{equation}\label{eq:theo:uniqueMarkovchain:coh2}
\sup\left\{\sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(\tilde{P}_w(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0\right\}\geq0.
\end{equation}
By comparing Equations~\eqref{eq:theo:uniqueMarkovchain:coh1} and~\eqref{eq:theo:uniqueMarkovchain:coh2}, it follows that in order to prove that $\tilde{P}$ is coherent, it suffices to show that, for all $i\in\{1,\dots,n\}$, $\tilde{P}_w(A_i\vert C_i)=\tilde{P}(A_i\vert C_i)$. So fix any $i\in\{1,\dots,n\}$. If $u_i=\emptyset$, then $s_i=0=w_0$ and therefore $(A_i,C_i)\in\mathcal{C}_w$, which implies that $\tilde{P}_w(A_i\vert C_i)=P_w(A_i\vert C_i)=\tilde{P}(A_i\vert C_i)$. If $u_i\neq\emptyset$, then since $u_i\subseteq w$, $s_i\in w$ and $s_i>u_i$, it follows from Lemma~\ref{lemma:simplechainextend} that $\tilde{P}_w(A_i\vert C_i)=\tilde{P}(A_i\vert C_i)$. Hence, $\tilde{P}$ is coherent.

% \begin{equation*}
% \tilde{P}_w(A_i\vert C_i)
% =\tilde{P}_w(X_{s_i}=y_i\vert X_{u_i}=x_{u_i})
% =\tilde{P}_w(X_{s_i}=y_i\vert X_{t_0}=x_{0}, \dots, X_{t_n}=x_{n})
% =T_{t_n}^s(x_n,y)
% =
% =P_w(A_i\vert C_i)
% =\tilde{P}(A_i\vert C_i)
% \end{equation*}


Therefore, and because of Theorem~\ref{theo:coherentextendable}, $\tilde{P}$ can be extended to a full conditional probability $\tilde{P}^*$. If we now let $P$ be the restriction of $\tilde{P}^*$ to $\mathcal{C}^\mathrm{SP}$, then clearly, $P$ is a stochastic process that extends $\tilde{P}$, which implies that $P$ is a Markov chain 

**** {\bf ATTN}: Claim of Markov property maybe needs some elaboration?

such that $\mathcal{T}_P=\mathcal{T}$ and, for all $y\in\states$, $P(X_0=y)=p(y)$. Lemma~\ref{lemma:samepandTissameP} implies that this Markov chain is unique. If $\mathcal{T}$ is well-behaved, then since $\mathcal{T}_P=\mathcal{T}$, it follows from Proposition~\ref{prop:Markovhassystem} that $P$ is well-behaved.
\end{proof}

\begin{lemma}\label{lemma:simplechaincoherence}
Let $w=\{w_0,w_1,\dots,w_m\}\subset\reals_{\geq0}$ be a finite set of time points, with $m\in\nats_0$, such that $w_0<w_1<\dots<w_m$.
Let $P_w$ be a real-valued function on
\begin{equation*}
\mathcal{C}_w\coloneqq
\left\{
(X_{w_j}=y,X_u=x_u)
\colon 
j\in\{0,\dots,m\},~
u=\{w_0,\dots,w_{j-1}\},~
y\in\states,~
x_u\in\states^u
\right\}
\end{equation*}
such that, for any $j\in\{0,\dots,m\}$, $u=\{w_0,\dots,w_{j-1}\}$ and $x_u\in\states^u$, $P_w(X_{w_j}=\cdot\,\vert X_u=x_u)$ is a probability mass function on $\states$. Then $P_w$ is a coherent conditional probability on $\mathcal{C}_w$.
\end{lemma}
\begin{proof}
We provide a proof by induction. Assume that this statement is true for any $m<k$, with $k\in\nats_\emptyset$. We will show that this implies that it is also true for $m=k$.

Consider any $n\in\nats$ and, for all $i\in\{1,\dots,n\}$, choose $(A_i,C_i)\in\mathcal{C}_w$ and $\lambda_i\in\reals$. We need to show that
\begin{equation}\label{eq:lemma:simplechaincoherence:TB}
\sup\left\{\sum_{i=1}^n\lambda_i\ind{C_i}(\omega)\bigl(P_w(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0\right\}\geq0,
\end{equation}
with $C_0\coloneqq\cup_{i=1}^nC_i$. %Clearly, without loss of generality, we may assume that for any $i_1,i_2\in\{1,\dots,n\}$ such that $i_1\neq i_2$, $(A_{i_1},C_{i_1})\neq(A_{i_2},C_{i_2})$.

For any $i\in\{1,\dots,n\}$, since $(A_i,C_i)\in\mathcal{C}_w$, there is some $j_i\in\{0,\dots,m\}$ and, for all $\ell\in\{0,\dots,j_i\}$, some $z_{\ell,i}\in\states$ such that
\begin{equation*}
A_i=(X_{w_{j_i}}=z_{j_i,i})
\text{~~and~~}
C_i=(X_{w_{0}}=z_{0,i}, \dots, X_{w_{j_i-1}}=z_{j_i-1,i}).
\end{equation*}
Let $S=\left\{i\in\{1,\dots,n\}\colon j_i<m\right\}$. If $S\neq\emptyset$, then by the induction hypothesis, we know that
\begin{equation*}
\sup\left\{\sum_{i\in S}\lambda_i\ind{C_i}(\omega)\bigl(P_w(A_i\vert C_i)-\ind{A_i}(\omega)\bigr)~\Bigg\vert~\omega\in C_0^*\right\}\geq0,
\end{equation*}
with $C_0^*\coloneqq\cup_{i\in S}C_i$. Since, for all $i\in S$, $\ind{A_i}(\omega)$ and $\ind{C_i}(\omega)$ only depend on the value of $\omega$ in the finite set of time points $w$, the expression in this supremum can take only a finite number of values, and therefore, it is in fact a maximum. Hence, it follows that there is some $\omega^*\in C_0^*$ such that
\begin{equation}\label{eq:lemma:simplechaincoherence:supremumreached}
\sum_{i\in S}\lambda_i\ind{C_i}(\omega^*)\bigl(P_w(A_i\vert C_i)-\ind{A_i}(\omega^*)\bigr)\geq0.
\end{equation}
If $S=\emptyset$, then let $\omega^*$ be any element of $C_0$. Equation~\eqref{eq:lemma:simplechaincoherence:supremumreached} is then trivially satisfied. Hence, in all cases, we have found some $\omega^*\in C_0$ that satisfies Equation~\eqref{eq:lemma:simplechaincoherence:supremumreached}.


Let $C^*\coloneqq\cap_{1\leq \ell<m}(X_{w_\ell}=\omega^*(w_\ell))$ and $S^*\coloneqq\{i\in\{1,\dots,n\}\colon C_i=C^*\}$. Then by the assumptions of this lemma, there is some probability mass function $p$ on $\states$ such that, for all $x\in\states$, $P_w(X_{w_m}=x\vert C^*)=p(x)$. 
For all $x\in\states$, let $\lambda_x\coloneqq\sum_{\{i\in S^*\colon z_{m,i}=x\}}\lambda_i$.
Since $p$ is a probability mass function, it then follows that
\begin{equation*}
\sum_{i\in S^*}\lambda_i P_w(A_i\vert C^*)
=
\sum_{x\in\states}
\lambda_x p(x)
\geq
\sum_{x\in\states} \left(\min_{y\in\states}\lambda_y\right) p(x)
=
\left(\min_{y\in\states}\lambda_y\right)\sum_{x\in\states}p(x)
=\min_{y\in\states}\lambda_y.
\end{equation*}
Now let $y^*$ be any element of $\states$ such that $\min_{y\in\states}\lambda_y=\lambda_{y^*}$ (since $\states$ is finite, this is always possible) and let $\omega^{**}$ be any path in $\Omega$ such that $\omega^{**}\in C^*$ and $\omega^{**}(w_m)=y^*$. Then
\begin{equation*}
\sum_{i\in S^*}\lambda_i(\omega^*)\bigl(P_w(A_i\vert C_i)-\ind{A_i}(\omega^{**})\bigr)
\geq
\min_{y\in\states}\lambda_y
-\sum_{i\in S^*}\lambda_i\ind{A_i}(\omega^{**})
=\lambda_{y^*}-\lambda_{y^*}=0.
\end{equation*}

Let $S^{**}\coloneqq\{1,\dots,n\}\setminus(S\cup S^*)$. Since $\omega^{**}\in C^*$, we find that $\ind{C_i}(w^{**})=\ind{C_i}(w^{*})$ and $\ind{A_i}(w^{**})=\ind{A_i}(w^{*})$ for all $i\in S$, that $\ind{C_i}(w^{**})=1$ for all $i\in S^{*}$, and that $\ind{C_i}(w^{**})=0$ for all $i\in S^{**}$. Hence, it follows from Equation~\eqref{eq:lemma:simplechaincoherence:supremumreached} that
\begin{equation*}
\sum_{i=1}^n\lambda_i\ind{C_i}(\omega^{**})\bigl(P_w(A_i\vert C_i)-\ind{A_i}(\omega^{**})\bigr)
\geq
\sum_{i\in S^*}\lambda_i\bigl(P_w(A_i\vert C^*)-\ind{A_i}(\omega^{**})\bigr).
\end{equation*}
By combining this inequality with the previous one, we find that in order to show that Equation~\eqref{eq:lemma:simplechaincoherence:TB} holds, it suffices to prove that $\omega^{**}\in C_0$. 

In order to prove this, it suffices to notice that the question of whether or not a path $\omega\in\Omega$ belongs to $C_0$, only depends on the values $\omega(t)$ of $\omega$ at time points $t\in\{w_0,\dots,w_{m-1}\}$. Indeed, since we infer from $\omega^{**}\in C^*$ that the value of $\omega^*$ and $\omega^{**}$ at these time points is the same, and because $\omega^*\in C_0$, this implies that $\omega^{**}\in C_0$.
\end{proof}

\begin{lemma}\label{lemma:simplechainextend}
Let $w=\{w_0,w_1,\dots,w_m\}\subset\reals_{\geq0}$ be a finite set of time points, with $m\in\nats_0$, such that $w_0<w_1<\dots<w_m$. Let $\mathcal{T}$ be a transition matrix system and let $\tilde{P}_w$ be any full conditional probability such that for all $j\in\{1,\dots,m\}$ and $x_{w_{\ell}}\in\states$, $\ell\in\{0,\dots,j\}$:
\begin{equation*}
\tilde{P}_w(X_{w_j}=x_{w_j}\vert X_{w_0}=x_{w_0},\dots,X_{w_{j-1}}=x_{w_{j-1}})=T_{w_{j-1}}^{w_j}(x_{w_{j-1}},x_{w_j}).
\end{equation*}
Then for any $s\in w$ and $u\subseteq w$ such that $s>u$ and $u\neq\emptyset$, any $y\in\states$ and any $x_u\in\states^u$, we have that
\begin{equation*}
\tilde{P}_w(X_s=y\vert X_u=x_u)
=T_{\max u}^s(x_{\max u},y).
\end{equation*}
\end{lemma}
\begin{proof}
Since $\emptyset\neq u\subseteq w$, $s\in w$ and $s>u$, it follows that there is some $j\in\{1,\dots,m\}$ such that $s=w_j$ and $u\subseteq\{w_0,\dots,w_{j-1}\}$.

We provide a proof by induction. If $s=w_1$, then $u=\{w_0\}$, and therefore, the result follows trivially from the assumptions in this lemma. Assume now that the result is true for $s=w_j$, with $1\leq j<m$. We will prove that this implies that it is also true for $s=w_{j+1}$. We consider two cases: $\max u=w_j$ and $\max u<w_j$.

If $\max u=w_j$, then with $v\coloneqq\{w_0,\dots,w_j\}\setminus u$:
\begin{align*}
\tilde{P}_w(X_{w_{j+1}}=y\vert X_u=x_u)
&=\sum_{z_{v}\in\states^{v}}\tilde{P}_w(X_{w_{j+1}}=y, X_{v}=z_{v}\vert X_u=x_u)\\
&=\sum_{z_{v}\in\states^{v}}
\tilde{P}_w(X_{w_{j+1}}=y\vert X_u=x_u, X_{v}=z_{v})
\tilde{P}_w(X_{v}=z_{v}\vert X_u=x_u)\\
&=\sum_{z_{v}\in\states^{v}}
T_{\max u}^{w_{j+1}}(x_{\max u},y)
\tilde{P}_w(X_{v}=z_{v}\vert X_u=x_u)\\[-1mm]
&\quad\quad\quad\quad\quad\quad
=T_{\max u}^{w_{j+1}}(x_{\max u},y)
\sum_{z_{v}\in\states^{v}}
\tilde{P}_w(X_{v}=z_{v}\vert X_u=x_u)\\[-1mm]
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad~~~
=T_{\max u}^{w_{j+1}}(x_{\max u},y),
\end{align*}
where the first equality follows from~\ref{def:coh_prob_3}, the second equality follows from \ref{def:coh_prob_6}, the third equality follows from the assumptions in this lemma and the fact that $\max u=w_j$, and the last equality follows from \ref{def:coh_prob_3} and~\ref{def:coh_prob_5}.

If $\max u<w_j$, then with $v\coloneqq\{w_0,\dots,w_{j-1}\}\setminus u$:
\begin{align*}
&\tilde{P}_w(X_{w_{j+1}}=y\vert X_u=x_u)\\[1,5mm]
&=\sum_{z_{w_j}\in\states}
\sum_{z_{v}\in\states^{v}}
\tilde{P}_w(X_{w_{j+1}}=y, X_{w_j}=z_{w_j}, X_v=z_v\vert X_u=x_u)\\
&=\sum_{z_{w_j}\in\states}
\sum_{z_{v}\in\states^{v}}
\tilde{P}_w(X_{w_{j+1}}=y\vert X_u=x_u, X_{w_j}=z_{w_j}, X_v=z_v)\\[-4mm]
&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad~\,
\tilde{P}_w(X_v=z_v\vert X_u=x_u, X_{w_j}=z_{w_j})
\tilde{P}_w(X_{w_j}=z_{w_j}\vert X_u=x_u)\\[4mm]
&=\sum_{z_{w_j}\in\states}
\sum_{z_{v}\in\states^{v}}
T_{w_j}^{w_{j+1}}(z_{w_j},y)
\tilde{P}_w(X_v=z_v\vert X_u=x_u, X_{w_j}=z_{w_j})
\tilde{P}_w(X_{w_j}=z_{w_j}\vert X_u=x_u)\\
&=\sum_{z_{w_j}\in\states}
\sum_{z_{v}\in\states^{v}}
T_{w_j}^{w_{j+1}}(z_{w_j},y)
\tilde{P}_w(X_v=z_v\vert X_u=x_u, X_{w_j}=z_{w_j})
T_{\max u}^{w_{j}}(x_{\max u},z_{w_j})\\
&=\sum_{z_{w_j}\in\states}
T_{w_j}^{w_{j+1}}(z_{w_j},y)
T_{\max u}^{w_{j}}(x_{\max u},z_{w_j})
\sum_{z_{v}\in\states^{v}}
\tilde{P}_w(X_v=z_v\vert X_u=x_u, X_{w_j}=z_{w_j})
\\
&=\sum_{z_{w_j}\in\states}
T_{w_j}^{w_{j+1}}(z_{w_j},y)
T_{\max u}^{w_{j}}(x_{\max u},z_{w_j})
=T_{\max u}^{w_{j+1}}(x_{\max u},y),
\end{align*}
where the first equality follows from~\ref{def:coh_prob_3}, the second equality follows from \ref{def:coh_prob_6}, the third equality follows from the assumptions in this lemma, the fourth equality follows from the induction hypothesis, the sixth equality follows from \ref{def:coh_prob_3} and~\ref{def:coh_prob_5}, and the last equality follows from Equation~\eqref{eq:transmatrixproduct}.
\end{proof}

\begin{lemma}\label{lemma:samepandTissameP}
Consider two Markov chains $P_1,P_2\in\mprocesses$ such that $\mathcal{T}_{P_1}=\mathcal{T}_{P_2}$ and, for all $y\in\states$, $P_1(X_0=y)=P_2(X_0=y)$. Then $P_1=P_2$.
\end{lemma}
\begin{proof}
Let $\mathcal{T}\coloneqq\mathcal{T}_{P_1}=\mathcal{T}_{P_2}$ be the common transition matrix system of $P_1$ and $P_2$ and let $p$ be their common initial probability mass function, as defined by $p(y)\coloneqq P_1(X_0=y)=P_2(X_0=y)$ for all $y\in\states$. Let $\tilde{P}$ be a real-valued function on $\mathcal{C}$, with $\mathcal{C}$ and $\tilde{P}$ defined as in the proof of Theorem~\ref{theo:uniqueMarkovchain}. It then follows from Definition~\ref{def:markov_property} that the restriction of $P_1$ and $P_2$ to $\mathcal{C}$ is equal to $\tilde{P}$. Furthermore, for any $s>0$, $y\in\states$ and $j\in\{1,2\}$, we find that
\begin{align*}
P_j(X_s=y)
=\sum_{x\in\states}P_j(X_s=y, X_0=x)
&=\sum_{x\in\states}P_j(X_s=y\vert X_0=x)P_j(X_0=x)\\
&=\sum_{x\in\states}\tilde{P}(X_s=y\vert X_0=x)\tilde{P}(X_0=x).
\end{align*}
Hence, the restrictions of $P_1$ and $P_2$ to
\begin{align*}
\mathcal{C}^*
\coloneqq&\mathcal{C}\cup
\{
(X_s=y,X_\emptyset=x_\emptyset)
\colon 
s\in\reals_{>0},~y\in\states
\}\\
=&\{
(X_s=y,X_u=x_u)
\colon 
u\in\mathcal{U},~s\in\reals_{\geq0},~s>u,~x_u\in\states^u,~y\in\states
\}
\end{align*}
are identical. We denote this common restriction by $\tilde{P}^*$.

Consider now any $(A,X_u=x_u)\in\mathcal{C}^\mathrm{SP}$. Then since $A\in\mathcal{A}_u$, there is some finite set of time points $v=\{v_1,v_2,\dots,v_n\}\subseteq\reals_{\geq0}$, with $n\in\nats_\emptyset$, such that $\max u<v_1<v_2<\dots<v_n$, and some set $S\subseteq\states^{u\cup v}$ such that $A=\cup_{z_{u\cup v}\in S}(X_{u\cup v}=z_{u\cup v})$. 
Let $S_v\coloneqq\{s_v\in\states^v\colon (x_u,z_v)\in S\}$.
For any $j\in\{1,2\}$, we then find that
\begin{align*}
P_j(A\vert X_u=x_u)
&=\sum_{z_{u\cup v}\in S}
P_j(X_{u\cup v}=z_{u\cup v}\vert X_u=x_u)\\
%&=\sum_{z_{v}\in S_v}
%P_1(X_{u}=x_{u}, X_v=z_v\vert X_u=x_u)\\
%&=\sum_{z_{v}\in S_v}
%P_1(X_v=z_v\vert X_u=x_u)\\
&=\sum_{z_{v}\in S_v}
P_j(X_{v_1}=z_{v_1}, X_{v_2}=z_{v_2}, \dots, X_{v_n}=z_{v_n}\vert X_u=x_u)\\[-1mm]
&=\sum_{z_{v}\in S_v}
\,\,
\prod_{i=1}^n
\,\,
P_j(X_{v_i}=z_{v_i}\vert X_u=x_u, X_{v_1}=z_{v_1}, \dots, X_{v_{i-1}}=z_{v_{i-1}})\\
&=\sum_{z_{v}\in S_v}
\,\,
\prod_{i=1}^n
\,\,
\tilde{P}^*(X_{v_i}=z_{v_i}\vert X_u=x_u, X_{v_1}=z_{v_1}, \dots, X_{v_{i-1}}=z_{v_{i-1}}),
\end{align*}
which implies that $P_1(A\vert X_u=x_u)=P_2(A\vert X_u=x_u)$. Since this is the case for any $(A,X_u=x_u)\in\mathcal{C}^\mathrm{SP}$, it follows that $P_1=P_2$.
\end{proof}

\begin{proof}[Proof of Corollary~\ref{cor:rate_has_unique_homogen_markov_process}]
Since we know from Proposition~\ref{prop:systemQ} that $\mathcal{T}_Q$ is a well-behaved transition matrix system, it follows from Theorem~\ref{theo:uniqueMarkovchain} that there is a unique Markov chain $P\in\mprocesses$ such that $\mathcal{T}_P=\mathcal{T}_Q$ and $P(X_0)=p(X_0)$, and that this Markov chain is furthermore well-behaved. Since it---trivially---follows from Definition~\ref{def:systemfromQ} that $\mathcal{T}_Q$ satisfies Equation~\eqref{eq:homogeneousMarkov}, Definition~\ref{def:homogeneousMarkov} implies that $P$ is homogeneous.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theo:homogeneoushasQ}]
Because of Proposition~\ref{prop:boundednon-emptyandclosed}, we know that $\overline{\partial}_{+}
{T^0_{0}}$ is a non-empty bounded set of rate matrices, which implies that there is some real $B>0$ such that $\norm{Q'}\leq B$ for all $Q'\in\overline{\partial}_{+}
{T^0_{0}}$. Let $Q$ be any of element of $\overline{\partial}_{+}
{T^0_{0}}$.


Fix any $c\geq0$, $\epsilon>0$ and $\delta>0$. 
It then follows from Proposition~\ref{prop:outerderivativebehaveslikelimit} and~\ref{N:homogeneous} that there is some $\delta^*>0$ such that
\begin{equation}
\label{eq:homogeneoushasQ1}
(\forall 0<\Delta^*<\delta^*)
~
(\exists Q^*\in\overline{\partial}_{+}
{T^0_{0}})
~
\norm{T_0^{\Delta^*}-(I+\Delta^*Q^*)}<\Delta^*\epsilon.
\end{equation}
Furthermore, because of Equation~\eqref{eq:rightouterderivative} and~\ref{N:homogeneous}, there is some $0<\Delta<\min\{\delta,\delta^*\}$ such that
\begin{equation}
\label{eq:homogeneoushasQ2}
\norm{T^{\Delta}_{0}-(I+\Delta Q)}<\Delta\epsilon.
\end{equation}
If we now define $n\coloneqq\lfloor\nicefrac{c}{\Delta}\rfloor$ and $d\coloneqq c-n\Delta$, then $n\Delta\leq c<(n+1)\Delta$ and therefore also $0\leq d<\Delta$. Because of Proposition~\ref{prop:Markovhassystem}, Equation~\eqref{eq:transmatrixproduct} and Definition~\ref{def:homogeneousMarkov}, we know that
\begin{equation*}
T_0^c=\left(
\prod_{j=1}^{n}
T_{(j-1)\Delta}^{j\Delta}
\right)
T_{n\Delta}^c
=\left(T_0^{\Delta}\right)^{n}
T_0^{d}
\end{equation*}
and therefore, it follows from Lemma~\ref{lemma:recursive} that
\begin{equation}
\label{eq:homogeneoushasQ3}
\norm{
	e^{Qc}-T_0^c
}
=
\norm{
\left(T_0^{\Delta}\right)^{n}
T_0^{d}
-
\left(
e^{Q\Delta}
\right)^{n}
e^{Qd}
}
\leq
n\norm{T_0^{\Delta}-e^{Q\Delta}}
+\norm{T_0^{d}-e^{Qd}}.
\end{equation}
From Equation~\eqref{eq:homogeneoushasQ2} and Lemma~\ref{lemma:linearpartofexponential}, we infer that
\begin{equation}
\label{eq:homogeneoushasQ4}
\norm{T_0^{\Delta}-e^{Q\Delta}}
\leq
\norm{T_0^{\Delta}-(I+\Delta Q)}
+
\norm{(I+\Delta Q)-e^{Q\Delta}}
\leq
\Delta\epsilon
+
\Delta^2\norm{Q}^2.
\end{equation}
Since $d<\Delta<\delta^*$, we infer from Equation~\eqref{eq:homogeneoushasQ1} that there is some $Q^*\in\overline{\partial}_{+}
{T^0_{0}}$ such that $\norm{T_0^{d}-(I+d Q^*)}<d\epsilon$. Hence, also using Lemma~\ref{lemma:linearpartofexponential}, we find that
\begin{align}
\norm{T_0^{d}-e^{Qd}}
&\leq
\norm{T_0^{d}-(I+d Q^*)}
+
\norm{(I+d Q^*)-(I+d Q)}
+
\norm{(I+d Q)-e^{Qd}}\notag\\
&\leq
d\epsilon+d\norm{Q^*-Q}
+d^2\norm{Q}^2
\leq
d\epsilon+d\norm{Q^*}
+d\norm{Q}
+d^2\norm{Q}^2.\label{eq:homogeneoushasQ5}
\end{align}
By combining Equations~\eqref{eq:homogeneoushasQ3}, \eqref{eq:homogeneoushasQ4} and~\eqref{eq:homogeneoushasQ5}, it follows that
\begin{equation*}
\norm{
	e^{Qc}-T_0^c
}
\leq
n\Delta\epsilon
+
n\Delta^2\norm{Q}^2
+
d\epsilon
+d\norm{Q^*}
+d\norm{Q}
+d^2\norm{Q}^2.
\end{equation*}
Taking into account that $\norm{Q}\leq B$, $\norm{Q^*}\leq B$, $n\Delta\leq c$ and $d<\Delta<\delta$, this implies that
\begin{equation*}
\norm{
	e^{Qc}-T_0^c
}
\leq
c\epsilon
+
c\delta B^2
+
\delta\epsilon
+2\delta B
+\delta^2 B^2.
\end{equation*}
Since this is true for any $\epsilon>0$ and $\delta>0$, it follows that $\norm{e^{Qc}-T_0^c}\leq0$, which implies that $T_0^c=e^{Qc}$. Since this is true for all $c\geq0$, it follows from Definition~\ref{def:homogeneousMarkov} that
\begin{equation}\label{eq:homogeneoushasQ6}
T_t^s=T_0^{s-t}=e^{Q(s-t)}
\text{~~for all $0\leq t\leq s$,}
\end{equation}
or equivalently, that $\mathcal{T}_P=\mathcal{T}_Q$.

Finally, we prove that $Q$ is unique. Assume \emph{ex absurdo} that this is not the case, or equivalently, that there are rate matrices $Q_1$ and $Q_2$, with $Q_1\neq Q_2$, such that $\mathcal{T}_P=\mathcal{T}_{Q_1}$ and $\mathcal{T}_P=\mathcal{T}_{Q_2}$. It then follows from Definition~\ref{def:systemfromQ} that $\partial_{+}{T^0_{0}}=Q_1$ and $\partial_{+}{T^0_{0}}=Q_2$, which implies that $Q_1=Q_2$. From this contradiction, it follows $Q$ is indeed unique.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:concat_restr_trans_mat_systems_is_system}]
Clearly, $\mathcal{T}^{[t,s]}$ is a family of transition matrices, and in particular, for all $\tau,\sigma\in[t,s]$ such that $\tau\leq \sigma$, there is a transition matrix $T_\tau^\sigma\in\mathcal{T}^{[t,s]}$. Furthermore, for all $q\in[t,s]$, we have that either $q\in[t,r]$ or $q\in[r,s]$. In either case, we have that $T_q^q=I$, because either $T_q^q\in\mathcal{T}^{[t,r]}$ or $T_q^q\in\mathcal{T}^{[r,s]}$. It remains to show that for all $\tau,q,\sigma\in[t,s]$ with $\tau\leq q\leq\sigma$, it holds that
\begin{equation*}
T_\tau^\sigma = T_\tau^qT_q^\sigma\,.
\end{equation*}
If both $\tau,\sigma\in[t,r]$ or if both $\tau,\sigma\in[r,s]$, this clearly holds. Therefore, suppose that $\tau\in[t,r]$ and $\sigma\in[r,s]$. Suppose furthermore that $q\in[t,r]$. Then, from the definition of the concatenation operator, we have that $T_q^\sigma=T_q^rT_r^\sigma$. Because $\tau,q,r\in[t,r]$, we know that $T_\tau^qT_q^r=T_\tau^r$, and hence, by the definition of the concatenation operator,
\begin{equation*}
T_\tau^qT_q^\sigma = T_\tau^qT_q^rT_r^\sigma = T_\tau^rT_r^\sigma = T_\tau^\sigma\,.
\end{equation*}
An exactly analogous argument proves the case for $q\in[r,s]$. Therefore, we conclude that $\mathcal{T}^{[t,s]}$ is a restricted transition matrix system.

It remains to show that if $\mathcal{T}^{[t,r]}$ and $\mathcal{T}^{[r,s]}$ are both well-behaved, that then $\mathcal{T}^{[t,s]}$ is also well-behaved. We need to show that for all $q\in[t,s]$, it holds that
\begin{equation*}
\limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(T_q^{q+\Delta} - I\right)} < +\infty,\quad\text{and,}\quad \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(T_{q-\Delta}^{q} - I\right)} < +\infty\,.
\end{equation*}
Because this clearly holds for all $q\in[t,r)$ and all $q\in(r,s]$, the interesting case is to show that this holds for $q=r$. However, for all $\Delta\in\realspos$ we have that $T_r^{r+\Delta}\in\mathcal{T}^{[r,s]}$, and $T_{r-\Delta}^{r}\in\mathcal{T}^{[t,r]}$. Because both $\mathcal{T}^{[t,r]}$ and $\mathcal{T}^{[r,s]}$ are well-behaved, we find that $\mathcal{T}^{[t,s]}$ is also well-behaved at $q=r$. Hence, $\mathcal{T}^{[t,s]}$ is well-behaved.
\end{proof}

\begin{lemma}\label{lemma:nonhomogen_trans_mat_system}
Let $Q_t$ be a left-continuous, piecewise-constant function that gives for each time point $t\in\realsnonneg$ a rate matrix $Q_t\in\mathcal{R}$, such that $Q_t$ takes different values on at most a finite number of intervals. Specifically, let $Q_t$ be such that there exists some ordered $u\in\mathcal{U}$ with $u=t_0,\ldots,t_n$ and rate matrices $\tilde{Q}_1,\ldots,\tilde{Q}_n\in\mathcal{R}$ such that, for all $t\in\realsnonneg$,
\begin{equation*}
Q_t = \tilde{Q}_i\,,\quad\text{if $t\in(t_{i-1},t_{i}]$, for all $i\in\{1,\ldots,n\}$}\,,
\end{equation*}
and $Q_t=\tilde{Q}_1$ if $t\leq t_0$, and $Q_t=\tilde{Q}_n$ if $t>t_n$. For notational convenience, let $t_{-1}\coloneqq-1$, $t_{n+1}\coloneqq +\infty$, $\tilde{Q}_0\coloneqq \tilde{Q}_1$, and $\tilde{Q}_{n+1}\coloneqq \tilde{Q}_n$. Then, for all $t\in\realsnonneg$, it holds that
\begin{equation*}
Q_t = \tilde{Q}_i\,,\quad\text{if $t\in(t_{i-1},t_i]$, for all $i\in\{0,\ldots,n+1\}$.}
\end{equation*}

Consider now a family $\mathcal{T}_{Q_t}$ of matrices $T_t^s$, defined recursively for all $t,s\in\realsnonneg$ with $t\leq s$, such that
\begin{equation*}
T_t^s \coloneqq \left\{\begin{array}{ll}
e^{Q_s(s-t)} & \text{if $\bigl(\exists i\in\{0,\ldots,n+1\}\,:\,t,s\in[t_{i-1},t_i]\bigr)$, and} \\
T_t^{t_{i-1}}T_{t_{i-1}}^s & \text{where $i\in\{1,\ldots,n+1\}$ is such that $s\in(t_{i-1},t_i]$, otherwise.}
\end{array}\right.
\end{equation*}
Then, $\mathcal{T}_{Q_t}$ is a well-behaved transition matrix system.
\end{lemma}
\begin{proof}
For any $T_t^s\in\mathcal{T}_{Q_t}$, it is clear that $T_t^s$ is a transition matrix if $t$ and $s$ coincide on some interval $[t_{i-1},t_i]$, with $i\in\{0,\ldots,n+1\}$, because then $T_t^s=e^{Q_s(s-t)}$. If they do not coincide, say $t\in[t_{i-1},t_i]$ and $s\in[t_{j-1},t_j]$ for some $i,j\in\{0,\ldots,n+1\}$ with $i<j$, by recursion, we find that
\begin{equation*}
T_t^s = T_t^{t_i}T_{t_i}^{t_{i+1}}\cdots T_{t_{j-2}}^{t_{j-1}}T_{t_{j-1}}^s\,.
\end{equation*}
Note that on the right-hand side of this equality, for each factor $T_a^b$, the time points $a$ and $b$ coincide on some interval, and hence each $T_a^b$ is a transition matrix. Hence, the right-hand side of this equality is a composition of transition matrices, and hence $T_t^s$ is a transition matrix. Therefore, $\mathcal{T}_{Q_t}$ is clearly a family of transition matrices.

Furthermore, it is clear that for any $T_t^t\in\mathcal{T}_{Q_t}$, it holds that $T_t^t=I$, because $t$ and $t$ trivially coincide on some interval, so that we find $T_t^t=e^{Q_t\cdot 0}=I$. Hence, for $\mathcal{T}_{Q_t}$ to be a transition matrix system, it remains to show that all $T_t^s\in\mathcal{T}_{Q_t}$ satisfy Equation~\eqref{eq:transmatrixproduct}.

If $t$ and $s$ coincide on some interval, Equation~\eqref{eq:transmatrixproduct} trivially holds for $T_t^s$. If they do not coincide, a similar factorization as found above yields the same result. Hence, $\mathcal{T}_{Q_t}$ is a transition matrix system. 

It remains to show that $\mathcal{T}_{Q_t}$ is well-behaved, i.e., that it also satisfies Equation~\eqref{eq:wellbehavedtransitionmatrix}.
Note that in the first limit expression of~\eqref{eq:wellbehavedtransitionmatrix}, for small enough $\Delta$, the time points $t$ and $t+\Delta$ coincide on some interval. On this interval, it holds that there is some $Q\in\rateset$ such that $Q_{t+\Delta}=Q$ for all $\Delta>0$ such that $t$ and $t+\Delta$ coincide. Hence, we find that
\begin{equation*}
\lim_{\Delta\to0^+}\frac{1}{\Delta}\norm{T_t^{t+\Delta}-I} = \lim_{\Delta\to0^+}\frac{1}{\Delta}\norm{e^{Q_{t+\Delta}\cdot\Delta}-I} = \lim_{\Delta\to0^+}\frac{1}{\Delta}\norm{e^{Q\cdot\Delta}-I} = \norm{Q} < +\infty\,,
\end{equation*}
where the last equality used the well-known derivative of the matrix exponential. Similarly, for the second limit expression of~\eqref{eq:wellbehavedtransitionmatrix}, for small enough $\Delta$, it holds that $t-\Delta$ and $t$ coincide on some interval. Hence
\begin{equation*}
\lim_{\Delta\to0^+}\frac{1}{\Delta}\norm{T_{t-\Delta}^{t}-I} = \lim_{\Delta\to0^+}\frac{1}{\Delta}\norm{e^{Q_t\cdot \Delta}-I}=\norm{Q_t}<+\infty\,.
\end{equation*}
Therefore, $\mathcal{T}_{Q_t}$ is well-behaved.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:continuous_rate_matrix_has_process}]
By Lemma~\ref{lemma:nonhomogen_trans_mat_system}, $\mathcal{T}_{Q_t}$ is a well-behaved transition matrix system. Therefore, by Theorem~{\bf REF}, there exists a well-behaved continuous-time Markov chain $P\in\wmprocesses$ such that $\mathcal{T}_P=\mathcal{T}_{Q_t}$.
\end{proof}

\begin{lemma}\label{lemma:nonhomogeneous_in_process_set}
Let $P\in\wmprocesses$ be such that there exists a left-continuous, piecewise-constant function $Q_t$ such that $\mathcal{T}_P=\mathcal{T}_{Q_t}$, where $\mathcal{T}_{Q_t}$ is defined as in Lemma~\ref{lemma:nonhomogen_trans_mat_system}. Then, for any set of rate matrices $\rateset$ for which it holds that $Q_t\in\rateset$ for all $t\in\realsnonneg$, it holds that $P\in\wmprocesses_\rateset$.
\end{lemma}
\begin{proof}
Note that, by the definition of $\mathcal{T}_{Q_t}$, it holds for all $t\in\realsnonneg$ that $\partial_+T_t^t$ and $\partial_-T_t^t$ exist, and that they satisfy $\partial_+T_t^t,\partial_-T_t^t\in\rateset$. Therefore, and because $P$ is well-behaved, by Corollary~\ref{corol:outersingleton} we have that $\smash{\overline{\partial}}_+T_t^t=\{\partial_+T_t^t\}$ and $\smash{\overline{\partial}}_-T_t^t=\{\partial_-T_t^t\}$. Hence, we find that
\begin{equation*}
\smash{\overline{\partial}}T_t^t = \smash{\overline{\partial}}_+T_t^t\cup \smash{\overline{\partial}}_-T_t^t = \{\partial_+T_t^t, \partial_-T_t^t\}\,,
\end{equation*}
from which it follows that, for all $t\in\realsnonneg$, it holds that $\smash{\overline{\partial}}T_t^t\subseteq\rateset$. Therefore, by Definition~\ref{def:markov_process_set_new}, we find that $P\in\wmprocesses_\rateset$.
\end{proof}

\begin{lemma}\label{lemma:linearpartofexponential}
Consider any $Q\in\mathcal{R}$ and any $\Delta\geq0$. Then
\begin{equation*}
\norm{e^{Q\Delta}-(I+\Delta Q)}\leq
\Delta^2\norm{Q}^2.
\end{equation*}
\end{lemma}
\begin{proof}
To avoid trivialities, we assume that $\Delta\neq 0$ and $\norm{Q}\neq 0$. 

Recall the $\epsilon-\delta$ limit expression for the matrix exponential, given by Equation~\eqref{eq:matrix_exp_limit}. Now, consider any $\epsilon\in\realspos$, and let $\delta^*\coloneqq\min\{\nicefrac{1}{\norm{Q}},\delta\}$, where $\delta$ satisfies Equation~\eqref{eq:matrix_exp_limit}. Take any $u\in\mathcal{U}_{[0,\Delta]}$ such that $\sigma(u)<\delta^*$. Then, clearly,
\begin{align*}
\norm{e^{Q\Delta}-(I+\Delta Q)} &\leq \norm{e^{Q\Delta} - \prod_{i=1}^n(I+\Delta_iQ)} + \norm{\prod_{i=1}^n(I+\Delta_iQ) - (I+\Delta Q)} \\
 &< \norm{\prod_{i=1}^n(I+\Delta_iQ) - (I+\Delta Q)} + \epsilon\,.
\end{align*}
Furthermore, because $Q$ is a rate matrix, it is easily verified that $Q$ satisfies~\ref{LR:constantzero}--\ref{LR:nondiagpos}. Hence, $Q$ is also a lower transition rate operator. Therefore, and because $\sigma(u)<\delta^*\leq\nicefrac{1}{\norm{Q}}$, it follows from Lemma~\ref{lemma:justthelinearpart} that
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_iQ) - (I+\Delta Q)} \leq \Delta^2\norm{Q}^2\,.
\end{equation*}
Hence, we find
\begin{equation*}
\norm{e^{Q\Delta}-(I+\Delta Q)} < \Delta^2\norm{Q}^2 + \epsilon\,.
\end{equation*}
Because this holds for any $\epsilon\in\realspos$, the statement in the lemma  follows.
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:iCTMC}}

\begin{lemma}\label{lemma:bound_on_linear_approx_partition}
Consider any $P\in\wprocesses_\rateset$, any $0<t<s$ and any $x_u$. Then for all $\epsilon>0$ and $\delta>0$, there is some $v\in\mathcal{U}_{[t,s]}$ such that $\sigma(v)<\delta$ and, for all $i\in\{0,\dots,n-1\}$:
\begin{equation*}
(\exists Q\in\rateset)
~
\norm{
T^{t_{i+1}}_{t_i,\,x_u}-(I+\Delta_{i+1}Q)
}<\Delta_{i+1}\epsilon
\end{equation*}
\end{lemma}
\begin{proof}
Fix any $\epsilon>0$ and $\delta>0$.
For any $r\in[t,s]$, it follows from Proposition~\ref{prop:outerderivativebehaveslikelimit} and Definition~\eqref{def:nonmarkovsetQ} that there is some $0<\delta_r<\delta$ such that, for all $0<\Delta<\delta_r$:
\begin{equation}\label{eq:epsilonboundsforlemma}
(\exists Q\in\rateset)
\norm{\frac{1}{\Delta}
(T^{r+\Delta}_{r,\,x_u}-I)-Q}<\epsilon
\text{~~and~~}
(\exists Q\in\rateset)
\norm{\frac{1}{\Delta}
(T^{r}_{r-\Delta,\,x_u}-I)-Q}<\epsilon.
\end{equation}
Let $U_r\coloneqq(r-\delta_r,r+\delta_r)$. Then the set $C\coloneqq\{U_r\colon r\in[t,s]\}$ is an open cover of $[t,s]$. By the Heine-Borel theorem, $C$ contains a finite subcover $C^*$ of $[t,s]$. Without loss of generality, we can take this subcover to be minimal, in the sense that if we remove any of its elements, it is no longer a cover. Let $m$ be the cardinality of $C^*$ and let $r_1<r_2<\dots<r_m$ be the ordered sequence of the midpoints of the intervals in $C^*$.

We will now prove that
\begin{equation}\label{eq:orderingofbounds}
r_i-\delta_{r_i}<r_j-\delta_{r_j}
\text{~~and~~}
r_i+\delta_{r_i}<r_j+\delta_{r_j}
\text{~~for all $1\leq i<j\leq m$.}
\end{equation}
Assume \emph{ex absurdo} that this statement is not true. Then this implies that there are $1\leq i<j\leq m$ such that either $r_i-\delta_{r_i}\geq r_j-\delta_{r_j}$ or $r_i+\delta_{r_i}\geq r_j+\delta_{r_j}$. If $r_i-\delta_{r_i}\geq r_j-\delta_{r_j}$, then since $i<j$ implies that $r_i<r_j$, it follows that $\delta_{r_j}\geq\delta_{r_i}+r_j-r_i>\delta_{r_i}$ and therefore, that $r_j+\delta_{r_j}>r_i+\delta_{r_i}$. 
Hence, we find that $U_{r_i}\subseteq U_{r_j}$. Since $C^*$ was taken to be a minimal cover, this is a contradiction.
Similarly, if $r_i+\delta_{r_i}\geq r_j+\delta_{r_j}$, then since $i<j$ implies that $r_i<r_j$, it follows that $\delta_{r_i}\geq\delta_{r_j}+r_j-r_i>\delta_{r_j}$ and therefore, that $r_i-\delta_{r_i}<r_j-\delta_{r_i}$. Hence, we find that $U_{r_j}\subseteq U_{r_i}$. Since $C^*$ was taken to be a minimal cover, this is again a contradiction. From these two contradictions, it follows that Equation~\eqref{eq:orderingofbounds} is indeed true.

Next, we prove that
\begin{equation}\label{eq:overlapasyouwantit}
r_{k+1}-\delta_{r_{k+1}}<r_k+\delta_{r_k}
\text{~~for all $k\in\{1,\dots,m-1\}$.}
\end{equation}
Assume \emph{ex absurdo} that this statement is not true or, equivalently, that there is some $k\in\{1,\dots,m-1\}$ such that $r_k+\delta_{r_k}\leq r_{k+1}-\delta_{r_{k+1}}$. For all $i\in\{k+1,\dots, m\}$, it then follows from Equation~\eqref{eq:orderingofbounds} that $r_k+\delta_{r_k}\leq r_i-\delta_{r_i}$, which implies that $r_k+\delta_{r_k}\notin U_{r_i}$. Similarly, for all $i\in\{1,\dots,k\}$, it follows from Equation~\eqref{eq:orderingofbounds} that $r_i+\delta_{r_i}\leq r_k+\delta_{r_k}$, which again implies that $r_k+\delta_{r_k}\notin U_{r_i}$. 
Hence, for all $i\in\{1,\dots,m\}$, we have found that $r_k+\delta_{r_k}\notin U_{r_i}$. 
Since $C^*$ is a cover of $[t,s]$, this implies that $r_k+\delta_{r_k}\notin[t,s]$, which, since $r_k\in[t,s]$, implies that $r_k+\delta_{r_k}>s$. Hence, since we know from Equation~\eqref{eq:orderingofbounds} that $r_k-\delta_{r_k}<r_m-\delta_{r_m}$, it follows that $U_{r_m}\cap[t,s]\subseteq U_{r_k}\cap[t,s]$. This contradicts the fact that $C^*$ was taken to be a minimal cover.

For all $k\in\{1,\dots,m-1\}$, we now define $q_k\coloneqq\nicefrac{1}{2}(r_k+\delta_{r_k}+r_{k+1}-\delta_{r_{k+1}})$.
Using Equation~\eqref{eq:orderingofbounds}, it then follows that
\begin{equation*}
q_k<\frac{r_{k+1}+\delta_{r_{k+1}}+r_{k+1}-\delta_{r_{k+1}}}{2}=r_{k+1}
\text{~~and~~}
q_k>\frac{r_{k}+\delta_{r_{k}}+r_{k}-\delta_{r_{k}}}{2}=r_{k},
\end{equation*}
and Equation~\eqref{eq:overlapasyouwantit} trivially implies that $r_{k+1}-\delta_{r_{k+1}}<q_k<r_k+\delta_{r_k}$. Hence,
\begin{equation*}
r_k<q_k<r_k+\delta_{r_k}
\text{~~and~~}
r_{k+1}-\delta_{r_{k+1}}<q_k<r_{k+1}.
\end{equation*}
Because of Equation~\eqref{eq:epsilonboundsforlemma}, and with $\Delta^*_k\coloneqq q_k-r_k$ and $\Delta^{**}_k\coloneqq r_{k+1}-q_k$, this implies that
\begin{equation}\label{eq:epsilonboundsforqk}
(\exists Q\in\rateset)
\norm{\frac{1}{\Delta^*_k}
(T^{q_k}_{r_k,\,x_u}-I)-Q}<\epsilon
\text{~~and~~}
(\exists Q\in\rateset)
\norm{\frac{1}{\Delta^{**}_k}
(T^{r_{k+1}}_{q_k,\,x_u}-I)-Q}<\epsilon.
\end{equation}

For all $k\in\{1,\dots,m-1\}$, we now let $s_{2k}\coloneqq q_k$ and, for all $k\in\{1,\dots,m\}$, we let $s_{2k-1}\coloneqq r_k$. For the resulting sequence $s_1<s_2<\dots<s_{2m-2}<s_{2m-1}$, it then follows from Equation~\eqref{eq:epsilonboundsforqk} and~\ref{N:homogeneous} that, for all $i\in\{1,\dots,2m-2\}$:
\begin{equation*}
(\exists Q\in\rateset)
~
\norm{
T^{s_{i+1}}_{s_i,\,x_u}-(I+\Delta'_{i+1}Q)
}<\Delta'_{i+1}\epsilon,
\end{equation*}
with $\Delta'_{i+1}\coloneqq s_{i+1}-s_i<\delta$. 

If $s_1\neq t$, we also define $s_0\coloneqq t$ and $\Delta'_1\coloneqq s_1-s_0=r_1-t>0$. Since $C^*$ is a minimal cover, and because of Equation~\eqref{eq:orderingofbounds}, it follows that $r_1-\delta_{r_1}<t<r_1$, which, because of Equation~\eqref{eq:epsilonboundsforlemma} and~\ref{N:homogeneous}, implies that
\begin{equation*}
(\exists Q\in\rateset)
~
\norm{
T^{s_{1}}_{s_0,\,x_u}-(I+\Delta'_{1}Q)
}<\Delta'_{1}\epsilon.
\end{equation*}

If $s_{2m-1}\neq s$, we also define $s_{2m}\coloneqq s$ and $\Delta'_{2m}\coloneqq s_{2m}-s_{2m-1}=s-r_m>0$. Since $C^*$ is a minimal cover, and because of Equation~\eqref{eq:orderingofbounds}, it follows that $r_m<s<r_m+\delta_{r_m}$, which, because of Equation~\eqref{eq:epsilonboundsforlemma} and~\ref{N:homogeneous}, implies that
\begin{equation*}
(\exists Q\in\rateset)
~
\norm{
T^{s_{2m}}_{s_{2m-1},\,x_u}-(I+\Delta'_{2m}Q)
}<\Delta'_{2m}\epsilon.
\end{equation*}

We now consider four cases.
If $s_1=t$ and $s_{2m-1}=s$, the result follows by letting $n\coloneqq 2m-2$ and defining $t_i\coloneqq s_{i+1}$ for all $i\in\{0,\dots,n\}$. 
If $s_1=t$ and $s_{2m-1}\neq s$, the result follows by letting $n\coloneqq 2m-1$ and defining $t_i\coloneqq s_{i+1}$ for all $i\in\{0,\dots,n\}$.
If $s_1\neq t$ and $s_{2m-1}=s$, the result follows by letting $n\coloneqq 2m-1$ and defining $t_i\coloneqq s_{i}$ for all $i\in\{0,\dots,n\}$.
If $s_1\neq t$ and $s_{2m-1}\neq s$, the result follows by letting $n\coloneqq 2m$ and defining $t_i\coloneqq s_{i}$ for all $i\in\{0,\dots,n\}$.
\end{proof}


\begin{lemma}\label{lemma:convex_rate_set_contains_approximation}
Consider any non-empty, bounded and convex set of rate matrices $\rateset$, any $\Delta\in\realspos$ such that $\Delta<\nicefrac{1}{\norm{\rateset}}$, and any $u\in\mathcal{U}_{[0,\Delta]}$ with $u=t_0,\ldots,t_n$. For all $i\in\{1,\ldots,n\}$, choose some $Q_i\in\rateset$. Let
\begin{equation*}
Q \coloneqq \sum_{i=1}^n \frac{\Delta_i}{\Delta}Q_i\,.
\end{equation*}
Then, $Q\in\rateset$, and furthermore,
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} < \Delta^2\norm{\rateset}^2\,.
\end{equation*}
\end{lemma}
\begin{proof}
The claim that $Q\in\rateset$ follows trivially from the fact that $\rateset$ is convex.

Now, consider the following product expansion:
\begin{align*}
\prod_{i=1}^n(I+\Delta_iQ_i) &= I + \sum_{i=1}^n\Delta_iQ_i + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_jQ_iQ_j + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_kQ_iQ_jQ_k + \cdots \\
% &= I + \sum_{i=1}^n\Delta_iQ_i + \sum_{k=1}^n\left[\sum_{i_1=1}^{n-k}\cdots\sum_{i_k=i_{k-1}+1}^n XXX \right]
\end{align*}
It follows that
\begin{align*}
 &\quad \norm{\prod_{i=1}^n(I+\Delta_iQ_i)} \\
 &= \norm{I + \sum_{i=1}^n\Delta_iQ_i + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_jQ_iQ_j + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_kQ_iQ_jQ_k + \cdots} \\
 &\leq \norm{I} + \norm{\sum_{i=1}^n\Delta_iQ_i} + \norm{\sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_jQ_iQ_j} + \norm{\sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_kQ_iQ_jQ_k} + \cdots \\
 &\leq \norm{I} + \sum_{i=1}^n\Delta_i\norm{Q_i} + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_j\norm{Q_iQ_j} + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_k\norm{Q_iQ_jQ_k} + \cdots \\
 &\leq \norm{I} + \sum_{i=1}^n\Delta_i\norm{Q_i} + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_j\norm{Q_i}\norm{Q_j} + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_k\norm{Q_i}\norm{Q_j}\norm{Q_k} + \cdots \\
 &\leq 1 + \sum_{i=1}^n\Delta_i\norm{\rateset} + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_j\norm{\rateset}^2 + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_k\norm{\rateset}^3 + \cdots \\
 &= 1 + \Delta\norm{\rateset} + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_j\norm{\rateset}^2 + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_k\norm{\rateset}^3 + \cdots
\end{align*}
Consider next the product expansion of the scalar product:
\begin{align*}
\prod_{i=1}^n(1+\Delta_i\norm{\rateset}) = 1 + \sum_{i=1}^n\Delta_i\norm{\rateset} + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_j\norm{\rateset}^2 + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_k\norm{\rateset}^3 + \cdots
\end{align*}
Clearly, these have the same form. Hence, we find that
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_iQ_i)} \leq \prod_{i=1}^n(1+\Delta_i\norm{\rateset})\,.
\end{equation*}

We are now ready to start proving the inequality of interest. We start by expanding the product term:
\begin{align*}
 &\quad \norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} \\
 &= \norm{I + \sum_{i=1}^n\Delta_iQ_i + \sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_jQ_iQ_j + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_kQ_iQ_jQ_k + \cdots - (I+\Delta Q)} \\
 &\leq \norm{I + \sum_{i=1}^n\Delta_iQ_i - (I+\Delta Q)} + \norm{\sum_{i=1}^{n-1}\sum_{j=i+1}^n\Delta_i\Delta_jQ_iQ_j + \sum_{i=1}^{n-2}\sum_{j=i+1}^{n-1}\sum_{k=j+1}^n\Delta_i\Delta_j\Delta_kQ_iQ_jQ_k + \cdots} \\
 &\leq \norm{I + \sum_{i=1}^n\Delta_iQ_i - (I+\Delta Q)} + \prod_{i=1}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset}) \\
 &= \norm{\sum_{i=1}^n\Delta_iQ_i - \Delta Q} + \prod_{i=1}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset}) \\
 &= \norm{\sum_{i=1}^n\Delta_iQ_i - \Delta \sum_{i=1}^n\frac{\Delta_i}{\Delta}Q_i} + \prod_{i=1}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset}) \\
 &= \prod_{i=1}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset})\,.
\end{align*}

We next give an upper bound on the remaining product term. Consider the exponential function $e^a$. It is well known that this function has the series representation
\begin{equation*}
e^a = \sum_{i=0}^\infty\frac{a^i}{i!} = 1 + a + \frac{a^2}{2!} + \frac{a^3}{3!} + \cdots
\end{equation*}
Hence, it follows that $(1+a)<e^a$ for all $a\in\realspos$. Therefore in particular, we find that $(1+\Delta_i\norm{\rateset})<e^{\Delta_i\norm{\rateset}}$ for all $i\in\{1,\ldots,n\}$. Hence,
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} &\leq \prod_{i=1}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset}) \\
% &< e^{\Delta_1\norm{\rateset}}\prod_{i=2}^n(1+\Delta_i\norm{\rateset}) - (1 + \Delta\norm{\rateset}) \\
% &\quad\vdots \\
 &< \prod_{i=1}^n e^{\Delta_i\norm{\rateset}} - (1 + \Delta\norm{\rateset}) \\
 &= e^{\sum_{i=1}^n\Delta_i\norm{\rateset}} - (1 + \Delta\norm{\rateset}) \\
 &= e^{\Delta\norm{\rateset}} - (1 + \Delta\norm{\rateset})\,.
\end{align*}
We now use the following claim.
\begin{claim}\label{claim:bound_on_exp}
For all $a\in\realspos$ with $a<1$, it holds that $e^a - (1 + a) < a^2$.
\end{claim}
Hence, because $\Delta<\nicefrac{1}{\norm{\rateset}}$, we find that
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} &< e^{\Delta\norm{\rateset}} - (1 + \Delta\norm{\rateset}) \\
 &< \Delta^2\norm{\rateset}^2\,.
\end{align*}
\end{proof}

\begin{proof}[Proof of Claim~\ref{claim:bound_on_exp}]
We have to show that $e^a-(1+a)<a^2$ for all $a\in\realspos$ such that $a<1$. To this end, consider the function
\begin{equation*}
f(a) \coloneqq 1 + a + a^2 - e^a\,.
\end{equation*}
Clearly, the inequality of interest holds whenever $f(a)>0$. Now, we clearly have that $f(0)=0$. Furthermore, if we consider the first and second derivatives,
\begin{equation*}
\frac{d f(a)}{d a}=1+2a-e^a\,,\quad\text{and,}\quad\frac{d^2 f(a)}{da^2}=2-e^a\,,
\end{equation*}
we see that at $a=0$, the function is in a local minimum, because $\nicefrac{df(a)}{da}=0$ and $\nicefrac{d^2f(a)}{da^2}>0$. Hence, $f(a)>0$ will hold close to $a=0$. Furthermore, inspection of the second derivative shows that the first derivative increases until $a=\ln(2)$, after which it remains decreasing. Therefore, $f(a)$ is monotonically increasing on $(0,b)$, for some value $b>\ln(2)$ at which the first derivative becomes negative. To prove the claim, we therefore only have to note that $\nicefrac{df(a)}{da} > 0$ still holds at $a=1$.
\end{proof}

\begin{lemma}\label{lemma:uniform_delta_for_convex_markov_set}
Let $\rateset$ be any non-empty, bounded and convex set of rate matrices, and choose any $\epsilon\in\realspos$. Then, there is some $\delta\in\realspos$ such that for all $P\in\wmprocesses_\rateset$, all $t\in\realsnonneg$, and all $\Delta\in\realspos$ such that $\Delta<\delta$,
\begin{equation*}
(\exists Q\in\rateset)\,\norm{T_{t}^{t+\Delta} - (I+\Delta Q)} < \Delta\epsilon\,.
\end{equation*}
\end{lemma}
\begin{proof}
Fix any $\epsilon\in\realspos$, and let
\begin{equation*}
\delta \coloneqq \min\left\{\frac{\epsilon}{2\norm{\rateset}^2},\frac{1}{\norm{\rateset}}\right\}\,.
\end{equation*}
Choose any $P\in\wmprocesses_\rateset$, any $t\in\realsnonneg$, and any $\Delta<\delta$.

Let $\epsilon'\coloneqq \nicefrac{\epsilon}{2}$. Then, by Lemma~\ref{lemma:bound_on_linear_approx_partition}, there is some $u\in\mathcal{U}_{[t,t+\Delta]}$ with $u=t_0,\ldots,t_n$, such that, for all $i\in\{1,\ldots,n\}$,
\begin{equation*}
(\exists Q\in\rateset)\,\norm{T_{t_{i-1}}^{t_i} - (I+\Delta_iQ)} < \Delta_i\epsilon'.
\end{equation*}
This implies the existence of rate matrices $Q_1,\ldots,Q_n\in\rateset$, such that, for all $i\in\{1,\ldots,n\}$
\begin{equation*}
\norm{T_{t_{i-1}}^{t_i} - (I+\Delta_iQ_i)} < \Delta_i\epsilon'\,.
\end{equation*}
Therefore, and due to Lemma~\ref{lemma:recursive}, we find using the Markov property of $P$ that
\begin{align*}
\norm{T_t^{t+\Delta} - \prod_{i=1}^n(I+\Delta_iQ_i)} &= \norm{\prod_{i=1}^nT_{t_{i-1}}^{t_i} - \prod_{i=1}^n(I+\Delta_iQ_i)} \\
 &< \sum_{i=1}^n\Delta_i\epsilon' \\
 &= \Delta\epsilon'\,.
\end{align*}
Let now
\begin{equation*}
Q\coloneqq \sum_{i=1}^n \frac{\Delta_i}{\Delta} Q_i\,.
\end{equation*}
Then, by Lemma~\ref{lemma:convex_rate_set_contains_approximation}, we have that $Q\in\rateset$, and because $\Delta<\delta\leq\nicefrac{1}{\norm{\rateset}}$,
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} < \Delta^2\norm{\rateset}^2\,.
\end{equation*}

Putting this all together, we find that
\begin{align*}
\norm{T_t^{t+\Delta} - (I+\Delta Q)} &\leq \norm{T_t^{t+\Delta} - \prod_{i=1}^n(I+\Delta_iQ_i)} + \norm{\prod_{i=1}^n(I+\Delta_iQ_i) - (I+\Delta Q)} \\
 &< \Delta\epsilon' + \Delta^2\norm{\rateset}^2 \\
 &< \Delta\frac{\epsilon}{2} + \Delta\delta\norm{\rateset}^2 \\
 &\leq \Delta\frac{\epsilon}{2} + \Delta\frac{\epsilon}{2\norm{\rateset}^2}\norm{\rateset}^2 \\
 &= \Delta\epsilon\,.
\end{align*}
\end{proof}

\begin{definition}\label{def:uniformly_well_behaved}
For any sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ of restricted transition matrix systems, we say that this sequence is \emph{uniformly well-behaved} if there is some $B\in\realspos$ such that, for all $i\in\nats$ and all $r\in[t,s]$, it holds that
\begin{equation*}
\limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta}-I\right)} < B\,,\quad\text{and,}\quad \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_{r-\Delta}^{r}-I\right)} < B\,.
\end{equation*}
Here, it is understood that $\presuper{i}T_r^{r+\Delta},\presuper{i}T_{r-\Delta}^{r}\in\mathcal{T}_i^{[t,s]}$ for all $i\in\nats$.
\end{definition}

\begin{lemma}\label{lemma:restricted_trans_mat_system_cauchy_converges}
Consider any $t,s\in\realsnonneg$ with $t\leq s$, and any Cauchy sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ of restricted transition matrix systems. Consider the family $\mathcal{T}_*^{[t,s]}$ of matrices $\presuper{*}T_q^r$, defined for all $q,r\in[t,s]$ with $q\leq r$ as
\begin{equation*}
\presuper{*}T_q^r \coloneqq \lim_{i\to\infty} \presuper{i}T_q^r\,,
\end{equation*}
where it is understood that $\presuper{i}T_q^r\in\mathcal{T}_i^{[t,s]}$ for all $i\in\nats$.

Then, $\mathcal{T}_*^{[t,s]}$ exists, is a restricted transition matrix system defined on $[t,s]$, and $\mathcal{T}_*^{[t,s]}=\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$. Furthermore, if $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is uniformly well-behaved, defined as in Definition~\ref{def:uniformly_well_behaved}, then $\mathcal{T}_*^{[t,s]}$ is well-behaved.
\end{lemma}
\begin{proof}
By assumption, the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is Cauchy, meaning that
\begin{equation*}
(\forall\epsilon\in\realspos)(\exists n\in\nats)(\forall i,j > n)\,:\,d(\mathcal{T}_i^{[t,s]},\mathcal{T}_j^{[t,s]}) < \epsilon\,.
\end{equation*}
We first show that $\mathcal{T}_*^{[t,s]}$ exists. To this end, consider any $q,r\in[t,s]$ such that $q\leq r$. Consider the sequence $\left\{\presuper{i}T_q^r\right\}_{i\in\nats}$. Then, because $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is Cauchy, the sequence $\left\{\presuper{i}T_q^r\right\}_{i\in\nats}$ is also clearly Cauchy. Therefore, and because this is a sequence of matrices, the limit $\presuper{*}T_q^r\coloneqq\lim_{i\to\infty}\presuper{i}T_q^r$ of this sequence clearly exists. Furthermore, because this is a sequence of transition matrices, $\presuper{*}T_q^r$ is also clearly a transition matrix. Therefore, and because the $q,r\in[t,s]$ were arbitrary, the family $\mathcal{T}_*^{[t,s]}$ exists. Furthermore, we have found that it is a family of transition matrices.

We now show that $\mathcal{T}_*^{[t,s]}$ is a restricted transition matrix system. Consider any $r\in[t,s]$. Clearly, we have that
\begin{equation*}
\presuper{*}T_r^r = \lim_{i\to\infty} \presuper{i}T_r^r = \lim_{i\to\infty} I = I\,.
\end{equation*}
It remains to show that for all $\tau,r,\sigma\in[t,s]$ such that $\tau\leq r\leq\sigma$, it holds that
\begin{equation*}
\presuper{*}T_\tau^\sigma = \presuper{*}T_\tau^r\presuper{*}T_r^\sigma\,.
\end{equation*}
Suppose \emph{ex absurdo} that this does not hold. Then, because $\presuper{*}T_\tau^\sigma = \lim_{i\to\infty} \presuper{i}T_\tau^\sigma=\lim_{i\to\infty}\presuper{i}T_\tau^r\presuper{i}T_r^\sigma$, we have that
\begin{equation*}
\lim_{i\to\infty} \presuper{i}T_\tau^r\presuper{i}T_r^\sigma \neq \presuper{*}T_\tau^r\presuper{*}T_r^\sigma\,.
\end{equation*}
Therefore, it holds that
\begin{equation*}
(\exists \epsilon\in\realspos)(\forall n\in\nats)(\exists i>n)\,:\,\norm{\presuper{i}T_\tau^r\presuper{i}T_r^\sigma - \presuper{*}T_\tau^r\presuper{*}T_r^\sigma} \geq \epsilon\,.
\end{equation*}
Consider such an $\epsilon\in\realspos$. Then, because $\presuper{*}T_\tau^r=\lim_{i\to\infty}\presuper{i}T_\tau^r$ and $\presuper{*}T_r^\sigma=\lim_{i\to\infty}\presuper{i}T_r^\sigma$ there must be some $n_\tau,n_\sigma\in\nats$ such that
\begin{equation*}
(\forall i>n_\tau)\,:\,\norm{\presuper{*}T_\tau^r - \presuper{i}T_\tau^r} < \frac{\epsilon}{2}\,, \quad\text{and,}\quad (\forall i>n_\sigma)\,:\,\norm{\presuper{*}T_r^\sigma - \presuper{i}T_r^\sigma} < \frac{\epsilon}{2}\,.
\end{equation*}
Consider now any $n\in\nats$ such that $n>\max\{n_\tau,n_\sigma\}$. Then, there must be some $i\in\nats$ such that $i>n$, and for which, by Lemma~\ref{lemma:recursive},
\begin{equation*}
\epsilon \leq \norm{\presuper{i}T_\tau^r\presuper{i}T_r^\sigma - \presuper{*}T_\tau^r\presuper{*}T_r^\sigma} < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\,.
\end{equation*}
From this contradiction, we conclude that indeed
\begin{equation*}
\presuper{*}T_\tau^\sigma = \presuper{*}T_\tau^r\presuper{*}T_r^\sigma\,.
\end{equation*}
Therefore, $\mathcal{T}_*^{[t,s]}$ is a restricted transition matrix system.

We next show that $\mathcal{T}_*^{[t,s]}=\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$. Suppose \emph{ex absurdo} that this does not hold. Then,
\begin{equation*}
(\exists\epsilon\in\realspos)(\forall n\in\nats)(\exists i>n)\,:\,d(\mathcal{T}_*^{[t,s]}, \mathcal{T}_i^{[t,s]}) \geq \epsilon\,.
\end{equation*}
Consider such an $\epsilon\in\realspos$. Because the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is Cauchy, we have that
\begin{equation*}
(\exists n\in\nats)(\forall i,j>n)\,:\,d(\mathcal{T}_i^{[t,s]},\mathcal{T}_j^{[t,s]}) < \frac{\epsilon}{3}\,.
\end{equation*}
Consider this $n$. Then, there must be some $i\in\nats$ with $i>n$, such that
\begin{equation*}
d(\mathcal{T}_*^{[t,s]}, \mathcal{T}_i^{[t,s]}) = \sup\left\{\norm{\presuper{*}T_q^r - \presuper{i}T_q^r}\,:\,q,r\in[t,s], q\leq r\right\} \geq \epsilon\,,
\end{equation*}
meaning that, for all $\epsilon'\in\realspos$, there are some $q,r\in[t,s]$ with $q\leq r$, such that
\begin{equation*}
\norm{\presuper{*}T_q^r - \presuper{i}T_q^r} + \epsilon' > \epsilon\,.
\end{equation*}
Let $\epsilon'\coloneqq\nicefrac{\epsilon}{3}$, and choose any such $q,r\in[t,s]$ with $q\leq r$. Then, because $\presuper{*}T_q^r=\lim_{k\to\infty}\presuper{k}T_q^r$, there must be some $j\in\nats$ such that $j>n$, and for which
\begin{equation*}
\norm{\presuper{*}T_q^r - \presuper{j}T_q^r} < \frac{\epsilon}{3}\,.
\end{equation*}
Consider this $j$. Putting this together, we find that
\begin{align*}
\epsilon &< \norm{\presuper{*}T_q^r - \presuper{i}T_q^r} + \frac{\epsilon}{3} \\
 &\leq \norm{\presuper{*}T_q^r - \presuper{j}T_q^r} + \norm{\presuper{j}T_q^r - \presuper{i}T_q^r} + \frac{\epsilon}{3} \\
 &< \frac{\epsilon}{3} + d(\mathcal{T}_j^{[t,s]},\mathcal{T}_i^{[t,s]}) + \frac{\epsilon}{3} \\
 &< \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} \\
 &= \epsilon\,.
\end{align*}
Hence, we have found a contradiction, and therefore $\mathcal{T}_*^{[t,s]}=\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$.

We finally show that if  $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is uniformly well-behaved, that then $\mathcal{T}_*^{[t,s]}$ is well-behaved. Suppose \emph{ex absurdo} that this does not hold. Then, it must hold that, for some $r\in[t,s]$, either
\begin{equation*}
\limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{*}T_r^{r+\Delta}-I\right)} \nless \infty\,,\quad\text{or,}\quad \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{*}T_{r-\Delta}^{r}-I\right)} \nless \infty\,.
\end{equation*}
We only give the proof for the first case; the proof for the second case is completely analogous. Therefore, in this case, it holds that
\begin{equation*}
(\forall B\in\realsnonneg)(\forall \delta\in\realspos)(\exists \Delta\in(0,\delta))\,:\,\norm{\frac{1}{\Delta}\left(\presuper{*}T_r^{r+\Delta}-I\right)} \geq B\,.
\end{equation*}
Consider now any sequence $\{B_k\}_{k\in\nats}$ in $\realsnonneg$ such that $\{B_k\}_{k\in\nats}\to+\infty$. For all $k\in\nats$, this implies the existence of some $\Delta_k\in\realspos$ such that $\Delta_k<\Delta_{k-1}$, with $\Delta_0\coloneqq 1$, and for which
\begin{equation*}
\norm{\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k}-I\right)} \geq B_k\,.
\end{equation*}
Consider this sequence $\left\{\Delta_k\right\}_{k\in\nats}$. Clearly, we have that $\left\{\Delta_k\right\}_{k\in\nats}\to0^+$, and,
\begin{equation*}
(\forall B\in\realspos)(\exists n\in\nats)(\forall k>n)\,:\,\norm{\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k}-I\right)} > B\,.
\end{equation*}

Because the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is uniformly well-behaved, there must be some $B^*\in\realspos$ such that, for all $i\in\nats$, it holds that
\begin{equation*}
(\exists\delta_i\in\realspos)(\forall\Delta\in(0,\delta_i))\,:\,\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta}-I\right)} < B^*\,.
\end{equation*}
For this $B^*$, we have that
\begin{equation*}
(\exists n\in\nats)(\forall k>n)\,:\,\norm{\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k}-I\right)} > 2B^*\,.
\end{equation*}
Consider this $n$.

Then, because $\mathcal{T}_*^{[t,s]}=\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$, there must be some $i\in\nats$ such that 
\begin{equation*}
d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]})<B^*\,.
\end{equation*}
Consider this $i$. Then, because $\{\Delta_k\}_{k\in\nats}\to0^+$, there must be some $k\in\nats$ such that $k>n$ and $\Delta_k <\delta_i$\,. Consider this $k$.

Putting this together, we have found that
\begin{align*}
2B^* &< \norm{\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k}-I\right)} \\
 &\leq \norm{\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k}-I\right) - \frac{1}{\Delta_k}\left(\presuper{i}T_r^{r+\Delta_k}-I\right)} + \norm{\frac{1}{\Delta_k}\left(\presuper{i}T_r^{r+\Delta_k}-I\right)} \\
 &< \Delta_k d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]}) + B^* \\
 &< \Delta_0 d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]}) + B^* \\
 &= d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]}) + B^* \\
 &< B^* + B^*\,.
\end{align*}
Hence, we have found a contradiction. Similarly, if instead
\begin{equation*}
\limsup_{\Delta\to0^+} \norm{\frac{1}{\Delta}\left(\presuper{*}T_{r-\Delta}^{r}-I\right)} \nless \infty\,,
\end{equation*}
we find a contradiction using a completely analogous argument. Therefore, we conclude that $\mathcal{T}_*^{[t,s]}$ is well-behaved.
\end{proof}

\begin{lemma}\label{lemma:restricted_trans_mat_system_complete_if_Q_closed}
Consider any non-empty, bounded and closed set of rate matrices $\rateset$, and any $t,s\in\realsnonneg$ such that $t\leq s$. Then, the metric space $(\mathbb{T}_\rateset^{[t,s]},d)$ is complete under the metric $d$, defined as in Equation~\eqref{eq:trans_mat_system_metric}.
\end{lemma}
\begin{proof}
We need to show that for any Cauchy sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ in $\mathbb{T}_\rateset^{[t,s]}$, it holds that $\mathcal{T}_*^{[t,s]}\coloneqq\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$ exists and satisfies $\mathcal{T}_*^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$. Therefore, consider any Cauchy sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ in  $\mathbb{T}_\rateset^{[t,s]}$. 

We first make the following claim, which is proved below.
\begin{claim}\label{claim:lemma_restricted_trans_mat_system_complete_uniformly_well_behaved}
The sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is uniformly well-behaved, as in Definition~\ref{def:uniformly_well_behaved}.
\end{claim}

Now, because this sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is Cauchy, it follows from Lemma~\ref{lemma:restricted_trans_mat_system_cauchy_converges} that the limit $\mathcal{T}_*^{[t,s]}$ exists, and is a restricted transition matrix system. Furthermore, due to Claim~\ref{claim:lemma_restricted_trans_mat_system_complete_uniformly_well_behaved} and Lemma~\ref{lemma:restricted_trans_mat_system_cauchy_converges}, $\mathcal{T}_*^{[t,s]}$ is well-behaved.

It remains to show that $\mathcal{T}_*^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$. To this end, consider any $Q\in\rateset$, and let $\mathcal{T}_Q$ be the transition matrix system corresponding to this $Q$, defined as in Definition~\ref{def:systemfromQ}. Let 
\begin{equation*}
\mathcal{T}_*\coloneqq \mathcal{T}_Q^{[0,t]}\otimes \mathcal{T}_*^{[t,s]} \otimes \mathcal{T}_Q^{[s,\infty)}\,.
\end{equation*}
Then, clearly, $\mathcal{T}_*$ is a transition matrix system, and because $\mathcal{T}_Q$ and $\mathcal{T}_*^{[t,s]}$ are well-behaved, $\mathcal{T}_*$ is also well-behaved. Therefore, and due to Theorem~\ref{theo:uniqueMarkovchain}, there is some $P_*\in\wmprocesses$ such that $\mathcal{T}_{P_*}=\mathcal{T}_*$. We will show that $P_*\in\wmprocesses_\rateset$, which then implies that $\mathcal{T}_{P_*}^{[t,s]}=\mathcal{T}_*^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$.

Suppose \emph{ex absurdo} that $P_*\notin\wmprocesses_\rateset$. Then, there must be some $r\in\realsnonneg$ such that $\smash{\overline{\partial}}\presuper{*}T_r^r\nsubseteq\rateset$. Therefore, and because $\smash{\overline{\partial}}\presuper{*}T_r^r$ is non-empty, there must be some $Q_*\in \smash{\overline{\partial}}\presuper{*}T_r^r$ such that $Q_*\notin\rateset$. 


Because $Q_*\in \smash{\overline{\partial}}\presuper{*}T_r^r$, we have that either $Q_*\in \smash{\overline{\partial}}_+\presuper{*}T_r^r$, or $Q_*\in \smash{\overline{\partial}}_-\presuper{*}T_r^r$. We only show that $Q_*\in \smash{\overline{\partial}}_+\presuper{*}T_r^r$ leads to a contradiction; the proof for $Q_*\in \smash{\overline{\partial}}_-\presuper{*}T_r^r$ is completely analogous. 

Therefore, suppose that $Q_*\in \smash{\overline{\partial}}_+\presuper{*}T_r^r$. Because for all $r<t$ and $r>s$ it holds that $\smash{\overline{\partial}}_+\presuper{*}T_r^r=\{Q\}\subseteq\rateset$, we clearly have that $r\in[t,s]$. Furthermore, because $Q_*\in \smash{\overline{\partial}}_+\presuper{*}T_r^r$, by Equation~\eqref{eq:rightouterderivative}, this implies the existence of a sequence $\{\Delta_k\}_{k\in\nats}\to0^+$ such that
\begin{equation}\label{eq:lemma_transmatsystem_complete_limit_rate}
Q_* = \lim_{k\to\infty}\frac{1}{\Delta_k}\left(\presuper{*}T_r^{r+\Delta_k} - I\right)\,.
\end{equation}

Now, consider any $i\in\nats$, and the corresponding restricted transition matrix system $\mathcal{T}_i^{[t,s]}$. Define $\epsilon_i\coloneqq d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]})$. Because $\mathcal{T}_i^{[t,s]}$ corresponds to some Markov chain $P_i\in\wmprocesses_\rateset$, by Proposition~\ref{prop:outerderivativebehaveslikelimit}, we have that
\begin{equation*}
(\exists \delta_i\in\realspos)(\forall \Delta\in(0,\delta_i))(\exists Q_i\in\rateset)\,:\,\norm{\frac{\presuper{i}T_r^{r+\Delta} - I}{\Delta} - Q_i} < \epsilon_i\,.
\end{equation*}
Consider this $\delta_i$. Due to Equation~\eqref{eq:lemma_transmatsystem_complete_limit_rate}, there must be some $n_i\in\nats$ such that, for all $k>n_i$, it holds that
\begin{equation*}
\norm{\frac{\presuper{*}T_r^{r+\Delta_k} - I}{\Delta_k} - Q_*} < \epsilon_i\,.
\end{equation*}
Consider this $n_i$. Finally, because $\{\Delta_k\}_{k\in\nats}\to0^+$, there must be some $k_i\in\nats$ such that $k_i>n_i$, and for which $\Delta_{k_i}<\min\{\delta_i,1\}$. Consider this $k_i$. Then, because $\Delta_{k_i}<\delta_i$, there must be some $Q_i\in\rateset$ such that
\begin{equation*}
\norm{\frac{\presuper{i}T_r^{r+\Delta_{k_i}} - I}{\Delta_{k_i}} - Q_i} < \epsilon_i\,.
\end{equation*}
Consider this $Q_i$. Putting this together, we have found a rate matrix $Q_i\in\rateset$, such that
\begin{align*}
\norm{Q_i - Q_*} &\leq \norm{\frac{\presuper{i}T_r^{r+\Delta_{k_i}} - I}{\Delta_{k_i}} - Q_i} + \norm{\frac{\presuper{*}T_r^{r+\Delta_{k_i}} - I}{\Delta_{k_i}} - Q_*} + \norm{\frac{\presuper{i}T_r^{r+\Delta_{k_i}} - I}{\Delta_{k_i}} - \frac{\presuper{*}T_r^{r+\Delta_{k_i}} - I}{\Delta_{k_i}}} \\
 &< \epsilon_i + \epsilon_i + \Delta_{k_i}d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]}) \\
 &< 2\epsilon_i + d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]})\,,
\end{align*}
where the last inequality used the fact that $\Delta_{k_i}<1$. Therefore, and by the definition of $\epsilon_i$, we have that
\begin{equation}\label{eq:lemma_transmatsystem_complete_rate_sequence_converges}
\norm{Q_i - Q_*} < 3d(\mathcal{T}_*^{[t,s]},\mathcal{T}_i^{[t,s]})\,.
\end{equation}

If we now repeat this selection for all $i\in\nats$, we end up with a sequence $\{Q_i\}_{i\in\nats}$ in $\rateset$. Furthermore, because $\mathcal{T}_*^{[t,s]}=\lim_{i\to\infty}\mathcal{T}_i^{[t,s]}$, it clearly follows from Equation~\eqref{eq:lemma_transmatsystem_complete_rate_sequence_converges} that $Q_*=\lim_{i\to\infty} Q_i$. Because this sequence $\{Q_i\}_{i\in\nats}$ is in $\rateset$, and because $\rateset$ is closed, we must therefore have that $Q_*\in\rateset$. 

This contradicts our earlier statement that $Q_*\notin\rateset$, and therefore $Q_*\notin\smash{\overline{\partial}}_+\presuper{*}T_r^r$. A completely analogous argument shows that $Q_*\in\smash{\overline{\partial}}_-\presuper{*}T_r^r$ also leads to a contradiction. Therefore, we have that $\smash{\overline{\partial}}\presuper{*}T_r^r\subseteq\rateset$ for all $r\in\realsnonneg$, and hence $P_*\in\wmprocesses_\rateset$. Hence, we find that indeed $\mathcal{T}_*^{[t,s]}=\mathcal{T}_{P_*}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$.

Therefore, and because the Cauchy sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ in $\mathbb{T}_\rateset^{[t,s]}$ was arbitrary, we conclude that $\mathbb{T}_\rateset^{[t,s]}$ is complete.
\end{proof}
\begin{proof}[Proof of Claim~\ref{claim:lemma_restricted_trans_mat_system_complete_uniformly_well_behaved}]
We have to show that the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ in $\mathbb{T}_\rateset^{[t,s]}$ is uniformly well-behaved, meaning that there is some $B\in\realsnonneg$ such that for all $i\in\nats$ and all $r\in[t,s]$, it holds that
\begin{equation}\label{eq:restricted_trans_mat_sequence_uniformly_bounded}
\limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right)} < B,\quad\text{and,}\quad \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_{r-\Delta}^{r} - I\right)} < B\,.
\end{equation}

Let $B\coloneqq 2\norm{\rateset}$, and assume \emph{ex absurdo} that Equation~\eqref{eq:restricted_trans_mat_sequence_uniformly_bounded} does not hold. Then, there must be some $i\in\nats$ and some $r\in[t,s]$, such that either
\begin{equation*}
\limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right)} \geq B,\quad\text{or,}\quad \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}\left(\presuper{i}T_{r-\Delta}^{r} - I\right)} \geq B\,.
\end{equation*}
We only give a proof for the first case; the proof for the second case is completely analogous. Hence, in this case,
\begin{equation*}
(\forall \delta\in\realspos)(\exists \Delta\in(0,\delta))\,:\,\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right)} \geq B\,.
\end{equation*}
Because $\mathcal{T}_i^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$, there must be some process $P_i\in\wmprocesses_\rateset$ for which $\mathcal{T}_{P_i}^{[t,s]}=\mathcal{T}_i^{[t,s]}$. Because $P_i\in\wmprocesses_\rateset$, and due to Proposition~\ref{prop:outerderivativebehaveslikelimit}, this implies that
\begin{equation*}
(\exists \delta\in\realspos)(\forall\Delta\in(0,\delta))(\exists Q\in\rateset)\,:\,\norm{\frac{\presuper{i}T_r^{r+\Delta}-I}{\Delta} - Q} < \norm{\rateset}\,.
\end{equation*}
Consider this $\delta\in\realspos$. Then, there must be a $\Delta\in\realspos$ such that $\Delta<\delta$, and for which
\begin{equation*}
\norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right)} \geq B\,.
\end{equation*}
Consider this $\Delta$. Because $\Delta<\delta$, there must then be some $Q\in\rateset$ such that
\begin{equation*}
\norm{\frac{\presuper{i}T_r^{r+\Delta}-I}{\Delta} - Q} < \norm{\rateset}\,.
\end{equation*}
Consider this $Q$. Putting this together, we have that
\begin{align*}
2\norm{\rateset} = B &\leq \norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right)} \\
 &\leq \norm{\frac{1}{\Delta}\left(\presuper{i}T_r^{r+\Delta} - I\right) - Q} + \norm{Q} \\
 &< \norm{\rateset} + \norm{Q} \leq 2\norm{\rateset}\,.
\end{align*}
Hence, we have found a contradiction. The argument for the second case in Equation~\eqref{eq:restricted_trans_mat_sequence_uniformly_bounded} is exactly analogous, and also leads to a contradiction.

Therefore, we conclude that the sequence $\left\{\mathcal{T}_i^{[t,s]}\right\}_{i\in\nats}$ is uniformly well-behaved.
\end{proof}

\begin{lemma}\label{lemma:restricted_trans_mat_system_totally_bounded_if_Q_bounded_convex}
Consider any non-empty, bounded and convex set of rate matrices $\rateset$, and any $t,s\in\realsnonneg$ such that $t\leq s$. Then, the metric space $(\mathbb{T}_\rateset^{[t,s]},d)$ is totally bounded under the metric $d$, defined as in Equation~\eqref{eq:trans_mat_system_metric}.
\end{lemma}
\begin{proof}
We have to show that $(\mathbb{T}_\rateset^{[t,s]},d)$ is totally bounded, meaning that for all $\epsilon\in\realspos$, there exists a finite collection of open $\epsilon$-balls centered on elements of $\mathbb{T}_\rateset^{[t,s]}$, such that this collection covers $\mathbb{T}_\rateset^{[t,s]}$. 

Equivalently, we need to show that for all $\epsilon\in\realspos$, there is some set
\begin{equation*}
\mathbb{C}_\epsilon\coloneqq \left\{\mathcal{T}_i^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}\,:\,i\in\{1,\ldots,N\}\right\}\,,
\end{equation*}
with $N\in\nats$, such that
\begin{equation*}
(\forall \mathcal{T}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]})(\exists \mathcal{S}^{[t,s]}\in \mathbb{C}_\epsilon)\,:\,d(\mathcal{T}^{[t,s]},\mathcal{S}^{[t,s]}) < \epsilon\,.
\end{equation*}

Fix any $\epsilon\in\realspos$, and define $C\coloneqq (s-t)$. We will start by constructing $\mathbb{C}_\epsilon$. To ensure that the cover is open, choose first any $\epsilon^*<\epsilon$. Then, let
\begin{equation*}
\epsilon' \coloneqq \frac{\epsilon^*}{3C}\,.
\end{equation*}

Because $\rateset$ is bounded and finite-dimensional, it is totally bounded under the metric induced by our usual norm $\norm{\cdot}$. Therefore, $\rateset$ admits a finite cover of open balls with radius $\epsilon'$. In other words, there is some set
\begin{equation*}
\rateset_{\epsilon'}\coloneqq \left\{Q_i\in\rateset\,:\,i\in\{1,\ldots,N'\}\right\}\,,
\end{equation*}
with $N'\in\nats$, such that
\begin{equation*}
(\forall Q\in\rateset)(\exists Q_i\in\rateset_{\epsilon'})\,:\,\norm{Q - Q_i} < \epsilon'\,.
\end{equation*}
For each $Q_i\in\rateset_{\epsilon'}$, we let $\mathcal{T}_{Q_i}$ be the family of transition matrices defined as in Definition~\ref{def:systemfromQ}.

Now, because $\rateset$ is non-empty, bounded, and convex, due to Lemma~\ref{lemma:uniform_delta_for_convex_markov_set}, there is some $\delta\in\realspos$ such that, for all $P\in\wmprocesses_\rateset$, all $t\in\realsnonneg$, and all $\Delta\in\realspos$ with $\Delta<\delta$,
\begin{equation}\label{eq:lemma_total_bounded_uniform_delta}
(\exists Q\in\rateset)\,\norm{T_t^{t+\Delta} - (I+\Delta Q)} < \frac{\Delta\epsilon^*}{6C}\,.
\end{equation}
Consider this $\delta$. Let now
\begin{equation*}
\delta^* \coloneqq \min\left\{\frac{\epsilon^*}{6C\norm{\rateset}^2},\, \frac{\epsilon^*}{12\norm{\rateset}},\, \delta\right\}\,.
\end{equation*}

Choose now any $u\in\mathcal{U}_{[t,s]}$ with $\sigma(u)<\delta^*$, such that $u=t_0,\ldots,t_n$. Consider any $i\in\{1,\ldots,n\}$. We then let $\mathcal{T}_{Q_j}^{[t_{i-1},t_i]}\subset\mathcal{T}_{Q_j}$ be the set of all transition matrices in $\mathcal{T}_{Q_j}$ that are defined on the interval $[t_{i-1},t_i]$, for all $j\in\{1,\ldots,N'\}$.

We now consider the set of these families of transition matrices. For all $i\in\{1,\ldots,n\}$, let $\mathbb{T}_i$ be the set of families of transition matrices defined by
\begin{equation*}
\mathbb{T}_i \coloneqq \left\{ \mathcal{T}_{Q_j}^{[t_{i-1},t_i]} \,:\,Q_j\in\rateset_{\epsilon'} \right\}\,.
\end{equation*}
Because $\rateset_{\epsilon'}$ is finite, $\mathbb{T}_i$ is also clearly finite.

We now use the following claim, which is proved below.
\begin{claim}\label{claim:composition_restricted_trans_mat_sys_in_set}
For all $i\in\{1,\ldots,n\}$, choose some $\mathcal{T}_i^{[t_{i-1},t_i]}\in\mathbb{T}_i$. Then,
\begin{equation*}
\mathcal{T}_1^{[t_{0},t_1]} \otimes \mathcal{T}_2^{[t_{1},t_2]} \cdots \otimes \mathcal{T}_n^{[t_{n-1},t_n]} \in \mathbb{T}_\rateset^{[t,s]}\,.
\end{equation*}
\end{claim}
Because each $\mathbb{T}_i$ is finite, there are only finitely many ways in which the product in Claim~\ref{claim:composition_restricted_trans_mat_sys_in_set} can be constructed. Therefore, if we now let
\begin{equation*}
\mathbb{C}_\epsilon \coloneqq \left\{\mathcal{T}_1^{[t_{0},t_1]} \otimes \mathcal{T}_2^{[t_{1},t_2]} \cdots \otimes \mathcal{T}_n^{[t_{n-1},t_n]}\,:\,\left(\forall i\in\{1,\ldots,n\} \,:\,\mathcal{T}_i^{[t_{i-1},t_i]}\in\mathbb{T}_i\right) \right\}\,,
\end{equation*}
then $\mathbb{C}_\epsilon$ contains a finite number of elements, and, due to Claim~\ref{claim:composition_restricted_trans_mat_sys_in_set}, $\mathbb{C}_\epsilon\subset \mathbb{T}_\rateset^{[t,s]}$.

It remains to show that $\mathbb{C}_\epsilon$ generates an open $\epsilon$-cover of $\mathbb{T}_\rateset^{[t,s]}$. To this end, consider any $\mathcal{T}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$. We will show that there is some $\mathcal{S}^{[t,s]}\in \mathbb{C}_{\epsilon}$ such that $d(\mathcal{T}^{[t,s]},\mathcal{S}^{[t,s]})<\epsilon$. We start by constructing this $\mathcal{S}^{[t,s]}$.

Because $\mathcal{T}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$, it follows that there is some corresponding $P\in\wmprocesses_\rateset$ which agrees with $\mathcal{T}^{[t,s]}$ on all transition matrices $T_q^r\in\mathcal{T}^{[t,s]}$. 

Consider any $i\in\{1,\ldots,n\}$, and the corresponding transition matrix $T_{t_{i-1}}^{t_i}\in\mathcal{T}^{[t,s]}$. Clearly, we have that $T_{t_{i-1}}^{t_i}=T_{t_{i-1}}^{(t_{i-1}+\Delta_i)}$. Therefore, and because $\Delta_i\leq\sigma(u)<\delta^*\leq\delta$, it follows from Equation~\eqref{eq:lemma_total_bounded_uniform_delta} that there is some $Q_i\in\rateset$ such that
\begin{equation}\label{eq:lemma_total_bounded_full_interval_error_linear}
\norm{T_{t_{i-1}}^{t_i} - (I+\Delta_i Q_i)} < \frac{\Delta_i\epsilon^*}{6C}\,.
\end{equation}
Consider this $Q_i$. Because $Q_i\in\rateset$, it follows that there is some $\widetilde{Q}_i\in\rateset_{\epsilon'}$ such that
\begin{equation*}
\norm{Q_i - \widetilde{Q}_i} < \epsilon'\,.
\end{equation*}
Consider this $\widetilde{Q}_i$. Then, because $\widetilde{Q}_i\in\rateset_{\epsilon'}$, we have that $\mathcal{T}_{\widetilde{Q_i}}^{[t_{i-1},t_i]}\in\mathbb{T}_i$.

If we now repeat this selection for all $i\in\{1,\ldots,n\}$, we end up with a collection $\mathcal{T}_{\widetilde{Q_1}}^{[t_{0},t_1]},\ldots,\mathcal{T}_{\widetilde{Q_n}}^{[t_{n-1},t_n]}$ such that $\mathcal{T}_{\widetilde{Q_i}}^{[t_{i-1},t_i]}\in \mathbb{T}_i$ for all $i\in\{1,\ldots,n\}$. Hence, by the construction of $\mathbb{C}_{\epsilon'}$, we have that
\begin{equation*}
\mathcal{S}^{[t,s]}\coloneqq \mathcal{T}_{\widetilde{Q_1}}^{[t_{0},t_1]} \otimes \cdots \otimes \mathcal{T}_{\widetilde{Q_n}}^{[t_{n-1},t_n]} \in \mathbb{C}_\epsilon\,.
\end{equation*}
It remains to show that $d(\mathcal{T}^{[t,s]},\mathcal{S}^{[t,s]})<\epsilon$. We make use of the following two claims, which are proved below.
\begin{claim}\label{claim:lemma_total_bounded_full_interval_error}
Consider any $i\in\{1,\ldots,n\}$. Then, with $T_{t_{i-1}}^{t_i}\in\mathcal{T}^{[t,s]}$ and $S_{t_{i-1}}^{t_i}\in\mathcal{S}^{[t,s]}$, it holds that
\begin{equation*}
\norm{T_{t_{i-1}}^{t_i} - S_{t_{i-1}}^{t_i}} < \frac{\Delta_i\epsilon^*}{3C} + \Delta_i\epsilon'\,.
\end{equation*}
\end{claim}
\begin{claim}\label{claim:lemma_total_bounded_sub_interval_error}
Consider any $i\in\{1,\ldots,n\}$, and any $q,r\in[t_{i-1},t_i]$ such that $q\leq r$. Then, with $T_q^r\in\mathcal{T}^{[t,s]}$ and $S_q^r\in\mathcal{S}^{[t,s]}$, it holds that
\begin{equation*}
\norm{T_q^r - S_q^r} < \frac{\Delta_i\epsilon^*}{3C} + \frac{\epsilon^*}{6}\,.
\end{equation*}
\end{claim}

We first give a bound on the difference between two transition matrices in $\mathcal{T}^{[t,s]}$ and $\mathcal{S}^{[t,s]}$, for any given time points. To this end, consider any $q,r\in[t,s]$ such that $q\leq r$, and the transition matrices $T_q^r\in\mathcal{T}^{[t,s]}$ and $S_q^r\in\mathcal{S}^{[t,s]}$. We consider three different cases; either $q$ and $r$ coincide on some interval $[t_{i-1},t_i]$, or they lie in consecutive intervals $[t_{i-1},t_i]$ and $[t_i,t_{i+1}]$, or there is at least one interval $[t_{k-1},t_k]$ such that $q<t_{k-1}$ and $r>t_k$. 

If $q,r\in[t_{i-1},t_i]$ for some $i\in\{1,\ldots,n\}$, then it follows from Claim~\ref{claim:lemma_total_bounded_sub_interval_error} that
\begin{equation*}
\norm{T_q^r - S_q^r} < \frac{\Delta_i\epsilon^*}{3C} + \frac{\epsilon^*}{6} < \frac{\epsilon^*}{3} + \frac{\epsilon^*}{6} < \epsilon^*\,.
\end{equation*}

For the second case, suppose that $q\in[t_{i-1},t_i]$ and $r\in[t_i,t_{i+1}]$ for some $i\in\{1,\ldots,n-1\}$. Then, because $T_q^r$ and $S_q^r$ satisfy Equation~\eqref{eq:transmatrixproduct}, it follows from Lemma~\ref{lemma:recursive} and Claim~\ref{claim:lemma_total_bounded_sub_interval_error} that
\begin{align*}
\norm{T_q^r - S_q^r} &= \norm{T_q^{t_i}T_{t_i}^r - S_q^{t_i}S_{t_i}^r} \\
 &< \frac{\Delta_i\epsilon^*}{3C} + \frac{\Delta_{i+1}\epsilon^*}{3C} + \frac{\epsilon^*}{6} + \frac{\epsilon^*}{6} \\
 &= \frac{(\Delta_i+\Delta_{i+1})\epsilon^*}{3C} + \frac{\epsilon^*}{3} \\
 &\leq \frac{\epsilon^*}{3} + \frac{\epsilon^*}{3}\\
 &< \epsilon^*\,.
\end{align*}

In any other case, there must be some $i,j\in\{1,\ldots,n\}$ such that $i+1<j$, and for which $q\in[t_{i-1},t_i]$ and $r\in[t_{j-1},t_j]$. Therefore, and because $T_q^r$ and $S_q^r$ satisfy Equation~\eqref{eq:transmatrixproduct}, it follows from Lemma~\ref{lemma:recursive} and Claim~\ref{claim:lemma_total_bounded_full_interval_error} and~\ref{claim:lemma_total_bounded_sub_interval_error} that
\begin{align*}
\norm{T_q^r - S_q^r} &= \norm{T_q^{t_i}\left(\prod_{k=i+1}^{j-1}T_{t_{k-1}}^{t_k}\right)T_{t_{j-1}}^r - S_q^{t_i}\left(\prod_{k=i+1}^{j-1}S_{t_{k-1}}^{t_k}\right)S_{t_{j-1}}^r} \\
 &< \frac{\Delta_i\epsilon^*}{3C} + \frac{\epsilon^*}{6} + \left(\sum_{k=i+1}^{j-1}\frac{\Delta_k\epsilon^*}{3C} + \Delta_k\epsilon'\right) + \frac{\Delta_{j}\epsilon^*}{3C} + \frac{\epsilon^*}{6} \\
 &= \sum_{k=i}^j \frac{\Delta_k\epsilon^*}{3C} + \frac{\epsilon^*}{3} + \sum_{k=i+1}^{j-1}{\Delta_k\epsilon'} \\
 &\leq \frac{\epsilon^*}{3} + \frac{\epsilon^*}{3} + C\cdot\epsilon' \\
 &= \frac{\epsilon^*}{3} + \frac{\epsilon^*}{3} + \frac{\epsilon^*}{3} \\
 &= \epsilon^*\,.
\end{align*}

In summary, we have shown that for all $q,r\in[t,s]$ with $q\leq r$, it holds that
\begin{equation*}
\norm{T_q^r - S_q^r} < \epsilon^*\,,
\end{equation*}
with $T_q^r\in\mathcal{T}^{[t,s]}$ and $S_q^r\in\mathcal{S}^{[t,s]}$. Because this holds for all $q$ and $r$, it follows that
\begin{equation*}
d(\mathcal{T}^{[t,s]},\mathcal{S}^{[t,s]}) = \sup\{\norm{T_q^r - S_q^r}\,:\,q,r\in[t,s], q\leq r\} \leq \epsilon^* < \epsilon\,.
\end{equation*}
Because this holds for any $\mathcal{T}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$, it follows that $\mathbb{C}_\epsilon$ is a finite, open $\epsilon$-cover of $\mathbb{T}_\rateset^{[t,s]}$. Because the $\epsilon\in\realspos$ was arbitrary, we conclude that $\mathbb{T}_\rateset^{[t,s]}$ is totally bounded.
\end{proof}

\begin{proof}[Proof of Claim~\ref{claim:composition_restricted_trans_mat_sys_in_set}]
For all $i\in\{1,\ldots,n\}$, choose some $\mathcal{T}_i^{[t_{i-1},t_i]}\in\mathbb{T}_i$. Let
\begin{equation*}
\mathcal{T}^{[t,s]}\coloneqq \mathcal{T}_1^{[t_{0},t_1]} \otimes \mathcal{T}_2^{[t_{1},t_2]} \cdots \otimes \mathcal{T}_n^{[t_{n-1},t_n]}\,.
\end{equation*}
Because for all $i\in\{1,\ldots,n\}$ we have that $\mathcal{T}_i^{[t_{i-1},t_i]}$ is a well-behaved restricted transition matrix system, it follows from Proposition~\ref{prop:concat_restr_trans_mat_systems_is_system} that $\mathcal{T}^{[t,s]}$ is a well-behaved restricted transition matrix system defined on $[t,s]$.

We now have to show that $\mathcal{T}^{[t,s]} \in \mathbb{T}_\rateset^{[t,s]}$. To this end, consider any $Q\in\rateset$, and let $\mathcal{T}_Q$ be the transition matrix system corresponding to $Q$, defined as in Definition~\ref{def:systemfromQ}. Let
\begin{equation*}
\mathcal{T} \coloneqq \mathcal{T}_Q^{[0,t]}\otimes \mathcal{T}^{[t,s]} \otimes \mathcal{T}_Q^{[s,\infty)}\,.
\end{equation*}
Then, clearly, $\mathcal{T}$ is an (unrestricted) transition matrix system, and because $\mathcal{T}^{[t,s]}$ and $\mathcal{T}_Q$ are well-behaved, $\mathcal{T}$ is also well-behaved. Therefore, and due to Theorem~\ref{theo:uniqueMarkovchain}, there is some $P\in\wmprocesses$ for which $\mathcal{T}_P = \mathcal{T}$.

We will show that $P\in\wmprocesses_\rateset$, which then implies that $\mathcal{T}_P = \mathcal{T}\in\mathbb{T}_\rateset^{[t,s]}$. To show that $P\in\wmprocesses_\rateset$, we have to show that $\smash{\overline{\partial}}T_r^r\subseteq\rateset$ for all $r\in\realsnonneg$. To this end, consider any $r\in\realsnonneg$.

We will consider several cases. If $r<t$, we have that $\smash{\overline{\partial}}T_r^r$ corresponds to $\mathcal{T}_Q^{[0,t]}$, and hence $\smash{\overline{\partial}}T_r^r=\{Q\}\subseteq\rateset$. If $r>s$, then $\smash{\overline{\partial}}T_r^r$ corresponds to $\mathcal{T}_Q^{[s,\infty)}$, in which case also $\smash{\overline{\partial}}T_r^r=\{Q\}\subseteq\rateset$.

Next, if $r\in(t_{i-1},t_i)$ for some $i\in\{1,\ldots,n\}$, then $\smash{\overline{\partial}}T_r^r$ corresponds to $\mathcal{T}_i^{[t_{i-1},t_i]}=\mathcal{T}_{Q_i}^{[t_{i-1},t_i]}$ for some $Q_i\in\rateset_{\epsilon'}$, and hence $\smash{\overline{\partial}}T_r^r=\{Q_i\}$. Because $\rateset_{\epsilon'}\subseteq\rateset$, it follows that then also $\smash{\overline{\partial}}T_r^r\subseteq\rateset$.

The remaining cases are when $r=t_i$ for some $i\in\{0,\ldots,n\}$. Suppose that, for some $i\in\{1,\ldots,n-1\}$, it holds that $r=t_i$. Then, $\smash{\overline{\partial}}_-T_r^r=\{Q_{i}\}$, and $\smash{\overline{\partial}}_+T_r^r=\{Q_{i+1}\}$. Hence,
\begin{equation*}
\smash{\overline{\partial}}T_r^r = \smash{\overline{\partial}}_-T_r^r\cup\smash{\overline{\partial}}_+T_r^r=\{Q_{i},Q_{i+1}\}\subseteq\rateset\,.
\end{equation*}
Finally, if $r=t_0$, then $\smash{\overline{\partial}}_-T_r^r=\{Q\}$ and $\smash{\overline{\partial}}_+T_r^r=\{Q_1\}$, and hence $\smash{\overline{\partial}}T_r^r\subseteq\rateset$. If $r=t_n$, we have $\smash{\overline{\partial}}_-T_r^r=\{Q_n\}$ and $\smash{\overline{\partial}}_+T_r^r=\{Q\}$, and therefore $\smash{\overline{\partial}}T_r^r\subseteq\rateset$.

In summary, we have found that $\smash{\overline{\partial}}T_r^r\subseteq\rateset$ for all $r\in\realsnonneg$, and hence $P\in\wmprocesses_\rateset$. Therefore, $\mathcal{T}_P^{[t,s]}=\mathcal{T}^{[t,s]}\in\mathbb{T}_\rateset^{[t,s]}$.
\end{proof}

\begin{proof}[Proof of Claim~\ref{claim:lemma_total_bounded_full_interval_error}]
Consider any $i\in\{1,\ldots,n\}$. Then, with $T_{t_{i-1}}^{t_i}\in\mathcal{T}^{[t,s]}$ and $S_{t_{i-1}}^{t_i}\in\mathcal{S}^{[t,s]}$, it follows from Equation~\eqref{eq:lemma_total_bounded_full_interval_error_linear} that there is some $Q_i\in\rateset$ such that
\begin{align*}
\norm{T_{t_{i-1}}^{t_i} - S_{t_{i-1}}^{t_i}} &\leq \norm{T_{t_{i-1}}^{t_i} - (I+\Delta_iQ_i)} + \norm{(I+\Delta_iQ_i) - S_{t_{i-1}}^{t_i}} \\
 &\leq \norm{T_{t_{i-1}}^{t_i} - (I+\Delta_iQ_i)} + \norm{(I+\Delta_iQ_i) - (I+\Delta_i\widetilde{Q}_i)} + \norm{(I+\Delta_i\widetilde{Q}_i) - S_{t_{i-1}}^{t_i}} \\
 &< \frac{\Delta_i\epsilon^*}{6C} + \Delta_i\epsilon' + \norm{(I+\Delta_i\widetilde{Q}_i) - S_{t_{i-1}}^{t_i}} \\
 &= \frac{\Delta_i\epsilon^*}{6C} + \Delta_i\epsilon' + \norm{(I+\Delta_i\widetilde{Q}_i) - e^{\widetilde{Q}_i\cdot\Delta_i}} \\
 &\leq \frac{\Delta_i\epsilon^*}{6C} + \Delta_i\epsilon' + \Delta_i^2\norm{\rateset}^2\,,
\end{align*}
where the strict equality follows from the definition of $\mathcal{S}^{[t,s]}$, and the final inequality follows from Lemma~\ref{lemma:linearpartofexponential}. Furthermore, because $\Delta_i\leq\sigma(u)<\delta^*\leq\nicefrac{\epsilon^*}{(6C\norm{\rateset}^2)}$, we have that
\begin{equation*}
\norm{T_{t_{i-1}}^{t_i} - S_{t_{i-1}}^{t_i}} < \frac{\Delta_i\epsilon^*}{6C} + \Delta_i\epsilon' + \Delta_i^2\norm{\rateset}^2 < 2\frac{\Delta_i\epsilon^*}{6C} + \Delta_i\epsilon' = \frac{\Delta_i\epsilon^*}{3C} + \Delta_i\epsilon'\,.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Claim~\ref{claim:lemma_total_bounded_sub_interval_error}]
Consider any $i\in\{1,\ldots,n\}$, and any $q,r\in[t_{i-1},t_i]$ such that $q\leq r$. Consider the transition matrices $T_q^r\in\mathcal{T}^{[t,s]}$ and $S_q^r\in\mathcal{S}^{[t,s]}$. Then, because $(r-q)\leq\Delta_i\leq\sigma(u)<\delta^*\leq\delta$, it follows from Equation~\ref{eq:lemma_total_bounded_uniform_delta} that there is some $Q\in\rateset$ such that
\begin{align*}
\norm{T_q^r - S_q^r} &< \frac{(r-q)\epsilon^*}{6C} + \norm{(I+(r-q)Q) - S_q^r} \\
 &\leq \frac{(r-q)\epsilon^*}{6C} + \norm{(I+(r-q)Q) - (I+(r-q)\widetilde{Q}_i)} + \norm{(I+(r-q)\widetilde{Q}_i) - S_q^r} \\
 &\leq \frac{(r-q)\epsilon^*}{6C} + 2(r-q)\norm{\rateset} + \norm{(I+(r-q)\widetilde{Q}_i) - S_q^r} \\
 &= \frac{(r-q)\epsilon^*}{6C} + 2(r-q)\norm{\rateset} + \norm{(I+(r-q)\widetilde{Q}_i) - e^{\widetilde{Q}_i\cdot(r-q)}} \\
 &\leq \frac{(r-q)\epsilon^*}{6C} + 2(r-q)\norm{\rateset} + (r-q)^2\norm{\rateset}^2 \\
 &\leq \frac{\Delta_i\epsilon^*}{6C} + 2(r-q)\norm{\rateset} + \Delta_i^2\norm{\rateset}^2 \\
 &\leq \frac{\Delta_i\epsilon^*}{6C} + 2(r-q)\norm{\rateset} + \frac{\Delta_i\epsilon^*}{6C}\,,
\end{align*}
where the last inequality follows from the fact that $\Delta_i\leq\sigma(u)<\delta^*\leq\nicefrac{\epsilon^*}{(6C\norm{\rateset}^2)}$. Hence, and because $(r-q)\leq\Delta_i\leq\sigma(u)<\delta^*\leq\nicefrac{\epsilon^*}{12\norm{\rateset}}$, we have
\begin{equation*}
\norm{T_q^r - S_q^r} < \frac{\Delta_i\epsilon^*}{3C} + 2\Delta_i\norm{\rateset} < \frac{\Delta_i\epsilon^*}{3C} + \frac{\epsilon^*}{6}\,.
\end{equation*}
\end{proof}

\begin{corollary}\label{cor:restricted_trans_mat_system_totally_bounded_if_Q_bounded}
Consider any non-empty bounded set of rate matrices $\rateset$, and any $t,s\in\realsnonneg$ such that $t\leq s$. Then, the metric space $(\mathbb{T}_\rateset^{[t,s]},d)$ is totally bounded under the metric $d$, defined as in Equation~\eqref{eq:trans_mat_system_metric}.
\end{corollary}
\begin{proof}
Let $\widetilde{\rateset}$ denote the convex closure of $\rateset$. Then, clearly, $\widetilde{\rateset}$ is a non-empty, bounded, and convex set of rate matrices, and furthermore, $\mathbb{T}_\rateset^{[t,s]}\subseteq \mathbb{T}_{\widetilde{\rateset}}^{[t,s]}$.

By Lemma~\ref{lemma:restricted_trans_mat_system_totally_bounded_if_Q_bounded_convex}, $\mathbb{T}_{\widetilde{\rateset}}^{[t,s]}$ is totally bounded. Therefore, and because any subset of a totally bounded set is itself totally bounded~{\bf CITE}, it follows that $\mathbb{T}_\rateset^{[t,s]}$ is totally bounded as well.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theorem:restricted_transmatsystem_space_compact_if_Q_closed}]
Immediate consequence of Lemma~\ref{lemma:restricted_trans_mat_system_complete_if_Q_closed} and Corollary~\ref{cor:restricted_trans_mat_system_totally_bounded_if_Q_bounded}.
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:lowertrans}}

***** Still need to add proofs for \ref{lem:normlratefinite} \ref{lemma:normofcoherenttrans} \ref{lemma:normQsmallenough} \ref{lemma:lower_trans_to_lower_rate}.

\begin{proof}[Proof of Proposition~\ref{lemma:completemetricspace}]
Define for all $\lt\in\underline{\mathcal{T}}$ and all $x\in\states$ the map $\lt_x:\gamblesX\rightarrow\reals$ as
\begin{equation*}
\lt_x(f) \coloneqq \lt(f)(x)\,,\quad\text{for all $f\in\gamblesX$,}
\end{equation*}
and let $\underline{\mathcal{T}}_x\coloneqq\left\{\lt_x\,:\,\lt\in\underline{\mathcal{T}}\right\}$ for all $x\in\states$. Then clearly, any $\lt\in\underline{\mathcal{T}}$ is a finite vector of elements $\lt_1\in\underline{\mathcal{T}}_1,\ldots,\lt_m\in\underline{\mathcal{T}}_m$, and $\underline{\mathcal{T}}=\underline{\mathcal{T}}_1\times\cdots\times \underline{\mathcal{T}}_m$.

Furthermore, for all $x\in\states$ and all $\lt_x\in\underline{\mathcal{T}}_x$, because of Definition~\ref{def:coh_low_trans}, $\lt_x$ is a map from $\gamblesX$ to $\reals$ that is super-additive, positively homogeneous, and bounded below by the minimum operator. Hence, by definition~\cite[Definition~2.3.3]{Walley:1991vk}, $\lt_x$ is a coherent lower prevision on $\gamblesX$, and $\underline{\mathcal{T}}_x$ corresponds to the space of all coherent lower previsions on $\gamblesX$.

Let now $\gambles_{\leq1}(\states)\coloneqq\left\{f\in\gamblesX\,:\,\forall x\in\states, 0\leq f(x)\leq 1\right\}$ be the set of non-negative functions $f\in\gamblesX$ with $\norm{f}\leq 1$. It was previously shown~\cite{DeBock:2015ck} that the metric space $(\underline{\mathcal{T}}_x,d_x)$ is compact under the topology generated by the metric $d_x$, defined for all $\lt_x,\underline{S}_x\in\underline{\mathcal{T}}_x$ by
\begin{equation*}
d_x(\lt_x,\underline{S}_x) \coloneqq \sup\bigl\{ \abs{\lt_xf - \underline{S}_xf} \,:\,f\in\gambles_{\leq1}(\states) \bigr\}\,.
\end{equation*}
Now consider the metric $d_x^*$, which we define for all $\lt_x,\underline{S}_x\in\underline{\mathcal{T}}_x$ by
\begin{equation*}
d_x^*(\lt_x,\underline{S}_x) \coloneqq \sup\left\{ \abs{\lt_xf - \underline{S}_xf}\,:\, f\in\gamblesX, \norm{f}=1\right\}\,.
\end{equation*}
It is fairly easy to see that for all $\lt_x,\underline{S}_x\in\underline{\mathcal{T}}_x$, we have that
\begin{equation*}
d_x(\lt_x,\underline{S}_x) \leq d_x^*(\lt_x,\underline{S}_x) \leq 2d_x(\lt_x,\underline{S}_x)\,,
\end{equation*}
from which it follows that any subset of $\underline{\mathcal{T}}_x$ that is open with respect to $d_x$ is also open with respect to $d_x^*$. Hence, $d_x$ and $d_x^*$ generate the same topology on $\underline{\mathcal{T}}_x$, and therefore because $(\underline{\mathcal{T}}_x, d_x)$ is compact, so is $(\underline{\mathcal{T}}_x,d_x^*)$. Because $(\underline{\mathcal{T}}_x,d_x^*)$ is a metric space, compactness now implies that $(\underline{\mathcal{T}}_x,d_x^*)$ is complete.

Therefore~\cite[Theorem 10.5.1]{OSearcoid:2006}, and because $\underline{\mathcal{T}}$ is a finite product of $\underline{\mathcal{T}}_1,\ldots,\underline{\mathcal{T}}_m$, the metric space $(\underline{\mathcal{T}},D)$ is complete under any metric $D$ that is \emph{conserving}~\cite[Definition 1.6.2]{OSearcoid:2006} with respect to $d_1^*,\ldots,d_m^*$. For $D$ to be conserving, it suffices to show that for all $\lt,\underline{S}\in\underline{\mathcal{T}}$,
\begin{equation*}
D(\lt, \underline{S}) = \max_{x\in\states}\bigl\{d_x^*(\lt_x, \underline{S}_x)\bigr\}\,.
\end{equation*}
Consider the metric $d$ on $\underline{\mathcal{T}}$ that is induced by $\norm{\cdot}$. We have, for any $\lt,\underline{S}\in\underline{\mathcal{T}}$, 
\begin{align*}
d(\lt,\underline{S}) &= \norm{\lt - \underline{S}} \\
% &= \sup\left\{ \norm{\lt f - \underline{S}f}\,:\,f\in\gamblesX, \norm{f}=1 \right\} \\
% &= \sup\left\{ \max_{x\in\states}\{\abs{\lt(f)(x) - \underline{S}(f)(x)}\}\,:\,f\in\gamblesX, \norm{f}=1 \right\} \\
 &= \sup\left\{ \max_{x\in\states}\{\abs{\lt_xf - \underline{S}_xf}\}\,:\,f\in\gamblesX, \norm{f}=1 \right\} \\
 &=  \max_{x\in\states}\bigl\{\sup\left\{\abs{\lt_xf - \underline{S}_xf}\,:\,f\in\gamblesX, \norm{f}=1 \bigr\}\right\} \\
 &=  \max_{x\in\states}\left\{d_x^*(\lt_x, \underline{S}_x)\right\}\,.
\end{align*}
Thus, $d$ is conserving with respect to $d_1^*,\ldots,d_m^*$, and hence $(\underline{\mathcal{T}},d)$ is complete.
\end{proof}

\begin{lemma}\label{lemma:differencenormofcoherenttransrate}
Consider any two non-negatively homogeneous operators $A$, $B$ from $\gamblesX$ to $\gamblesX$, and let $\lrate$ be an arbitrary lower transition rate operator. Then, it holds that $\norm{\lrate A-\lrate B}\leq 2\norm{\lrate}\norm{A-B}$.
\end{lemma}
\begin{proof}
*** {\bf TODO } *** This can be shown to follow from the definition of the norm and the properties of $\lrate$.
\end{proof}

\begin{lemma}\label{lemma:differencenormofcoherenttrans}
Consider any two non-negatively homogeneous operators $A$, $B$ from $\gamblesX$ to $\gamblesX$, and let $\lt$ be an arbitrary lower transition operator. Then, it holds that $\norm{\lt A-\lt B}\leq \norm{A-B}$.
\end{lemma}
\begin{proof}
*** {\bf TODO } *** This can be shown to follow from coherence.
\end{proof}

\begin{lemma}\label{lemma:justtheindicator}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}\leq\Delta\norm{\lrate}.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}
&=\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-\prod_{i=1}^{n-1}(I+\Delta_i\lrate)+\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&\leq\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-\prod_{i=1}^{n-1}(I+\Delta_i\lrate)}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&\leq\norm{(I+\Delta_n\lrate)-I}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}\\
&=\Delta_n\norm{\lrate}+\norm{\prod_{i=1}^{n-1}(I+\Delta_i\lrate)-I}
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:differencenormofcoherenttrans}. By repeating this argument over and over again (actually, by induction), we find that
\begin{align*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-I}
\leq \Delta_n\norm{\lrate} +\Delta_{n-1}\norm{\lrate}+\cdots
+\Delta_1\norm{\lrate}
=\Delta\norm{\lrate}.
\end{align*}
\end{proof}

\begin{lemma}\label{lemma:justthelinearpart}
Consider any sequence $0<\Delta_i\leq\nicefrac{1}{\norm{\lrate}}$, $i=1,\dots,n$, and let $\Delta\coloneqq\sum_{i=1}^n\Delta_i$. Then
\begin{equation*}
\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\leq\Delta^2\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&=\norm{\prod_{i=2}^n(I+\Delta_i\lrate)+\Delta_1\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-(I+\sum_{i=2}^n\Delta_i\lrate)-\Delta_1\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\norm{\Delta_1\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-\Delta_1\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1\norm{\lrate\left(\prod_{i=2}^n(I+\Delta_i\lrate)\right)-\lrate}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1 2\norm{\lrate}\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-I},
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:differencenormofcoherenttransrate}. Due to Lemma~\ref{lemma:justtheindicator}, this implies that
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&\leq\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+\Delta_1 2\norm{\lrate}\left(\sum_{i=2}^n\Delta_i\right)\norm{\lrate}\\
&=\norm{\prod_{i=2}^n(I+\Delta_i\lrate)-(I+\sum_{i=2}^n\Delta_i\lrate)}+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right).
\end{align*}
By continuing in this way (applying induction) we find that
\begin{align*}
&\norm{\prod_{i=1}^n(I+\Delta_i\lrate)-(I+\Delta\lrate)}\\
&\leq
\norm{\prod_{i=n}^n(I+\Delta_i\lrate)-(I+\sum_{i=n}^n\Delta_i\lrate)}
+2\norm{\lrate}^2\Delta_{n-1}\left(\sum_{i=n}^n\Delta_i\right)
+\cdots
+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right)\\
&=2\norm{\lrate}^2\Delta_{n-1}\left(\sum_{i=n}^n\Delta_i\right)
+\cdots
+2\norm{\lrate}^2\Delta_1\left(\sum_{i=2}^n\Delta_i\right)\\
&=2\norm{\lrate}^2\sum_{k=1}^n\Delta_k\sum_{i=k+1}^n\Delta_i\\
&\leq2\norm{\lrate}^2\frac{1}{2}\left(\sum_{k=1}^n\Delta_k\right)^2=\Delta^2\norm{\lrate}^2
\end{align*}
\end{proof}

\begin{lemma}\label{lemma:differencebetweennested}
For any $k\in\{1,\dots,n\}$, consider a sequence of $\Delta_{k,i}>0$, $i=1,\dots,n_k$ and let $\Delta_k\coloneqq\sum_{i=1}^{n_k}\Delta_{n,k}$. Let $\Delta\coloneqq\sum_{k=1}^n\Delta_k$ and let $\alpha\coloneqq\max\{\Delta_k\colon k\in\{1,\dots,n\}\}$. If $\alpha\leq\nicefrac{1}{\norm{\lrate}}$, then
\begin{equation*}
\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}
\leq\alpha\Delta\norm{\lrate}^2.
\end{equation*}
\end{lemma}
\begin{proof}
\begin{align*}
&\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}\\
&=\norm{\left(\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)\right)\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&\leq\norm{
\left(\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)\right)\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&=\norm{
\left(
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
}\\
&\leq\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}
\norm{
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)(I+\Delta_n\lrate)
},
\end{align*}

\noindent
which, because of Lemma~\ref{lemma:productiscoherent}, \ref{lemma:normofcoherenttrans} and~\ref{lemma:differencenormofcoherenttrans}, implies that

\begin{align*}
&\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}\\
&\leq\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}\\
&~~~~+\norm{
\left(\prod_{i=1}^{n_n}(I+\Delta_{n,i}\lrate)\right)
-
(I+\Delta_n\lrate)
}\\
&\leq
\norm{
\left(
\prod_{k=1}^{n-1}\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
\right)
-
\left(\prod_{k=1}^{n-1}(I+\Delta_k\lrate)\right)
}
+
\Delta_n^2\norm{\lrate}^2,
\end{align*}
where the last inequality follows from Lemma~\ref{lemma:justthelinearpart}.

By continuing in this way (applying induction), we find that
\begin{align*}
\norm{\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right)
-
\prod_{k=1}^n(I+\Delta_k\lrate)
}
&\leq
\Delta_1^2\norm{\lrate}^2+\cdot+\Delta_k^2\norm{\lrate}^2+\cdot
+
\Delta_n^2\norm{\lrate}^2\\
&\leq
\alpha\Delta_1\norm{\lrate}^2+\cdot+\alpha\Delta_k\norm{\lrate}^2+\cdot
+
\alpha\Delta_n\norm{\lrate}^2\\
&=
\alpha\Delta\norm{\lrate}^2
\end{align*}
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:differencebetweenu}]
Consider any $u'\in\mathcal{U}_{[t,s]}$ that is finer than $u$ and $u^*$, meaning that the timepoints it consists of contain the timepoints in $u$ and the timepoints in $u^*$. For example, let $u'$ be the ordered union of the timepoints in $u$ and $u^*$.

This implies that, for all $k\in\{1,\dots,n\}$, there is some sequence $\Delta_{k,i}>0$, $i\in\{1,\dots,n_k\}$, such that $\Delta_k=\sum_{i=1}^{n_k}\Delta_{k,i}$ and
\begin{equation*}
\Phi_{u'}\coloneqq\prod_{k=1}^n\left(\prod_{i=1}^{n_k}(I+\Delta_{k,i}\lrate)\right).
\end{equation*}
It then follows from Lemma~\ref{lemma:differencebetweennested} that $\norm{\Phi_{u'}-\Phi_u}\leq\alpha\Delta\norm{\lrate}^2$. 

Similarly, for all $k\in\{1,\dots,n^*\}$, there is some sequence $\Delta^*_{k,i}>0$, $i\in\{1,\dots,n^*_k\}$, such that $\Delta^*_k=\sum_{i=1}^{n^*_k}\Delta^*_{k,i}$ and
\begin{equation*}
\Phi_{u'}\coloneqq\prod_{k=1}^{n^*}\left(\prod_{i=1}^{n^*_k}(I+\Delta^*_{k,i}\lrate)\right).
\end{equation*}
It then follows from Lemma~\ref{lemma:differencebetweennested} that $\norm{\Phi_{u'}-\Phi_{u^*}}\leq\alpha\Delta\norm{\lrate}^2$.

Hence, we find that
\begin{equation*}
\norm{\Phi_{u}-\Phi_{u^*}}
=
\norm{\Phi_{u}-\Phi_{u'}+\Phi_{u'}-\Phi_{u^*}}
\leq
\norm{\Phi_{u}-\Phi_{u'}}
+
\norm{\Phi_{u'}-\Phi_{u^*}}
\leq2\alpha\Delta\norm{\lrate}^2.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Corollary~\ref{corol:limitexistsandiscoherent}]
Since $\lim_{n\to\infty}\sigma(u_n)=0$, and because of Lemma~\ref{lemma:productiscoherent}, there is some index $i$ such that the sequence $\Phi_{u_i},\Phi_{u_{i+1}},\dots,\Phi_{u_n},\dots$ consists of lower transition operators. Due to Corollary~\ref{corol:cauchy}, this sequence is Cauchy and therefore, because of Lemma~\ref{lemma:completemetricspace}, this sequence has a limit that is also a lower transition operator. Since the limit starting from $i$ and the limit starting from $1$ are identical (initial elements do not influence the limit), we find that the sequence $\Phi_{u_1},\Phi_{u_2},\dots,\Phi_{u_n},\dots$ has a limit, and that this limit is a lower transition operator.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theo:convergencelowerbound}]
Start by considering any sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{i\to\infty}\sigma(u_i)=0$. Due to Corollary~\ref{corol:limitexistsandiscoherent}, the sequence $\{\Phi_{u_i}\}_{i\in\nats}$ converges to a lower transition operator, which we denote by $\lt$. 

Consider now any $\epsilon>0$ and let $\Delta\coloneqq s-t$ and
\begin{equation*}
\delta\coloneqq\min\left\{\frac{\epsilon}{4\Delta\norm{\lrate}^2},\frac{1}{\norm{\lrate}}\right\}.
\end{equation*}

\noindent Since $\{\Phi_{u_i}\}_{i\in\nats}$ converges to $\lt$, there is some $N\in\nats$ such that
\begin{equation*}
(\forall n\geq N)~\norm{\lt - \Phi_{u_n}}<\frac{\epsilon}{2}.
\end{equation*}
Therefore, since $\lim_{i\to\infty}\sigma(u_i)=0$, there is some $N^*\geq N$ such that
\begin{equation*}
\sigma(u_{N^*})<\delta\text{ and }\norm{\lt - \Phi_{u_{N^*}}}<\frac{\epsilon}{2}
\end{equation*}

\noindent Consider now any $u\in\mathcal{U}_{[t,s]}$ such that $\sigma(u)<\delta$. Then

\begin{equation*}
\norm{\lt - \Phi_u}\leq\norm{\lt-\Phi_{u_{N^*}}}
+\norm{\Phi_{u_{N^*}}-\Phi_u}
<\frac{\epsilon}{2}+2\delta\Delta\norm{\lrate}^2\leq\epsilon,
\end{equation*}
where the strict inequality follows from Proposition~\ref{prop:differencebetweenu}.
In summary, we have shown that there is lower transition operator $\lt$ such that
\begin{equation*}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall u\in\mathcal{U}_{[t,s]}\colon\sigma(u)<\delta)~\norm{\lt - \Phi_u}<\epsilon\,.
\end{equation*}
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:lower_trans_system_is_system}]
We start by showing that for all $t\in\realsnonneg$, it holds that $L_t^t=I$. To this end, consider any $t\in\realsnonneg$. Then, the set $\mathcal{U}_{[t,t]}$ of sequences of time points that partition the interval $[t,t]$ only contains degenerate sequences. That is, for all $u\in\mathcal{U}_{[t,t]}$, it holds that $t_0=t_1=\cdots=t_n=t$. Therefore, the corresponding differences $\Delta_1,\ldots,\Delta_n$ satisfy $\Delta_j=0$ for all $j\in\{1,\ldots,n\}$. Hence, $\lim_{i\to\infty}\sigma(u_i)=0$ trivially holds for any sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,t]}$. Consider now any such sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,t]}$. Then, for all $i\in\nats$, we have
\begin{equation*}
\Phi_{u_i} = \prod_{k=1}^n(I+\Delta_k\lrate) = \prod_{k=1}^n I = I\,.
\end{equation*}
Hence, $\lim_{i\to\infty}\Phi_{u_i}=I$, and by Theorem~\ref{theo:convergencelowerbound}, it now follows that $L_t^t=\lim_{i\to\infty}\Phi_{u_i}=I$.

We next show that for all $t,r,s,\in\realsnonneg$ such that $t\leq r\leq s$, it holds that $L_t^s=L_t^rL_r^s$. To this end, consider any $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,r]}$ and any $\{v_i\}_{i\in\nats}$ in $\mathcal{U}_{[r,s]}$, such that $\lim_{i\to\infty}\sigma(u_i)=0$ and $\lim_{i\to\infty}\sigma(v_i)=0$. Then, by Theorem~\ref{theo:convergencelowerbound}, $\lim_{i\to\infty}\Phi_{u_i}=L_t^r$ and $\lim_{i\to\infty}\Phi_{v_i}=L_r^s$. Denote $u_i=t_0^i,\ldots,t_{n_i}^i$, and $v_i=s_0^i,\ldots,s_{m_i}^i$. Let the differences be denoted as $\Delta_1^{u_i},\ldots,\Delta_{n_i}^{u_i}$ and $\Delta_1^{v_i},\ldots,\Delta_{m_i}^{v_i}$ for $u_i$ and $v_i$, respectively.

For all $i\in\nats$, let now $w_i\in\mathcal{U}_{[t,s]}$ be such that $w_i=u_i\cup v_i$. Then, clearly, $w_i=t_0^i,\ldots,t_{n_i}^i,s_0^i,\ldots,s_{m_i}^i$, and because $t_{n_i}^i=r=s_0^i$, it holds that $\sigma(w_i)=\max\{\sigma(u_i),\sigma(v_i)\}$. Therefore, we find that $\lim_{i\to\infty}\sigma(w_i)=0$. Consider now the corresponding sequence $\{\Phi_{w_i}\}_{i\in\nats}$. For all $i\in\nats$, this satisfies
\begin{equation*}
\Phi_{w_i} = \prod_{k=1}^{n_i}(I+\Delta_{k}^{u_i}\lrate)\prod_{k=1}^{m_i}(I+\Delta_{k}^{v_i}\lrate) = \Phi_{u_i}\Phi_{v_i}\,.
\end{equation*}
Furthermore, we have that
\begin{equation*}
\lim_{i\to\infty}\Phi_{w_i} = \lim_{i\to\infty}\{\Phi_{u_i}\Phi_{v_i}\} = \lim_{i\to\infty}\{\Phi_{u_i}\}\lim_{i\to\infty}\{\Phi_{v_i}\}\,.
\end{equation*}
Due to Theorem~\ref{theo:convergencelowerbound}, this now implies that
\begin{equation*}
L_t^s = \lim_{i\to\infty}\Phi_{w_i} = \lim_{i\to\infty}\{\Phi_{u_i}\}\lim_{i\to\infty}\{\Phi_{v_i}\} = L_t^rL_r^s\,.
\end{equation*}
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:lower_transition_is_homogeneous}]
Consider any $t,s\in\realsnonneg$ such that $t\leq s$, any $\Delta\in\realsnonneg$, and any sequence $\{u_i\}_{i\in\nats}$ in $\mathcal{U}_{[t,s]}$ such that $\lim_{i\to\infty}\sigma(u)=0$. Then, by Theorem~\ref{theo:convergencelowerbound}, $\lim_{i\to\infty}\Phi_{u_i}=L_t^s$.

For any $u_i$ in $\{u_i\}_{i\in\nats}$ such that $u_i=t_0,\ldots,t_n$, define the sequence $u_i^*=(t_0+\Delta),(t_1+\Delta),\ldots,(t_n+\Delta)$. Then, for all $i\in\nats$, we have that $u_i^*\in\mathcal{U}_{[t+\Delta,s+\Delta]}$. Furthermore, because $\lim_{i\to\infty}\sigma(u_i)=0$, we have $\lim_{i\to\infty}\sigma(u_i^*)=0$. Therefore, and by Theorem~\ref{theo:convergencelowerbound},  it holds that $\lim_{i\to\infty}\Phi_{u_i^*}=L_{t+\Delta}^{s+\Delta}$.

Consider now any $u_i=t_0,\ldots,t_n$, $i\in\nats$, with differences $\Delta_1,\ldots,\Delta_n$. Then, the corresponding sequence $u_i^*$ has differences $\Delta^*_j=(t_j+\Delta)-(t_{j-1}+\Delta)=\Delta_j$, for all $j\in\{1,\ldots,n\}$. Therefore, and by the definition of $\Phi_{u_i}$ and $\Phi_{u_i^*}$, we have that $\Phi_{u_i}=\Phi_{u_i^*}$. Hence, and because the $i\in\nats$ was arbitrary, we find that $\{\Phi_{u_i}\}_{i\in\nats}=\{\Phi_{u_i^*}\}_{i\in\nats}$. Because these sequences are identical, they have the same limit, and therefore
\begin{equation*}
L_t^s=\lim_{i\to\infty}\Phi_{u_i}=\lim_{i\to\infty}\Phi_{u_i^*}=L_{t+\Delta}^{s+\Delta}\,.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:lower_transition_has_deriv}]
The proposition claims that $\frac{d}{dt}L_t^s=-\lrate L_t^s$ and $\frac{d}{ds}L_t^s=L_t^s\lrate$, meaning that
\begin{equation}\label{eq:lower_deriv_backward}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall\Delta\,:\,0<\lvert\Delta\rvert <\delta)~
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert<\epsilon
\end{equation}
and
\begin{equation}\label{eq:lower_deriv_forward}
(\forall\epsilon>0)\,
(\exists\delta>0)\,
(\forall\Delta\,:\,0<\lvert\Delta\rvert<\delta)~
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert<\epsilon.
\end{equation}
We start by proving Equation~\eqref{eq:lower_deriv_backward}. Choose any $\epsilon\in\realspos$, and let
\begin{equation}\label{eq:derivative_max_delta}
\delta \coloneqq \frac{\epsilon}{3\norm{\lrate}^2}.
\end{equation}
Then, consider any $\Delta\neq 0$ such that $\lvert\Delta\rvert<\delta$. We will show that
\begin{equation*}
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert<\epsilon
\end{equation*}
Start by rewriting the statement slightly to prevent having to consider different cases for positive and negative $\Delta$. Let $t'\coloneqq\max\{t,t+\Delta\}$, and let $\Delta'\coloneqq t'-t$. Then,
\begin{equation*}
\Big\lVert\frac{L_{t+\Delta}^s-L_t^s}{\Delta}+\lrate L_t^s\Big\rVert = \norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s}\,.
\end{equation*}
Now,
\begin{align*}
\norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s} &= \norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^{t'}L_{t'}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}L_{t'}^s} \\
 &\leq \norm{\frac{I - L_{t'-\lvert\Delta\rvert}^{t'}}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}}\norm{L_{t'}^s} \\
 &\leq \norm{\frac{I - L_{t'-\lvert\Delta\rvert}^{t'}}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^{t'}} \\
 &= \norm{\frac{I - L_{0}^{\lvert\Delta\rvert}}{\lvert\Delta\rvert}+\lrate L_{0}^{\Delta'}} \\
 &= \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert}-\lrate L_{0}^{\Delta'}} \\
 &\leq \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert}-\lrate} + \norm{\lrate - \lrate L_{0}^{\Delta'}} \\
 &\leq \frac{1}{\lvert\Delta\rvert}\cdot\norm{L_{0}^{\lvert\Delta\rvert} - (I+\lvert\Delta\rvert\lrate)} + 2\norm{\lrate}\norm{I - L_{0}^{\Delta'}} \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\Delta'\norm{\lrate}^2.
\end{align*}
Because $\Delta'$ satisfies either $\Delta'=0$ or $\Delta'=\lvert\Delta\rvert$, we have that $\Delta'\leq\lvert\Delta\rvert$. Thus,
\begin{align*}
\norm{\frac{L_{t'}^s - L_{t'-\lvert\Delta\rvert}^s}{\lvert\Delta\rvert}+\lrate L_{t'-\Delta'}^s} &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\Delta'\norm{\lrate}^2 \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + 2\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &= 3\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &< 3\delta\norm{\lrate}^2 \\
 &= \epsilon\,,
\end{align*}
where the last step used Equation~\eqref{eq:derivative_max_delta}. This concludes the proof of Equation~\eqref{eq:lower_deriv_backward}. We will now prove Equation~\eqref{eq:lower_deriv_forward}.

Again choose any $\epsilon\in\realspos$, and let $\delta$ be given by
\begin{equation*}
\delta \coloneqq \frac{\epsilon}{2\norm{\lrate}^2}\,.
\end{equation*}
Consider any $\Delta\neq 0$ such that $\lvert\Delta\rvert<\delta$. We will show that
\begin{equation*}
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert<\epsilon\,.
\end{equation*}
We again first rewrite the statement to prevent having to perform case-work in the sign of $\Delta$. Let $s'\coloneqq\min\{s,s+\Delta\}$, and let $\Delta'\coloneqq s-s'$. Then,
\begin{equation*}
\Big\lVert\frac{L_{t}^{s+\Delta}-L_t^s}{\Delta}-\lbound_t^s\lrate \Big\rVert = \norm{\frac{L_t^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'+\Delta'}\lrate}\,.
\end{equation*}
Now,
\begin{align*}
\norm{\frac{L_t^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'+\Delta'}\lrate} &= \norm{\frac{L_t^{s'}L_{s'}^{s'+\lvert\Delta\rvert} - L_t^{s'}}{\lvert\Delta\rvert} - L_t^{s'}L_{s'}^{s'+\Delta'}\lrate} \\
 &\leq \norm{L_t^{s'}}\norm{\frac{L_{s'}^{s'+\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{s'}^{s'+\Delta'}\lrate} \\
 &\leq \norm{\frac{L_{s'}^{s'+\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{s'}^{s'+\Delta'}\lrate} \\
 &= \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - L_{0}^{\Delta'}\lrate} \\
 &\leq \norm{\frac{L_{0}^{\lvert\Delta\rvert} - I}{\lvert\Delta\rvert} - \lrate} + \norm{\lrate - L_{0}^{\Delta'}\lrate} \\
 &\leq \frac{1}{\lvert\Delta\rvert}\cdot\norm{L_{0}^{\lvert\Delta\rvert} - (I+\lvert\Delta\rvert\lrate)} + \norm{\lrate}\norm{I - L_{0}^{\Delta'}} \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + \Delta'\norm{\lrate}^2 \\
 &\leq \lvert\Delta\rvert\cdot\norm{\lrate}^2 + \lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &= 2\lvert\Delta\rvert\cdot\norm{\lrate}^2 \\
 &< 2\delta\norm{\lrate}^2 \\
 &= \epsilon\,.
\end{align*}
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:connections}}

\begin{proof}[Proof of Proposition~\ref{prop:lowerenvelopeislowertrans}]
Consider any $Q\in\rateset$. It then follows from Definition~\ref{def:rate_matrix} that the matrix $Q$, when regarded as a map from $\gamblesX$ to $\gamblesX$, satisfies \ref{LR:constantzero}--\ref{LR:nondiagpos}. Since each of these properties is preserved under taking lower envelopes, it follows that $\lrate$ satisfies \ref{LR:constantzero}--\ref{LR:nondiagpos}, which means that $\lrate$ is a lower transition rate operator.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:dominating_nonempty_bounded}]
Fix any $f\in\gamblesX$. Choose $\Delta>0$ small enough such that $0\leq\Delta\norm{\lrate}\leq 1$ (this always possible because of Lemma~\ref{lem:normlratefinite}). Define $\lt\coloneqq I+\Delta\lrate$. Since $\lrate$ is a lower transition rate operator, it follows from Lemma~\ref{lemma:normQsmallenough} that $\lt$ is a lower transition operator. For any $x\in\states$, we now let
\begin{equation*}
\lt_xg\coloneqq(\lt g)(x)
\text{~~for all $g\in\gamblesX$.}
\end{equation*}
Since $\lt$ is a lower transition operator, it follows that $\lt_x\colon \gamblesX\to\reals$ is super-additive, positively homogeneous and bounded below by the minimum operator. Hence, by definition~\cite[Definition~2.3.3]{Walley:1991vk}, $\lt_x$ is a coherent lower prevision on $\gamblesX$. Because of \cite[Theorem~3.3.3(b)]{Walley:1991vk}, this implies the existence of an expectation operator $E_x$ on $\gamblesX$---Reference~\cite{Walley:1991vk} calls this a linear prevision on $\gamblesX$---such that $E_xg\geq\lt_xg$ for all $g\in\gamblesX$ and $E_xf=\lt_xf$. Let $P_x$ be the unique probability mass function that corresponds to $E_x$. For all $x,y\in\states$, we now let $T(x,y)\coloneqq P_x(y)\coloneqq E_x(\ind{x})$. Then $T$ is clearly a stochastic matrix. Furthermore, for every $x\in\states$ and $g\in\gamblesX$, we have that $(Tg)(x)=E_xg$. Hence, it follows that $Tg\geq\lt g$ for all $g\in\gamblesX$ and that $Tf=\lt f$. Now let $Q\coloneqq\nicefrac{1}{\Delta}(T-I)$, which, because of Proposition~\ref{prop:rate_from_stochastic_matrix}, is a rate matrix. Since $Tf=\lt f$, it then follows that
\begin{equation*}
Qf=\frac{1}{\Delta}(Tf-f)\geq\frac{1}{\Delta}{\lt f-f}=\lrate f.
\end{equation*}
Similarly, since $Tg\geq\lt g$ for all $g\in\gamblesX$, it follows that $Qg\geq\lrate g$, or equivalently, since $Q$ is a rate matrix, that $Q\in\rateset_{\lrate}$. Since $f$ was arbitrary, this proves that, for all $f\in\gamblesX$, there is some $Q\in\rateset_{\lrate}$ such that $Qf=\lrate f$. Since $\gamblesX$ is non-empty, this clearly implies that $\rateset_{\lrate}$ is non-empty.

We end this proof by showing that $\rateset_{\lrate}$ is bounded. Consider any $x\in\states$. Then for all $Q\in\rateset_{\lrate}$, we have that $Q(x,x)=(Q\ind{x})(x)\geq(\lrate\ind{x})(x)$, which implies that
\begin{equation*}
\inf\left\{Q(x,x)\colon Q\in\rateset_{\lrate}\right\}\geq(\lrate\ind{x})(x)>-\infty.
\end{equation*}
Since $x\in\states$ is arbitary, Proposition~\ref{prop:alternativedefforbounded} now guarantees that $\rateset_{\lrate}$ is bounded. 
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:dominatingproperties}]
We start by showing that $\rateset_{\lrate}$ is closed, or equivalently, that for any converging sequence $\{Q_i\}_{i\in\nats}$ in $\rateset_{\lrate}$, the limit $Q\coloneqq\lim_{i\to+\infty}Q_i$ is again an element of $\rateset_{\lrate}$. Because $\{Q_i\}_{i\in\nats}$ is in the bounded set $\rateset_{\lrate}$ of rate matrices, we know that the limit $Q$ is again a rate matrix. Now, assume \emph{ex absurdo} that $Q\notin\rateset_{\lrate}$. Then, by Equation~\eqref{eq:dominatingratematrices}, there is some $f\in\gamblesX$ and some $x\in\states$ such that $\left[Qf\right](x) < \left[\lrate f\right](x)$. This means that there is some $\epsilon\in\realspos$ such that also $\left[Qf\right](x) + \epsilon < \left[\lrate f\right](x)$. Because $\lim_{i\to+\infty}Q_i=Q$, we must eventually have that, for large enough $i$, it holds that $\left[Q_if\right](x) < \left[Qf\right](x) + \epsilon$. This implies that also $\left[Q_if\right](x) < \left[\lrate f\right](x)$, which, because $Q_i\in\rateset_{\lrate}$, is a contradiction. Therefore, $Q\in\rateset_{\lrate}$, and because the converging sequence $\{Q_i\}_{i\in\nats}$ was arbitrary, this proves that $\rateset_{\lrate}$ is closed.

We now show that $\rateset_{\lrate}$ is convex, meaning that for any rate matrices $Q_1,Q_2\in\rateset_{\lrate}$, and any $\lambda\in[0,1]$, the matrix $Q_\lambda\coloneqq\lambda Q_1 + (1-\lambda)Q_2$ also satisfies $Q_\lambda\in\rateset_{\lrate}$. It is easily verified from Definition~\ref{def:rate_matrix} that $Q_\lambda$ is a rate matrix. Now, assume \emph{ex absurdo} that $Q_\lambda\notin\rateset_{\lrate}$. Then, by Equation~\eqref{eq:dominatingratematrices}, there is some $f\in\gamblesX$ and some $x\in\states$ such that $\left[Q_\lambda f\right](x) < \left[\lrate f\right](x)$. This implies that $\left(\lambda\left[Q_1 f\right](x)+(1-\lambda)\left[Q_2 f\right](x)\right) < \left[\lrate f\right](x)$, which because $Q_1,Q_2\in\rateset_{\lrate}$, is a contradiction. Therefore, $Q_\lambda\in\rateset_{\lrate}$.

We finally show that $\rateset_{\lrate}$ has separately specified rows. For all $x\in\states$, let $\rateset_x\coloneqq\{Q(x,\cdot)\,:\,Q\in\rateset_{\lrate}\}$. Now, let $Q$ be any matrix such that, for all $x\in\states$, $Q(x,\cdot)\in\rateset_x$. It is easily verified from Definition~\ref{def:rate_matrix} that $Q$ is a rate matrix. Now, assume \emph{ex absurdo} that $Q\notin\rateset_{\lrate}$. Then, by Equation~\eqref{eq:dominatingratematrices}, there is some $f\in\gamblesX$ and some $x\in\states$ such that $\left[Qf\right](x) < \left[\lrate f\right](x)$. Because $Q(x,\cdot)\in\rateset_x$, this implies that there is some $Q'\in\rateset_{\lrate}$ such that also $\left[Q'f\right](x) < \left[\lrate f\right](x)$, a contradiction. Therefore, $Q\in\rateset_{\lrate}$.
\end{proof}

\begin{lemma}\label{lemma:rows_nonempty_bounded_closed_convex}
Let $\rateset$ be any non-empty, bounded, closed and convex set of rate matrices that has separately specified rows. Then, for all $x\in\states$, the set $\rateset_x\coloneqq\{Q(x,\cdot)\,:\,Q\in\rateset\}$ is non-empty, bounded, closed, and convex.
\end{lemma}
\begin{proof}
Take any $x\in\states$. Non-emptiness, boundedness, and convexity of $\rateset_x$ follows trivially from the fact that $\rateset$ is non-empty, bounded, and convex. It remains to show that $\rateset_x$ is closed, or, equivalently, that for any converging sequence $\{Q_i(x,\cdot)\}_{i\in\nats}$ in $\rateset_x$, the limit $Q^*(x,\cdot)\coloneqq\lim_{i\to+\infty}Q_i(x,\cdot)$ also satisfies $Q^*(x,\cdot)\in\rateset_x$.

For all $x'\in\states$ such that $x'\neq x$, choose some $Q(x',\cdot)\in\rateset_{x'}$. Construct a sequence of matrices $\{\hat{Q}_i\}_{i\in\nats}$ such that, for all $i\in\nats$ and all $x'\in\states$, $x'\neq x$, $\hat{Q}_i(x',\cdot)=Q(x',\cdot)$, and such that $\hat{Q}_i(x,\cdot)=Q_i(x,\cdot)$ for all $i\in\nats$. Because $\rateset$ has separately specified rows, and because $\hat{Q}_i(y,\cdot)\in\rateset_y$ for all $y\in\states$ and all $i\in\nats$, we then have that $\hat{Q}_i\in\rateset$, for all $i\in\nats$.

Furthermore, in the sequence $\{\hat{Q}_i\}_{i\in\nats}$, only the $x$-th row is changing. Therefore, because $\{Q_i(x,\cdot)\}_{i\in\nats}$ is converging, so is $\{\hat{Q}_i\}_{i\in\nats}$. In particular, $\{\hat{Q}_i(x,\cdot)\}_{i\in\nats}\to Q^*(x,\cdot)$. Let $Q^*\coloneqq\lim_{i\to+\infty}\hat{Q}_i$. Because $\rateset$ is closed, and $\{\hat{Q}_i\}_{i\in\nats}$ is in $\rateset$, it follows that $Q^*\in\rateset$. Therefore, we find that $Q^*(x,\cdot)\in\rateset_x$.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:dominating_unique_characterization}]
Let $\rateset$ be any non-empty, bounded, closed and convex set of rate matrices with separately specified rows, with corresponding lower transition rate operator $\lrate$. Assume \emph{ex absurdo} that $\rateset\neq\rateset_{\lrate}$.

Then, we must have that either $\rateset\subset\rateset_{\lrate}$, or, because $\rateset$ is non-empty, there must be some $Q\in\rateset$ such that $Q\notin\rateset_{\lrate}$. In the latter case, because $\rateset$ has $\lrate$ as its lower envelope, we immediately find a contradiction with Equation~\eqref{eq:dominatingratematrices}. Hence, if indeed $\rateset\neq\rateset_{\lrate}$, we must instead have that $\rateset\subset\rateset_{\lrate}$. Therefore, and because $\rateset_{\lrate}$ is non-empty, there must be some $Q\in\rateset_{\lrate}$ such that $Q\notin\rateset$.

Because $\rateset$ has separately specified rows, there must therefore be some $x\in\states$ such that $Q(x,\cdot)\notin\rateset_x$, where $\rateset_x\coloneqq\{Q'(x,\cdot)\,:\,Q'\in\rateset\}$. Because $\rateset$ is non-empty, bounded, closed, convex, and has separately specified rows, it follows from Lemma~\ref{lemma:rows_nonempty_bounded_closed_convex} that $\rateset_x$ is non-empty, bounded, closed, and convex. 

Note that we can interpret $\rateset_x\subset\reals^m$ as a subset of the vector space $\reals^m$, where $m$ is the size of $\states$. Furthermore, because $\rateset_x$ is closed and bounded, we have that $\rateset_x$ is compact. Because $Q(x,\cdot)\notin\rateset_x$, the (non-empty, closed, convex) singleton set $\{Q(x,\cdot)\}$ is clearly disjoint from $\rateset_x$.

Therefore, by the hyperplane separation theorem\footnote{That is, by one of them.} ({\bf REF}), there must be some $f\in\gamblesX$ and some $c_1,c_2\in\reals$, with $c_1<c_2$, such that $Q(x,\cdot)f = [Qf](x) \leq c_1$, and such that, for all $Q'(x,\cdot)\in\rateset_x$, $Q'(x,\cdot)f = [Q'f](x) \geq c_2$.

This clearly implies that, for all $Q'\in\rateset$, it holds that $[Qf](x) \leq c_1 < c_2 \leq [Q'f](x)$. In turn, this implies the existence of some $\epsilon\in\realspos$ for which $[Qf](x) + \epsilon < [Q'f](x)$, for all $Q'\in\rateset$. Because $\lrate$ is the lower envelope of $\rateset$, by Equation~\eqref{eq:correspondinglowertrans}, we therefore find that $[Qf](x) < [\lrate f](x)$. Hence, we have found a $f\in\gamblesX$ and a $x\in\states$, such that for some $Q\in\rateset_{\lrate}$, it holds that $[Qf](x) < [\lrate f](x)$. By Equation~\eqref{eq:dominatingratematrices}, this is a contradiction, and hence $\rateset=\rateset_{\lrate}$.
\end{proof}

\begin{lemma}\label{lemma:rateset_has_arginf}
Let $\rateset$ be an arbitrary non-empty bounded set of rate matrices that has separately specified rows, with corresponding lower transition rate operator $\lrate$. Then for all $f\in\gamblesX$ and $\epsilon\in\realspos$, there exists a $Q\in\rateset$ such that
\begin{equation*}
\norm{\lrate f - Qf} < \epsilon\,.
\end{equation*}
\end{lemma}
\begin{proof}
This is immediate from the definition of the lower envelope of $\rateset$, as given by Equation~\eqref{eq:correspondinglowertrans}, and the fact that $\rateset$ has separately specified rows.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{theorem:nonmarkov_single_var_lower_bounded}]
Consider any $P\in\wprocesses_\rateset$, any $s\in\realsnonneg$, any $u\in\mathcal{U}_{<s}$, any $x_u\in\states^u$, and any $f\in\gamblesX$. We will show that for all $\epsilon\in\realspos$, it holds that 
\begin{equation*}
[L_{t_n}^s f](x_{t_n}) < \mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] + \epsilon\,,
\end{equation*}
which then implies that $[L_{t_n}^s f](x_{t_n}) \leq \mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]$. Start by choosing any $\epsilon\in\realspos$, and let $C\coloneqq(s-t_n)$. 

Now, by Theorem~\ref{theo:convergencelowerbound}, there is some $\delta\in\realspos$ such that
\begin{equation*}
(\forall v\in\mathcal{U}_{[t_n,s]}\,:\,\sigma(v)<\delta) \norm{L_{t_n}^s - \Phi_v} < \frac{\epsilon}{2\norm{f}}\,,
\end{equation*}
which implies that for all $v\in\mathcal{U}_{[t_n,s]}$ with $\sigma(v)<\delta$, and all $x\in\states$,
\begin{equation}\label{eq:lowerbound_proof_linear_approx_lbound}
\left[L_{t_n}^sf\right](x) - \frac{\epsilon}{2} < \left[\Phi_vf\right](x)\,.
\end{equation}

Now, let $w\coloneqq t_0,\ldots,t_{n-1}$, and let $x_w\coloneqq(x_{t_0},\ldots,x_{t_{n-1}})$. Then, because $P\in\wprocesses_\rateset$, by Proposition~\ref{prop:outerderivativebehaveslikelimit}, there is some $\delta'\in\realspos$ such that for all $\Delta\in\realspos$ with $\Delta<\delta'$, there is a $Q_0\in\rateset$ such that
\begin{equation*}
\norm{T_{t_n,x_w}^{t_n+\Delta} - (I+\Delta Q_0)} < \frac{\Delta\epsilon}{2C\norm{f}}\,.
\end{equation*}
Choose any $\Delta_0$ such that $\Delta_0<\min\{\delta,\delta'\}$. This implies that for all $g\in\gamblesX$ with $\norm{g}\leq\norm{f}$, we have that
\begin{equation*}
\norm{T_{t_n,x_w}^{t_n+\Delta_0}g - (I+\Delta_0 Q_0)g} < \frac{\Delta_0\epsilon}{2C}\,,
\end{equation*}
which in turn implies that for all $x\in\states$,
\begin{equation*}
\left[(I+\Delta_0 Q_0)g\right](x) - \frac{\Delta_0\epsilon}{2C} < \left[T_{t_n,x_w}^{t_n+\Delta_0}g\right](x)\,.
\end{equation*}
Because $Q_0\in\rateset$, using Equation~\eqref{eq:correspondinglowertrans}, we find that, for all $g\in\gamblesX$ with $\norm{g}\leq\norm{f}$,
\begin{equation}\label{eq:lowerbound_proof_linear_approx_last_part}
\left[(I+\Delta_0 \lrate)g\right](x) - \frac{\Delta_0\epsilon}{2C} < \left[T_{t_n,x_w}^{t_n+\Delta_0}g\right](x)\,.
\end{equation}

Let $\delta^*\coloneqq\min\{\delta,\nicefrac{1}{\norm{\lrate}}\}$. 
Because $P\in\wprocesses_\rateset$, Lemma~\ref{lemma:bound_on_linear_approx_partition} implies that there is some $v\in\mathcal{U}_{[t_n+\Delta_0,s]}$ such that $\sigma(v)<\delta^*$, with $v=\tau_0,\ldots,\tau_m$, and $\tau_0=t_n+\Delta_0$, $\tau_m=s$, and, for all $i\in\{1,\ldots,m\}$,
\begin{equation*}
(\exists Q\in\rateset)\norm{T_{\tau_{i-1},x_u}^{\tau_{i}} - (I+\Delta_{i}Q)} < \frac{\Delta_{i}\epsilon}{2C\norm{f}}\,,
\end{equation*}
which implies that there exist rate matrices $Q_{1},\ldots,Q_{m}$ such that, for all functions $g\in\gamblesX$ with $\norm{g}\leq\norm{f}$ and all $i\in\{1,\ldots,m\}$,
\begin{equation*}
\norm{T_{\tau_{i-1},x_u}^{\tau_{i}}g - (I+\Delta_{i}Q_i)g} < \frac{\Delta_{i}\epsilon}{2C}\,.
\end{equation*}
This in turn implies that for all $g\in\gamblesX$ with $\norm{g}\leq\norm{f}$, all $i\in\{1,\ldots,m\}$, and all $x\in\states$,
\begin{equation*}
\left[(I+\Delta_{i}Q_{i})g\right](x) - \frac{\Delta_{i}\epsilon}{2C} < \left[T_{\tau_{i-1},x_u}^{\tau_{i}}g\right](x)\,.
\end{equation*}
Because for all $i\in\{1,\ldots,m\}$ it holds that $Q_i\in\rateset$, by Equation~\eqref{eq:correspondinglowertrans} we find that for all $g\in\gamblesX$ with $\norm{g}\leq\norm{f}$ and all $x\in\states$,
\begin{equation}\label{eq:lowerbound_proof_linear_approx_lrate}
\left[(I+\Delta_{i}\lrate)g\right](x) - \frac{\Delta_{i}\epsilon}{2C} < \left[T_{\tau_{i-1},x_u}^{\tau_{i}}g\right](x)\,.
\end{equation}

Now, observe that because $\tau_m=s$,
\begin{align*}
\left[T_{\tau_{m-1},x_u}^{\tau_{m}}f\right](x) &= \mathbb{E}[f(X_{\tau_m})\,\vert\,X_{\tau_{m-1}}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\\
 &= \mathbb{E}[f(X_{s})\,\vert\,X_{s-\Delta_m}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,.
\end{align*}
Furthermore, by the basic properties of expectation, we have that
\begin{align*}
\mathbb{E}[&f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] \\
 & = \mathbb{E}\bigl[\mathbb{E}[f(X_s)\,\vert\,X_{s-\Delta_m},X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}]\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\bigr]\,,
\end{align*}
and because this (outer) expectation computes a convex combination of values, we find by substitution of Equation~\eqref{eq:lowerbound_proof_linear_approx_lrate}, that
\begin{align*}
\mathbb{E}[&f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] \\
& > \mathbb{E}\bigl[[(I+\Delta_m\lrate)f](X_{\tau_{m-1}})\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\bigr] - \frac{\Delta_{m}\epsilon}{2C}\,.
\end{align*}

Because $\Delta_m\leq\sigma(v)<\delta^*\leq\nicefrac{1}{\norm{\lrate}}$, we find by Proposition~\ref{lemma:normQsmallenough} that $(I+\Delta_m\lrate)$ is a lower transition operator. Therefore, by Proposition~\ref{lemma:normofcoherenttrans}, we have that $\norm{(I+\Delta_m\lrate)f}\leq\norm{f}$. Hence, Equation~\eqref{eq:lowerbound_proof_linear_approx_lrate} applies, and we can use backward induction on $m$ to find
\begin{align*}
\mathbb{E}[&f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] \\
& > \mathbb{E}\bigl[[(I+\Delta_m\lrate)f](X_{\tau_{m-1}})\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\bigr] - \frac{\Delta_{m}\epsilon}{2C} \\
 &> \mathbb{E}\bigl[[(I+\Delta_{m-1}\lrate)(I+\Delta_m\lrate)f](X_{\tau_{m-2}})\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\bigr] - \frac{\Delta_{m-1}\epsilon}{2C} - \frac{\Delta_{m}\epsilon}{2C} \\
&\vdots \\
%& > \mathbb{E}\left[\left[\left(\prod_{i=2}^m(I+\Delta_i\lrate)\right)f\right](X_{\tau_{1}})\,\Bigg\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right] - \sum_{i=2}^m\frac{\Delta_{i}\epsilon}{2C} \\
& > \mathbb{E}\left[\left[\left(\prod_{i=1}^m(I+\Delta_i\lrate)\right)f\right](X_{\tau_{0}})\,\Bigg\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right] - \sum_{i=1}^m\frac{\Delta_{i}\epsilon}{2C} \\
& = \mathbb{E}\left[\left[\left(\prod_{i=1}^m(I+\Delta_i\lrate)\right)f\right](X_{t_n+\Delta_0})\,\Bigg\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}\right] - \sum_{i=1}^m\frac{\Delta_{i}\epsilon}{2C} \\
&= \left[T_{t_n,x_w}^{t_n+\Delta_0}\left(\prod_{i=1}^m(I+\Delta_i\lrate)\right)f\right](x_{t_n}) - \sum_{i=1}^m\frac{\Delta_{i}\epsilon}{2C}\,.
%& = \left[\left(\prod_{i=1}^m(I+\Delta_i\lrate)\right)f\right](x_{t_n}) - \sum_{i=1}^m\frac{\Delta_{i}\epsilon}{2C}\\
%& = \left[\Phi_v f\right](x_{t_n}) - \frac{\epsilon}{2}\,,
\end{align*}
Because $\prod_{i=1}^m(I+\Delta_i\lrate)$ is a lower transition operator, we have that $\norm{\prod_{i=1}^m(I+\Delta_i\lrate)f}\leq\norm{f}$. Therefore, Equation~\eqref{eq:lowerbound_proof_linear_approx_last_part} applies, and hence we find that
\begin{equation*}
\mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] > \left[\prod_{i=0}^m(I+\Delta_i\lrate)f\right](x_{t_n}) - \sum_{i=0}^m\frac{\Delta_{i}\epsilon}{2C}\,.
\end{equation*}
Note that $\sum_{i=0}^m\Delta_i=C$. Let now $v^*\coloneqq t_n,\tau_0,\ldots,\tau_m$. Then clearly, $v^*\in\mathcal{U}_{[t_n,s]}$. We therefore have that
\begin{equation*}
\mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] > \left[\Phi_{v^*}f\right](x_{t_n}) - \frac{\epsilon}{2}\,,
\end{equation*}
and because $\sigma(v^*)<\delta$, we now find from Equation~\eqref{eq:lowerbound_proof_linear_approx_lbound} that
\begin{equation*}
\mathbb{E}[f(X_s)\,\vert\,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}] > \left[L_{t_n}^sf\right](x_{t_n}) - \epsilon\,.
\end{equation*}
Because the $\epsilon\in\realspos$ was arbitrary, this completes the proof.
\end{proof}

%
%**** {\bf the one below is deprecated}
%\begin{proof}[Proof of Proposition~\ref{theorem:nonmarkov_single_var_lower_bounded}]
%Consider any $P\in\processes_\rateset$, any $t,s\in\realsnonneg$ such that $t<s$, any $u\in\mathcal{U}_{[0,t]}$, and any $g\in\gambles(\states^{\{s\}})$. We will show that for all $\epsilon\in\realspos$,
%\begin{equation*}
%[L_t^s g](x_{t_n}) < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] + \epsilon\,,
%\end{equation*}
%which then implies $[L_t^s g](x_{t_n}) \leq \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]$. Start by choosing any $\epsilon\in\realspos$, and let $C\coloneqq (s-t)$.
%
%Because $P\in\processes_\rateset$, it follows from Definition~\ref{def:set_non_markov_process} that there is some $\delta\in\realspos$ such that
%\begin{align}\label{eq:nonmarkov_bound_proof_deriv_bounded}
%\begin{split}
% &(\forall \tau\in\realsnonneg)\,(\forall\Delta\in(0,\delta))\,(\forall v\in\mathcal{U}_{[0,\tau]})\,(\forall(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}})\,(\exists Q\in\rateset)\,: \\
% &(\forall f\in\gambles(\states^{v\cup\{\tau+\Delta\}}))\,(\forall x_{\tau_m}\in\states^{\{\tau_m\}}): \\
% &\left\lvert \frac{\mathbb{E}[f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\,\vert\,X_{\tau_0,\ldots,\tau_m}=x_{\tau_0,\ldots,\tau_m}] 
% - f(x_{\tau_0},\ldots,x_{\tau_m},x_{\tau_m})}{\Delta} \right. \\
% &\quad\quad\quad\quad\quad\quad - \left[Q f(x_{\tau_0},\ldots,x_{\tau_{m}},X_{\tau+\Delta})\right](x_{\tau_m})\biggr\rvert \quad < \quad\frac{\epsilon}{2C\norm{g}}\cdot\norm{f}\,.
%\end{split}
%\end{align}
%Furthermore, it follows from Theorem~\ref{theo:convergencelowerbound} that there is some $\delta'\in\realspos$ such that
%\begin{equation}\label{eq:nonmarkov_bound_proof_lbound_approx}
%(\forall v\in\mathcal{U}_{[t,s]}\,:\,\sigma(v)<\delta')\,(\forall x_t\in\states)\abs{\left[L_t^s g\right](x_t) - \left[\prod_{k=1}^n(I+\Delta_i\lrate)g\right](x_t)} < \frac{\epsilon}{2}\,.
%\end{equation}
%
%Let $\delta^*\coloneqq\min\{\delta,\delta'\}$, and choose any $n>\nicefrac{C}{\delta^*}$. Then, for $\Delta\coloneqq\nicefrac{C}{n}$, we have $\Delta<\delta$ and $\Delta<\delta'$.
%
%Equation \eqref{eq:nonmarkov_bound_proof_deriv_bounded} now implies that for all $\tau\in\realspos$, all $v\in\mathcal{U}_{[0,\tau]}$ such that $v=\tau_0,\ldots,\tau_m$, and all $(x_{\tau_0},\ldots,x_{\tau_{m-1}})\in\states^{\{\tau_0,\ldots,\tau_{m-1}\}}$, there is some $Q^v_{x_{\tau_0},\ldots,x_{\tau_{m-1}}}\in\rateset$ such that, for all $f\in\gambles(\states^{v\cup\{\tau+\Delta\}})$ and all $x_{\tau_m}\in\states^{\{\tau_m\}}$,
%\begin{align}\label{eq:nonmarkov_bound_proof_deriv_inequal}
%\begin{split}
% &\left[(I + \Delta Q^v_{x_{\tau_0},\ldots,x_{\tau_{m-1}}})f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\right](x_{\tau_m}) - \frac{\Delta\epsilon\norm{f}}{2C\norm{g}} \\
% &\quad< \mathbb{E}[f(x_{\tau_0},\ldots,x_{\tau_m},X_{\tau+\Delta})\,\vert\,X_{\tau_0,\ldots,\tau_m}=x_{\tau_0,\ldots,\tau_m}]\,.
%\end{split}
%\end{align}
%Now, note that by the basic properties of probability,
%\begin{align*}
%\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &= \mathbb{E}\bigl[\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}]\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr]\,.
%\end{align*}
%By choosing $\tau=(s-\Delta)$, setting $v=t_0,\ldots,t_n,(s-\Delta)$, and noting that $g\in\gambles(\states^{\{s\}})=\gambles(\states^{\{\tau+\Delta\}})\subset\gambles(\states^{v\cup\{\tau+\Delta\}})$, we find from Equation \eqref{eq:nonmarkov_bound_proof_deriv_inequal} that for all $(x_{t_0},\ldots,x_{t_n})\in\states^{u}$ there is some $Q^v_{x_{t_0},\ldots,x_{t_n}}\in\rateset$ such that, for all $x_{s-\Delta}\in\states^{\{s-\Delta\}}$,
%\begin{equation*}
%\left[(I + \Delta Q^v_{x_{t_0},\ldots,x_{t_n}})g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}=x_{s-\Delta}]\,.
%\end{equation*}
%Furthermore, we find using Equation~\eqref{eq:correspondinglowertrans} and the fact that $Q^v_{x_{t_0},\ldots,x_{t_n}}\in\rateset$, that
%\begin{equation*}
%\left[(I + \Delta \lrate)g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C} \leq \left[(I + \Delta Q^v_{x_{t_0},\ldots,x_{t_n}})g\right](x_{s-\Delta}) - \frac{\Delta\epsilon}{2C}\,.
%\end{equation*}
%Noting that an expectation takes a convex combination of values, we find by substitution that
%\begin{align*}
%\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &= \mathbb{E}\bigl[\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s-\Delta}]\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr] \\
%&> \mathbb{E}\bigl[[(I+\Delta\lrate)g](X_{s-\Delta})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr] - \frac{\Delta\epsilon}{2C}\,.
%\end{align*}
%
%Note also that
%\begin{equation*}
%[(I+\Delta\lrate)g](X_{s-\Delta})\in\gambles(\states^{\{s-\Delta\}})\subset\gambles(\states^{u\cup\{s-\Delta\}})\,.
%\end{equation*}
%Hence, we can repeat this argument, factoring the expectation at time points $(s-2\Delta),\ldots,(s-(n-1)\Delta)$, to obtain
%\begin{align*}
%\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &> \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - n\cdot\frac{\Delta\epsilon}{2C} \\
% &= \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - \frac{\epsilon}{2}\,.
%\end{align*}
%
%It follows from Equation \eqref{eq:nonmarkov_bound_proof_lbound_approx} and the fact that $\Delta<\delta'$,
%\begin{equation*}
%\left[L_t^s g\right](x_{t_n}) - \frac{\epsilon}{2} < \left[(I+\Delta\lrate)^n g\right](x_{t_n})\,,
%\end{equation*}
%so that by substitution,
%\begin{align*}
%\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] &> \left[(I+\Delta\lrate)^ng\right](x_{t_n}) - \frac{\epsilon}{2} \\
% &> [L_t^s g](x_{t_n}) - \frac{\epsilon}{2} - \frac{\epsilon}{2} \\
% &= [L_t^s g](x_{t_n}) - \epsilon\,.
%\end{align*}
%Thus, we have found that
%\begin{equation*}
%[L_t^s g](x_{t_n}) < \mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] + \epsilon\,.
%\end{equation*}
%Because the $\epsilon\in\realspos$ was arbitrary, this concludes the proof.
%\end{proof}

\begin{proof}[Proof of Proposition~\ref{theorem:lower_markov_bound_is_tight}]
Choose any $f\in\gamblesX$ and any $\epsilon\in\realspos$. Let $C\coloneqq (s-t)$. 

The proof works by selecting a rate matrix at each point in time, showing that there is a $P\in\mprocesses_\rateset$ that is characterized by this construction, and finally establishing that this $P$ satisfies the inequality of interest.

By Lemma~\ref{lemma:rateset_has_arginf}, for all $\tau\in[t,s]$ there is some rate matrix $Q_\tau\in\rateset$ such that
\begin{equation}\label{eq:lower_char_rate_matrix}
\norm{\lrate \lbound_\tau^sf - Q_\tau \lbound_\tau^sf} < \frac{\epsilon}{2C}\,.
\end{equation}
To fix $Q_\tau$'s values outside of the interval $[t,s]$, let $Q_\tau \coloneqq Q_t$ for all $\tau\in[0,t]$, and let $Q_\tau\coloneqq Q_s$ for all $\tau>s$.
%Define a \emph{lower-characterizing rate matrix} $Q_\tau$ as
%\begin{equation}\label{eq:lower_char_rate_matrix}
%Q_\tau(x_\tau,\cdot)\coloneqq \argmin\left\{ Q(x_\tau,\cdot)\bigl[\lbound_\tau^sf\bigr]\,:\,Q(x_\tau,\cdot)\in\mathcal{Q}_{x_\tau}\right\}\quad\text{for all $x_\tau\in\states$ and $\tau\in[t,s]$}\,.
%\end{equation}
%Note that the $\argmin\{\cdot\}$ may be set-valued, in which case take an arbitrary element.
%Furthermore, let $Q_\tau \coloneqq Q_t$ for all $\tau\in[0,t]$, and let $Q_\tau\coloneqq Q_s$ for all $\tau>s$.

Next, define
\begin{equation}\label{eq:delta_required_for_tight_bound}
\delta \coloneqq \min\left\{\frac{\epsilon}{4C\norm{\mathcal{Q}}^2\norm{f}},\frac{1}{\norm{\lrate}}\right\}\,,
\end{equation}
and choose any $n>\nicefrac{C}{\delta}$. Then, for $\Delta\coloneqq \nicefrac{C}{n}$, we have $\Delta<\delta$.

For all $k\in\{0,\ldots,n\}$, define $t_k=t+k\Delta$. Let $u\coloneqq t_0,t_1,\ldots,t_n$. Finally, define a piecewise-constant approximation $Q_\tau^u$ to $Q_\tau$ such that, for all $k\in\{1,\ldots,n\}$,
\begin{equation}\label{eq:lower_char_matrix_linear_approx}
Q_\tau^u \coloneqq Q_{t_k},\quad\text{for all $\tau\in (t_{k-1},t_k]$}\,.
\end{equation}
Let $Q_\tau^u\coloneqq Q_{t_0}$ for all $\tau\leq t_0$ and let $Q_\tau^u\coloneqq Q_{t_n}$ for all $\tau>t_n$.

Then, $Q_\tau^u$ is a left-continuous, piecewise-constant function that gives for each time point $\tau\in\realsnonneg$ a rate matrix $Q_\tau^u\in\rateset\subset\mathcal{R}$, such that the value of $Q_\tau^u$ differs on a finite number of intervals. Therefore, by Proposition~\ref{prop:continuous_rate_matrix_has_process}, there is some $P\in\wmprocesses$ such that $\mathcal{T}_P=\mathcal{T}_{Q_\tau^u}$, where $\mathcal{T}_{Q_\tau^u}$ is defined as in Lemma~\ref{lemma:nonhomogen_trans_mat_system}. Furthermore, because $Q_\tau^u$ takes values in $\rateset$, by Lemma~\ref{lemma:nonhomogeneous_in_process_set}, $P$ furthermore satisfies $P\in\wmprocesses_\rateset$. It remains to show that, for this $P$, it holds that $\norm{L_t^sf - T_t^sf}<\epsilon$. 

We start by factorizing the interval $[t,s]$ according to $u$, as follows.
\begin{align*}
\norm{L_t^sf - T_t^sf} &= \norm{L_{t_0}^{t_n}f - T_{t_0}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_n}f - T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f} + \norm{T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f - T_{t_0}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f - T_{t_0}^{t_{n-1}}L_{t_{n-1}}^{t_n}f} + \norm{{T_{t_0}^{t_{n-1}}}}\cdot\norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \,.
\end{align*}
Recursion on the first summand yields
\begin{align*}
\norm{L_t^sf - T_t^sf} &\leq \norm{L_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_0}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
 &\leq \norm{L_{t_0}^{t_{n-2}}\left[L_{t_{n-2}}^{t_n}f\right] - T_{t_0}^{t_{n-2}}\left[L_{t_{n-2}}^{t_n}f\right]} \\
 &\quad\quad\quad+ \norm{L_{t_{n-2}}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right] - T_{t_{n-2}}^{t_{n-1}}\left[L_{t_{n-1}}^{t_n}f\right]} + \norm{L_{t_{n-1}}^{t_n}f - T_{t_{n-1}}^{t_n}f} \\
&\vdots \\
 &\leq \sum_{i=1}^{n} \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]}\,.
\end{align*}
For all $i\in\{1,\ldots,n\}$, we have using Lemma~\ref{lemma:justthelinearpart} and the facts that $\Delta<\delta\leq\nicefrac{1}{\norm{\lrate}}$ and $\norm{\lrate}\leq\norm{\rateset}$,
\begin{align*}
&\quad \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - \left[I+\Delta\lrate\right]L_{t_i}^{t_n}f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \norm{L_{t_{i-1}}^{t_i} - \left[I+\Delta\lrate\right]}\cdot\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \Delta^2\norm{\lrate}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
&\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]}\,.
\end{align*}
By Equation~\eqref{eq:lower_char_rate_matrix}, we have $\norm{Q_{t_i}L_{t_i}^{t_n}f - \lrate L_{t_i}^{t_n}f} < \nicefrac{\epsilon}{2C}$. Furthermore, by Equation~\eqref{eq:lower_char_matrix_linear_approx}, we have $Q_{t_i}^u=Q_{t_i}$, so that
\begin{align*}
 &\quad \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta\lrate\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \norm{\left[I+\Delta \lrate\right]L_{t_i}^{t_n}f - \left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f} \\
 &= \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \Delta\norm{\lrate L_{t_i}^{t_n}f - Q_{t_i}L_{t_i}^{t_n}f} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right]L_{t_i}^{t_n}f - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} + \frac{\Delta\epsilon}{2C} \\
 &\leq \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}^u\right] - T_{t_{i-1}}^{t_i}}\cdot\norm{f} + \frac{\Delta\epsilon}{2C} \\
 &= \Delta^2\norm{\mathcal{Q}}^2\norm{f} + \norm{\left[I+\Delta Q_{t_i}\right] - e^{Q_{t_i}\cdot(t_i-t_{i-1})}}\cdot\norm{f} + \frac{\Delta\epsilon}{2C} \\
 &\leq 2\Delta^2\norm{\mathcal{Q}}^2\norm{f} + \frac{\Delta\epsilon}{2C}\,,
\end{align*}
where we used the definition of $T_{t_{i-1}}^{t_i}$ from Lemma~\ref{lemma:nonhomogen_trans_mat_system}, and where the last step used Lemma~\ref{lemma:linearpartofexponential} and the fact that $\norm{Q_{t_i}}\leq\norm{\rateset}$, since $Q_{t_i}\in\rateset$.

Thus, using the fact that $n\Delta=C$, we find
\begin{align*}
\norm{L_t^sf - T_t^sf} &\leq \sum_{i=1}^n \norm{L_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right] - T_{t_{i-1}}^{t_i}\left[L_{t_i}^{t_n}f\right]} \\
 &\leq \sum_{i=1}^n 2\Delta^2\norm{\mathcal{Q}}^2\norm{f} + \frac{\Delta\epsilon}{2C} \\
 &= 2n\Delta^2\norm{\mathcal{Q}}^2\norm{f} + n\frac{\Delta\epsilon}{2C}\\
 &= 2C\Delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2}\,,
\end{align*}
so that by Equation~\eqref{eq:delta_required_for_tight_bound} and the fact that $\Delta<\delta$, we have
\begin{equation*}
\norm{L_t^sf - T_t^sf} \leq 2C\Delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2} < 2C\delta\norm{\mathcal{Q}}^2\norm{f} + \frac{\epsilon}{2} \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon\,.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Corollary~\ref{cor:lower_operator_is_infimum}]
We start by proving the first statement. By Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded} and Proposition~\ref{prop:lower_exp_markov_bounded_by_nonmarkov}, we have that for all $P\in\mprocesses_\rateset$ it holds that $\left[L_t^sg\right](x) \leq \mathbb{E}[g(X_s)\,\vert\,X_t=x]$. Furthermore, by Theorem~\ref{theorem:lower_markov_bound_is_tight}, for all $\epsilon\in\realspos$ there is some $P\in\mprocesses_\rateset$ such that $\norm{L_t^sg - T_t^sg} < \epsilon$. Together this implies, using Definition~\ref{def:lower_markov}, that
\begin{equation*}
\left[L_t^sg\right](x) = \inf\left\{\left[T_t^sf\right](x)\,:\,P\in\mprocesses_\rateset\right\} = \underline{\mathbb{E}}^{\mathrm{M}}\left[g(X_s)\,\vert\,X_t=x\right]\,.
\end{equation*}

We now move on to the second statement. By Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded} we have that for all $P\in\processes_\rateset$ it holds that $\left[L_t^sg\right](x) \leq \mathbb{E}[g(X_s)\,\vert\,X_t=x]$.
Furthermore, by Theorem~\ref{theorem:lower_markov_bound_is_tight} and Proposition~\ref{prop:markov_set_subset_of_nonmarkov_set}, for all $\epsilon\in\realsnonneg$ there is some $P\in\processes_\rateset$ such that
$\norm{L_t^sg - T_t^sg} < \epsilon$.
Together this implies, using Definition~\ref{def:lower_non_markov}, that
\begin{equation*}
\left[L_t^sg\right](x) = \inf\left\{\left[T_t^sf\right](x)\,:\,P\in\processes_\rateset\right\} = \underline{\mathbb{E}}\left[g(X_s)\,\vert\,X_t=x\right]\,.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Theorem~\ref{theo:dominating_rate_processes_max_set}]
By Propositions~\ref{prop:dominating_nonempty_bounded} and \ref{prop:dominatingproperties}, the set $\rateset_{\lrate}$ is non-empty, bounded, has separately specified rows, and by definition has $\lrate$ as its corresponding lower transition rate operator. The first statement therefore follows directly from Corollary~\ref{cor:lower_operator_is_infimum}.

For the second statement, take any $P\in\processes$ such that $P\notin\wprocesses_{\rateset_{\lrate}}$. Clearly, we must have that either $P\in\wprocesses$ or $P\notin\wprocesses$. We will start by assuming the former, and show that the statement then follows.

Because $P\notin\wprocesses_{\rateset_{\lrate}}$, by Definition~\ref{def:set_non_markov_process}, there must be some $t\in\realsnonneg$, some $u\in\mathcal{U}_{<t}$, and some $x_u\in\states^u$, such that $\smash{\overline{\partial}}T_{t,x_u}^{t}\nsubseteq\rateset_{\lrate}$. Furthermore, by Proposition~\ref{prop:boundednon-emptyandclosed}, we have that $\smash{\overline{\partial}}T_{t,x_u}^{t}\neq\emptyset$. Hence, there must be some rate matrix $Q\in\smash{\overline{\partial}}T_{t,x_u}^{t}$ such that $Q\notin\rateset_{\lrate}$, which by Equation~\eqref{eq:dominatingratematrices} implies that there is some $f\in\gamblesX$ and some $x\in\states$ such that $\left[Qf\right](x)<\left[\lrate f\right](x)$.

Now, assume \emph{ex absurdo} that the statement is false. Because $Q\in\smash{\overline{\partial}}T_{t,x_u}^{t}$, we must have that either $Q\in\smash{\overline{\partial}}_+T_{t,x_u}^{t}$ or $Q\in\smash{\overline{\partial}}_-T_{t,x_u}^{t}$. Assume it is the former. Then, by Equation~\ref{eq:rightouterderivative}, there is some $\{\Delta_i\}_{i\in\nats}\to0^+$ such that $\lim_{i\to+\infty}\nicefrac{1}{\Delta_i}(T_{t,x_u}^{t+\Delta_i}-I)=Q$. Because we assumed that the claim is false, we must have that for all $\Delta\in\realspos$, it holds that $\left[L_t^{t+\Delta}f\right](x) \leq \left[T_{t,x_u}^{t+\Delta}f\right](x)$,
or equivalently, that
\begin{equation*}
\frac{1}{\Delta}\left[(L_t^{t+\Delta} - I)f\right](x) \leq \frac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta} - I)f\right](x)\,.
\end{equation*}
Taking limits on both sides with respect to $\{\Delta_i\}_{i\in\nats}$, we find that
\begin{align*}
\lim_{i\to+\infty}\frac{1}{\Delta_i}\left[(L_t^{t+\Delta_i} - I)f\right](x) &\leq \lim_{i\to+\infty}\frac{1}{\Delta_i}\left[(T_{t,x_u}^{t+\Delta_i} - I)f\right](x) \\
\left[\lrate f\right](x) &\leq \left[Qf\right](x)\,,
\end{align*}
where the left-hand limit follows from Proposition~\ref{prop:lower_transition_has_deriv}. This contradicts the earlier observation that $\left[Qf\right](x)<\left[\lrate f\right](x)$. Hence, if the statement is indeed false, we must instead have that $Q\in\smash{\overline{\partial}}_-T_{t,x_u}^{t}$. In that case, there is some other $\{\Delta_i\}_{i\in\nats}\to0^+$, such that $\lim_{i\to+\infty}\nicefrac{1}{\Delta_i}(T_{t-\Delta_i,x_u}^{t}-I)=Q$, and similarly, we should have for all $\Delta\in\realspos$ that
\begin{equation*}
\frac{1}{\Delta}\left[(L_{t-\Delta}^{t} - I)f\right](x) \leq \frac{1}{\Delta}\left[(T_{t-\Delta,x_u}^{t} - I)f\right](x)\,.
\end{equation*}
By Proposition~\ref{prop:lower_transition_is_homogeneous}, we have that $L_{t-\Delta}^{t}=L_{t}^{t+\Delta}$, and so after taking limits on both sides,
\begin{align*}
\lim_{i\to+\infty}\frac{1}{\Delta_i}\left[(L_t^{t+\Delta_i} - I)f\right](x) &\leq \lim_{i\to+\infty}\frac{1}{\Delta_i}\left[(T_{t-\Delta_i,x_u}^{t} - I)f\right](x) \\
\left[\lrate f\right](x) &\leq \left[Qf\right](x)\,,
\end{align*}
we again find a contradiction. Therefore, if $P\in\wprocesses$, the statement follows.

Now, suppose that instead $P\notin\wprocesses$. Assume \emph{ex absurdo} that the statement is false. Because $P\notin\wprocesses$, by Definition~\ref{def:well-behaved} there must be some $t\in\realsnonneg$, some $u\in\mathcal{U}_{<t}$, some $x_u\in\states^u$, and some $x,y\in\states$, such that either 
\begin{equation*}
\limsup_{\Delta\to0^+}\frac{1}{\Delta}\abs{P(X_{t+\Delta}=y\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})-\delta_{xy}}\nless+\infty\,,
\end{equation*}
or,
\begin{equation*}
\limsup_{\Delta\to0^+}\frac{1}{\Delta}\abs{P(X_{t}=y\,\vert\,X_{t-\Delta}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})-\delta_{xy}}\nless+\infty\,.
\end{equation*}
Start by assuming that it is the former. Clearly, we have for all $\Delta\in\realspos$ that $\left[T_{t,x_u}^{t+\Delta}\ind{y}\right](x)=P(X_{t+\Delta}=y\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})$, and furthermore, that $\left[I\ind{y}\right](x)=\delta_{xy}$. Hence, we have that
\begin{equation*}
\left[(T_{t,x_u}^{t+\Delta}-I)\ind{y}\right](x) = P(X_{t+\Delta}=y\,\vert\,X_t=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n}) - \delta_{xy}\,.
\end{equation*}
By Proposition~\ref{prop:rate_from_stochastic_matrix}, we have that $\nicefrac{1}{\Delta}(T_{t,x_u}^{t+\Delta}-I)$ is a transition rate matrix, and hence by Definition~\ref{def:rate_matrix} we must have that $\nicefrac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta}-I)\ind{x}\right](x)\leq 0$, and $\nicefrac{1}{\Delta}\abs{\left[(T_{t,x_u}^{t+\Delta}-I)\ind{y}\right](x)}\leq\nicefrac{1}{\Delta}\abs{\left[(T_{t,x_u}^{t+\Delta}-I)\ind{x}\right](x)}$. It therefore follows that also
\begin{equation}\label{eq:nonwellbehaved_limit_diagonal}
\limsup_{\Delta\to0^+}\frac{1}{\Delta}\abs{\left[(T_{t,x_u}^{t+\Delta}-I)\ind{x}\right](x)} \nless +\infty\,.
\end{equation}
Similarly, by Lemma~\ref{lemma:lower_trans_to_lower_rate}, we have that $\nicefrac{1}{\Delta}(L_t^{t+\Delta}-I)$ is a lower transition rate operator, and hence by Definition~\ref{def:coh_low_trans_rate}, we must have that $\nicefrac{1}{\Delta}\left[(L_t^{t+\Delta}-I)\ind{x}\right](x)\leq 0$. 

Because we assumed that the statement is false, and because $\ind{x}\in\gamblesX$, it must hold for all $\Delta\in\realspos$ that $\left[L_{t}^{t+\Delta}\ind{x}\right](x)\leq\left[T_{t,x_u}^{t+\Delta}\ind{x}\right](x)$, or equivalently, that
\begin{equation*}
\frac{1}{\Delta}\left[(L_{t}^{t+\Delta} - I)\ind{x}\right](x) \leq \frac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta} - I)\ind{x}\right](x)\,.
\end{equation*}
From our earlier observations, we know that both sides of this inequality are non-positive. Hence, we must have that
\begin{equation*}
\abs{\frac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta} - I)\ind{x}\right](x)} \leq \abs{\frac{1}{\Delta}\left[(L_{t}^{t+\Delta} - I)\ind{x}\right](x)}\,.
\end{equation*}
By the definition of the norm, we have that $\abs{\nicefrac{1}{\Delta}\left[(L_{t}^{t+\Delta} - I)\ind{x}\right](x)}\leq\norm{\nicefrac{1}{\Delta}(L_{t}^{t+\Delta} - I)\ind{x}}$, and because $\ind{x}\in\gamblesX$ and $\norm{\ind{x}}=1$, we have $\norm{\nicefrac{1}{\Delta}(L_{t}^{t+\Delta} - I)\ind{x}}\leq \norm{\nicefrac{1}{\Delta}(L_{t}^{t+\Delta} - I)}$. Hence, we must have that
\begin{equation*}
\abs{\frac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta} - I)\ind{x}\right](x)} \leq \norm{\frac{1}{\Delta}(L_{t}^{t+\Delta} - I)}\,.
\end{equation*}

Now, by Proposition~\ref{prop:lower_transition_has_deriv}, we have that $\lim_{\Delta\to0^+}\nicefrac{1}{\Delta}(L_{t}^{t+\Delta} - I) = \lrate$, and hence it follows that $\lim_{\Delta\to0^+}\norm{\nicefrac{1}{\Delta}(L_{t}^{t+\Delta} - I)} = \norm{\lrate}$. By Lemma~\ref{lem:normlratefinite}, we furthermore know that $\norm{\lrate}<+\infty$. Taking limits on both sides of our earlier inequality, we therefore find that
\begin{equation*}
\limsup_{\Delta\to0^+}\abs{\frac{1}{\Delta}\left[(T_{t,x_u}^{t+\Delta} - I)\ind{x}\right](x)} \leq \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}(L_{t}^{t+\Delta} - I)} = \norm{\lrate} < +\infty\,,
\end{equation*}
which, by Equation~\eqref{eq:nonwellbehaved_limit_diagonal}, is a contradiction. Therefore, if the statement is indeed false, we must instead have that for some (other) $t\in\realsnonneg$, some (other) $u\in\mathcal{U}_{<t}$, some (other) $x_\in\states^u$, and some (other) $x,y\in\states$,
\begin{equation}\label{eq:nonwellbehaved_limit_diagonal_left}
\limsup_{\Delta\to0^+}\frac{1}{\Delta}\abs{P(X_{t}=y\,\vert\,X_{t-\Delta}=x,X_{t_0}=x_{t_0},\ldots,X_{t_n}=x_{t_n})-\delta_{xy}}\nless+\infty\,.
\end{equation}
Using the same argument as before, we must then have for all $\Delta\in\realspos$ that
\begin{equation*}
\abs{\frac{1}{\Delta}\left[(T_{t-\Delta,x_u}^t - I)\ind{x}\right](x)} \leq \norm{\frac{1}{\Delta}(L_{t-\Delta}^t - I)}\,.
\end{equation*}
Because by Proposition~\ref{prop:lower_transition_is_homogeneous} we have that $L_{t-\Delta}^t=L_t^{t+\Delta}$, we again find after taking limits on both sides that
\begin{equation*}
\limsup_{\Delta\to0^+}\abs{\frac{1}{\Delta}\left[(T_{t-\Delta,x_u}^t - I)\ind{x}\right](x)} \leq \limsup_{\Delta\to0^+}\norm{\frac{1}{\Delta}(L_{t}^{t+\Delta} - I)} = \norm{\lrate} < +\infty\,,
\end{equation*}
a contradiction with Equation~\eqref{eq:nonwellbehaved_limit_diagonal_left}. Therefore, if $P\notin\wprocesses$, the statement follows.
\end{proof}

\section{Proofs and Lemmas for Section~\ref{sec:funcs_multi_time_points}}

\begin{proof}[Proof of Proposition~\ref{prop:multi_var_single_future_bounded}]
Because $f(x_{t_0},\ldots,x_{t_n},X_s)$ is a restriction of $f$ to $\states^{\{s\}}$, there is some $g\in\gambles(\states^{\{s\}})$ such that $g(x_s) = f(x_{t_0},\ldots,x_{t_n},x_s)$ for all $x_s\in\states^{\{s\}}$. By substitution, we therefore have to show that $\left[L_t^sg\right](x_{t_n}) \leq \mathbb{E}\left[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\right]$. Because $g\in\gambles(\states^{\{s\}})$, this inequality holds by Theorem~\ref{theorem:nonmarkov_single_var_lower_bounded}.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:multi_var_single_future_tight}]
Because $f(x_{t_0},\ldots,x_{t_n},X_s)$ is a restriction of $f$ to $\states^{\{s\}}$, there is some $g\in\gambles(\states^{\{s\}})$ such that $g(x_s) = f(x_{t_0},\ldots,x_{t_n},x_s)$ for all $x_s\in\states^{\{s\}}$. By substitution, we now have to show that there is a $P\in\mprocesses_\rateset$ such that $\abs{\left[L_t^sg\right](x_{t_n})-\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]} < \epsilon$. 

Because $g\in\gambles(\states^{\{s\}})$, by Theorem~\ref{theorem:lower_markov_bound_is_tight} there must be some $P\in\mprocesses_\rateset$ such that $\norm{L_t^sg - \mathbb{E}[g(X_s)\,\vert\,X_{t_n}]} < \epsilon$. Consider this $P$. By the Markov property, its expectation must satisfy $\abs{\left[L_t^sg\right](x_{t_n})-\mathbb{E}[g(X_s)\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}]} = \abs{\left[L_t^sg\right](x_{t_n})-\mathbb{E}[g(X_s)\,\vert\,X_{t_n}=x_{t_n}]}$, and by the definition of the norm, we have 
\begin{equation*}
\abs{\left[L_t^sg\right](x_{t_n})-\mathbb{E}[g(X_s)\,\vert\,X_{t_n}=x_{t_n}]} \leq \norm{L_t^sg-\mathbb{E}[g(X_s)\,\vert\,X_{t_n}]} < \epsilon\,.
\end{equation*}
\end{proof}

\begin{proof}[Proof of Corollary~\ref{cor:inf_works_for_single_future_var}]
This is a direct consequence of Propositions \ref{prop:markov_set_subset_of_nonmarkov_set}, \ref{prop:lower_exp_markov_bounded_by_nonmarkov}, \ref{prop:multi_var_single_future_bounded}, and \ref{prop:multi_var_single_future_tight}. The proof is similar to that of Corollary~\ref{cor:lower_operator_is_infimum}.
\end{proof}


\begin{proof}[Proof of Proposition~\ref{prop:multivar_bounded}]
By the basic properties of expectation, we can decompose the expectation functional as
\begin{align*}
 &\quad \mathbb{E}[f(x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \\
 &= \mathbb{E}\bigl[\mathbb{E}[f(x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n},X_{s_0,\ldots,s_{m-1}}]\,\big\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr]\,.
\end{align*}
Note that the nested expectation is conditioned on the time points $t_0,\ldots,t_n,s_0,\ldots,s_{m-1}$; it therefore only computes an expectation on a single point $s_m$ in the future. Hence, by Proposition~\ref{prop:multi_var_single_future_bounded} and the fact that the (outer) expectation computes a convex combination of values, we have
\begin{align*}
&\quad\mathbb{E}[f(x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_m})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}] \\
 &\geq \mathbb{E}\bigl[[L_{s_{m-1}}^{s_m}f](x_{t_0},\ldots,x_{t_n},X_{s_0},\ldots,X_{s_{m-1}})\,\vert\,X_{t_0,\ldots,t_n}=x_{t_0,\ldots,t_n}\bigr]\,.
\end{align*}
The proof is then finished by backward induction on $m$.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:multivar_bound_tight}]
{\bf TODO} *** deze is nog een beetje ingewikkeld, we moeten weer een process bouwen en laten zien dat die in $\processes_\rateset$ zit ***
\end{proof}

\begin{proof}[Proof of Corollary~\ref{cor:inf_works_for_multivar}]
This is a direct consequence of Propositions~\ref{prop:multivar_bounded} and \ref{prop:multivar_bound_tight}.
\end{proof}


\end{document}
